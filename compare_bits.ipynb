{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from models.resnet import resnet18im, resnet18\n",
    "import os, random\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from options import Option\n",
    "\n",
    "from log_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/nsh/save_log/cifar100_resnet18/log_cifar100_resnet18_bs128_ep200_seed_3/ is exists\n",
      "load log path /data/nsh/save_log/cifar100_resnet18/log_cifar100_resnet18_bs128_ep200_seed_3/\n",
      "GPU : [0, 1]\n",
      "activation_index : [3, 9, 15]\n",
      "activation_step : [0, 30, 50, 70, 100]\n",
      "batch_size : 128\n",
      "data_path : /dataset/\n",
      "dataset : cifar100\n",
      "epochs : 200\n",
      "get_weight_grad_param : True\n",
      "get_weight_param : True\n",
      "load_state_dict : False\n",
      "log_override : True\n",
      "lr : 0.1\n",
      "lr_gamma : 0.2\n",
      "ml_step : [60, 120, 160]\n",
      "model_name : resnet18\n",
      "momentum : 0.9\n",
      "nGPU : 1\n",
      "nesterov : True\n",
      "optimizer : SGD\n",
      "save_path : /data/nsh/save_log/cifar100_resnet18\n",
      "scheduler : multi_step\n",
      "seed : 3\n",
      "train : True\n",
      "visible_devices : 1\n",
      "warmup : 5\n",
      "weight_decay : 0.0005\n",
      "worker : 8\n"
     ]
    }
   ],
   "source": [
    "option = Option(\"./resnet18_cifar100.hocon\", \"test\")\n",
    "# 기존에 있는 log 를 불러오기 위해 log_override를 false로 하고 진행\n",
    "option.log_override=False\n",
    "option.set_save_path()\n",
    "\n",
    "\n",
    "torch.manual_seed(option.seed)\n",
    "torch.cuda.manual_seed(option.seed)\n",
    "np.random.seed(option.seed)\n",
    "\n",
    "option.print_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.float16'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This TensorChannelAdder (N, C, H, W) -> (1, C, 1, 1)\n",
    "# It is similar result tensor.sum(axis=0).sum(axis=2).sum(axis=3)\n",
    "# We change tensor.transpose(0, 1).reshape(C, chunk, N*H*W//chunk).sum(axis=2).sum(axis=1)\n",
    "def BatchNormMeanSim(tensor, chunk=1024,AdderType=torch.float16):\n",
    "    epsilon = 1e-10\n",
    "    if not len(tensor.shape) ==4 :\n",
    "        AssertionError(f\"It only supported 4d Matrix, but this tensor shape {tensor.shape}\")\n",
    "\n",
    "    if AdderType==torch.float16:\n",
    "        mantissa = 10\n",
    "    elif AdderType==torch.bfloat16:\n",
    "        mantissa = 7\n",
    "    elif AdderType==torch.float32:\n",
    "        mantissa = 22\n",
    "    elif AdderType==\"test\":\n",
    "        mantissa= 100\n",
    "    else:\n",
    "        AssertionError(\"This Adder only supported FP16|BF16|FP32\")\n",
    "    \n",
    "    temp_tensor =tensor.clone()\n",
    "    zero_mask_counter = []\n",
    "    \n",
    "    n, c, h, w = tensor.shape\n",
    "\n",
    "    \n",
    "    if not n*h*w % chunk == 0: \n",
    "        AssertionError(f\"The n*h*w should always be divisible chunk but result {n*h*w % chunk}\")\n",
    "    #change (c, n*h*w//chunk, chunk) \n",
    "    chunk_tensor = temp_tensor.transpose(1, 0).reshape(c, chunk, n*h*w//chunk)\n",
    "    \n",
    "    # first chunk based Adder (last dim size is equal to n*h*w divided by chunk, so last dim adder is always chunk adder)\n",
    "    # (C, chunk, 0) + (C, chunk, 1) = C*chunk adder\n",
    "    # accumulated that result of adder is final values (chunk_tensor[:, :, -1])\n",
    "    for i in range(chunk_tensor.shape[-1] -1):\n",
    "        prev = chunk_tensor[:, :, i]\n",
    "        prec = chunk_tensor[:, :, i+1]\n",
    "        log_prev = torch.log2(torch.abs(prev)+epsilon)\n",
    "        log_prec = torch.log2(torch.abs(prec)+epsilon)\n",
    "        zero_mask = torch.abs(log_prec-log_prev) > mantissa\n",
    "        max_log_tensor = prec.clone()\n",
    "        max_log_tensor[log_prec<log_prev] = prev[log_prec<log_prev] # 두 벡터 중 log2 의 value가 큰 값을 가지고 있는 vector 생성\n",
    "        output = prec+prev # 두 벡터를 더함\n",
    "        output[zero_mask] = max_log_tensor[zero_mask] # zero_mask에 해당하는 부분은 log2 value가 큰 값만 저장\n",
    "        chunk_tensor[:,:, i+1] = output\n",
    "        zero_mask_counter.append(zero_mask.sum())\n",
    "    \n",
    "    sum_tensor = chunk_tensor[:, :, -1] # C, chunk_size\n",
    "    #print(f\"chunk based sum result : {sum(zero_mask_counter)}/{c * chunk * (chunk_tensor.shape[-1]-1)} = {sum(zero_mask_counter) / (c * chunk * (chunk_tensor.shape[-1]-1)) * 100}%\")\n",
    "    \n",
    "    for j in range(chunk_tensor.shape[1]-1):\n",
    "        prev = sum_tensor[:, j]\n",
    "        prec = sum_tensor[:, j+1]        \n",
    "        log_prev = torch.log2(torch.abs(prev)+epsilon)\n",
    "        log_prec = torch.log2(torch.abs(prec)+epsilon)\n",
    "        zero_mask = torch.abs(log_prec-log_prev) > mantissa\n",
    "        max_log_tensor = prec.clone()\n",
    "        max_log_tensor[log_prec<log_prev] = prev[log_prec<log_prev] # 두 벡터 중 log2 의 value가 큰 값을 가지고 있는 vector 생성\n",
    "        output = prec+prev # 두 벡터를 더함\n",
    "        output[zero_mask] = max_log_tensor[zero_mask] # zero_mask에 해당하는 부분은 log2 value가 큰 값만 저장\n",
    "        sum_tensor[:, j+1] = output\n",
    "        zero_mask_counter.append(zero_mask.sum())\n",
    "        \n",
    "    # chunk_tensor[:, :, -1] is same to chunk_tensor.sum(dim=-2), and then finally  \n",
    "\n",
    "    #print(f\"final sum result : {sum(zero_mask_counter)}/{c*(chunk-1)+c * chunk * (chunk_tensor.shape[-1]-1)} =\\\n",
    "    #    {sum(zero_mask_counter)/(c*(chunk-1)+ c * chunk * (chunk_tensor.shape[-1]-1)) * 100}%\")\n",
    "    \n",
    "    return sum_tensor[:, -1]/(n*h*w), sum(zero_mask_counter), (n*h*w-1)*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This TensorChannelAdder (N, C, H, W) -> (1, C, 1, 1)\n",
    "# It is similar result tensor.sum(axis=0).sum(axis=2).sum(axis=3)\n",
    "# We change tensor.transpose(0, 1).reshape(C, chunk, N*H*W//chunk).sum(axis=2).sum(axis=1)\n",
    "def BatchNormStdSim(tensor, mean_tensor, chunk=1024, AdderType=torch.float16):\n",
    "    epsilon = 1e-10\n",
    "    if not len(tensor.shape) ==4 :\n",
    "        AssertionError(f\"It only supported 4d Matrix, but this tensor shape {tensor.shape}\")\n",
    "\n",
    "    if AdderType==torch.float16:\n",
    "        mantissa = 10\n",
    "    elif AdderType==torch.bfloat16:\n",
    "        mantissa = 7\n",
    "    elif AdderType==torch.float32:\n",
    "        mantissa = 22\n",
    "    elif AdderType==\"test\":\n",
    "        mantissa= 100\n",
    "    else:\n",
    "        AssertionError(\"This Adder only supported FP16|BF16|FP32\")\n",
    "    \n",
    "    temp_tensor =tensor.clone()\n",
    "    zero_mask_counter = []\n",
    "    \n",
    "    n, c, h, w = tensor.shape\n",
    "\n",
    "    \n",
    "    if not n*h*w % chunk == 0: \n",
    "        AssertionError(f\"The n*h*w should always be divisible chunk but result {n*h*w % chunk}\")\n",
    "    #change (c, n*h*w//chunk, chunk) \n",
    "\n",
    "    if mean_tensor.dim() == 1:\n",
    "        #change 4d tensor\n",
    "        mean_tensor = mean_tensor.reshape(1, -1, 1, 1)\n",
    "    elif mean_tensor.dim() !=4:\n",
    "        AssertionError(\"mean_tensor input only 1d or 4d tensor\")\n",
    "    \n",
    "    if not mean_tensor.shape[1] == c:\n",
    "        AssertionError(\"mean_tensor and tensor is required same shape\")\n",
    "    # first computing (X-mean)**2\n",
    "\n",
    "    mean_tensor = torch.zeros_like(temp_tensor) + mean_tensor # broadcasting and same shape result tensor\n",
    "    log_temp_tensor = torch.log2(torch.abs(temp_tensor) + epsilon)\n",
    "    log_temp_mean = torch.log2(torch.abs(mean_tensor) + epsilon)\n",
    "    zero_mask = torch.abs(log_temp_tensor - log_temp_mean) > mantissa\n",
    "    output = temp_tensor - mean_tensor # X - mean(X)\n",
    "    max_log_tensor = temp_tensor.clone()\n",
    "    max_log_tensor[log_temp_tensor<log_temp_mean] = mean_tensor[log_temp_tensor<log_temp_mean] # get log2 max_value\n",
    "    output[zero_mask]=max_log_tensor[zero_mask]\n",
    "    var = output**2 # (X - mean(X))^2\n",
    "\n",
    "    chunk_tensor = var.transpose(1, 0).reshape(c, chunk, n*h*w//chunk)\n",
    "\n",
    "    \n",
    "    # second chunk based Adder (last dim size is equal to n*h*w divided by chunk, so last dim adder is always chunk adder)\n",
    "    # (C, chunk, 0) + (C, chunk, 1) = C*chunk adder\n",
    "    # accumulated that result of adder is final values (chunk_tensor[:, :, -1])\n",
    "    for i in range(chunk_tensor.shape[-1] -1):\n",
    "        prev = chunk_tensor[:, :, i]\n",
    "        prec = chunk_tensor[:, :, i+1]\n",
    "        log_prev = torch.log2(torch.abs(prev)+epsilon)\n",
    "        log_prec = torch.log2(torch.abs(prec)+epsilon)\n",
    "        zero_mask = torch.abs(log_prec-log_prev) > mantissa\n",
    "        max_log_tensor = prec.clone()\n",
    "        max_log_tensor[log_prec<log_prev] = prev[log_prec<log_prev] # 두 벡터 중 log2 의 value가 큰 값을 가지고 있는 vector 생성\n",
    "        output = prec+prev # 두 벡터를 더함\n",
    "        output[zero_mask] = max_log_tensor[zero_mask] # zero_mask에 해당하는 부분은 log2 value가 큰 값만 저장\n",
    "        chunk_tensor[:,:, i+1] = output\n",
    "        zero_mask_counter.append(zero_mask.sum())\n",
    "    \n",
    "    sum_tensor = chunk_tensor[:, :, -1] # C, chunk_size\n",
    "    #print(f\"chunk based sum result : {sum(zero_mask_counter)}/{c * chunk * (chunk_tensor.shape[-1]-1)} = {sum(zero_mask_counter) / (c * chunk * (chunk_tensor.shape[-1]-1)) * 100}%\")\n",
    "    \n",
    "    for j in range(chunk_tensor.shape[1]-1):\n",
    "        prev = sum_tensor[:, j]\n",
    "        prec = sum_tensor[:, j+1]        \n",
    "        log_prev = torch.log2(torch.abs(prev)+epsilon)\n",
    "        log_prec = torch.log2(torch.abs(prec)+epsilon)\n",
    "        zero_mask = torch.abs(log_prec-log_prev) > mantissa\n",
    "        max_log_tensor = prec.clone()\n",
    "        max_log_tensor[log_prec<log_prev] = prev[log_prec<log_prev] # 두 벡터 중 log2 의 value가 큰 값을 가지고 있는 vector 생성\n",
    "        output = prec+prev # 두 벡터를 더함\n",
    "        output[zero_mask] = max_log_tensor[zero_mask] # zero_mask에 해당하는 부분은 log2 value가 큰 값만 저장\n",
    "        sum_tensor[:, j+1] = output\n",
    "        zero_mask_counter.append(zero_mask.sum())\n",
    "        \n",
    "    # chunk_tensor[:, :, -1] is same to chunk_tensor.sum(dim=-2), and then finally  \n",
    "\n",
    "    #print(f\"final sum result : {sum(zero_mask_counter)}/{c*(chunk-1)+c * chunk * (chunk_tensor.shape[-1]-1)} =\\\n",
    "    #    {sum(zero_mask_counter)/(c*(chunk-1)+ c * chunk * (chunk_tensor.shape[-1]-1)) * 100}%\")\n",
    "    \n",
    "    return torch.sqrt(sum_tensor[:, -1]/(n*h*w)), sum(zero_mask_counter), (n*h*w-1)*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk based sum result : 0/1015808 = 0.0%\n",
      "tensor([-0.0078, -0.0006, -0.0035, -0.0039, -0.0056,  0.0142,  0.0017,  0.0023,\n",
      "         0.0043, -0.0045, -0.0013, -0.0046,  0.0023, -0.0019,  0.0101, -0.0036,\n",
      "         0.0102,  0.0052,  0.0104, -0.0016,  0.0012,  0.0014,  0.0037,  0.0004,\n",
      "        -0.0075,  0.0056,  0.0108, -0.0060,  0.0024,  0.0025, -0.0106, -0.0031])\n",
      "(tensor([-0.0078, -0.0006, -0.0035, -0.0039, -0.0056,  0.0142,  0.0017,  0.0023,\n",
      "         0.0043, -0.0045, -0.0013, -0.0046,  0.0023, -0.0019,  0.0101, -0.0036,\n",
      "         0.0102,  0.0052,  0.0104, -0.0016,  0.0012,  0.0014,  0.0037,  0.0004,\n",
      "        -0.0075,  0.0056,  0.0108, -0.0060,  0.0024,  0.0025, -0.0106, -0.0031]), tensor(0), 1048544)\n",
      "chunk based sum result : 0/1015808 = 0.0%\n",
      "tensor([1.0005, 1.0002, 0.9954, 1.0013, 1.0012, 0.9972, 0.9992, 0.9966, 1.0012,\n",
      "        1.0026, 1.0054, 1.0032, 0.9957, 1.0012, 1.0064, 1.0021, 1.0002, 0.9988,\n",
      "        0.9989, 0.9955, 0.9992, 0.9890, 1.0029, 1.0000, 1.0011, 1.0081, 0.9985,\n",
      "        0.9975, 0.9936, 1.0025, 0.9971, 0.9947])\n",
      "(tensor([1.0004, 1.0002, 0.9954, 1.0013, 1.0011, 0.9972, 0.9991, 0.9965, 1.0012,\n",
      "        1.0025, 1.0054, 1.0032, 0.9957, 1.0012, 1.0064, 1.0021, 1.0002, 0.9988,\n",
      "        0.9989, 0.9955, 0.9992, 0.9889, 1.0029, 1.0000, 1.0011, 1.0081, 0.9984,\n",
      "        0.9975, 0.9936, 1.0025, 0.9971, 0.9947]), tensor(0), 1048544)\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.randn(128, 32, 16, 16)\n",
    "original_mean = test_tensor.transpose(0,1).reshape(32, -1).mean(1)\n",
    "refined_mean = BatchNormMeanSim(test_tensor, chunk=1024, AdderType=\"test\") # zero_setting error 발생안함.\n",
    "print(original_mean)\n",
    "print(refined_mean)\n",
    "\n",
    "original_std = test_tensor.transpose(0,1).reshape(32,-1).std(1)\n",
    "refined_std =BatchNormStdSim(test_tensor, original_mean, chunk=1024, AdderType=\"test\")\n",
    "print(original_std)\n",
    "print(refined_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compare_BatchNorm_Precision(nn.Module):\n",
    "    # this is custom batchnorm different precision\n",
    "    # Considered https://github.com/ptrblck/pytorch_misc/blob/master/batch_norm_manual.py and rangeBN \n",
    "\n",
    "\n",
    "    def __init__(self, num_features, intermediate_result = False, chunk=1024, dim=1, momentum=0.9, affine=True, eps=1e-5, compute_type=torch.float16):\n",
    "        super(Compare_BatchNorm_Precision, self).__init__()\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.zeros(num_features))\n",
    "\n",
    "        self.momentum = momentum\n",
    "        self.dim = dim\n",
    "        self.eps = 1e-10\n",
    "        self.intermediate_result = intermediate_result\n",
    "        if affine:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_features))\n",
    "            self.weight = nn.Parameter(torch.Tensor(num_features))\n",
    "        self.compute_type = compute_type\n",
    "        self.eps = eps\n",
    "        self.chunk = chunk\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        if self.weight is not None:\n",
    "            self.weight.data.uniform_()\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def load_params(self, weight, bias, running_mean, running_var):\n",
    "        self.weight=weight\n",
    "        self.bias=bias\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var\n",
    "        \n",
    "\n",
    "    def forward(self, x, inference=True):\n",
    "        x_ch = x.type(self.compute_type)        \n",
    "        if not inference:\n",
    "        \n",
    "            # not using momentum\n",
    "            n,c,h,w = x.shape\n",
    "            mean = x.transpose(1,0).reshape(c,-1).mean(dim=-1) # c axis mean\n",
    "            std = x.transpose(1,0).reshape(c,-1).std(dim=-1) # c axis std\n",
    "\n",
    "            mean_ch, zero_mean_count, total_mean_compute =  BatchNormMeanSim(x, chunk=self.chunk, AdderType=self.compute_type)\n",
    "            std_ch, zero_std_count, total_std_compute = BatchNormStdSim(x, mean_ch, chunk=self.chunk, AdderType=self.compute_type)\n",
    "\n",
    "            out = (x - mean.view(1, mean.size(0), 1, 1)) / \\\n",
    "                (std.view(1, std.size(0), 1, 1) + self.eps)\n",
    "\n",
    "            out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) / \\\n",
    "                (std_ch.view(1, std_ch.size(0), 1, 1) + self.eps)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # using running_mean, and running_var\n",
    "            c = x_ch.shape[1]\n",
    "            mean = self.running_mean\n",
    "            scale = self.running_var\n",
    "            mean_ch = self.running_mean.type(self.compute_type)\n",
    "            scale_ch = self.running_var.type(self.compute_type)\n",
    "\n",
    "            out = (x - mean.view(1, mean.size(0), 1, 1)) / \\\n",
    "                (scale.view(1, scale.size(0), 1, 1) + self.eps)\n",
    "\n",
    "            out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) / \\\n",
    "                (scale_ch.view(1, scale.size(0), 1, 1) + self.eps)\n",
    "        \n",
    "        if self.intermediate_result:\n",
    "            # return only normalized value\n",
    "\n",
    "            return out, out_ch, zero_mean_count, total_mean_compute, zero_std_count, total_std_compute\n",
    "\n",
    "        if self.weight is not None:\n",
    "            \n",
    "            weight = self.weight\n",
    "            weight_ch = self.weight.type(self.compute_type)\n",
    "            out = out * weight.view(1, weight.size(0), 1, 1)\n",
    "            out_ch = out_ch * weight_ch.view(1, weight_ch.size(0), 1, 1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias =self.bias\n",
    "            out = out + bias.view(1, bias.size(0), 1, 1)\n",
    "            bias_ch = self.bias.type(self.compute_type)\n",
    "            out_ch = out_ch + bias_ch.view(1, bias_ch.size(0), 1, 1)\n",
    "\n",
    "        return out, out_ch, zero_mean_count, total_mean_compute, zero_std_count, total_std_compute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_csv_path = os.path.join(option.save_path, \"batchnorm_param.csv\")\n",
    "batchnorm_df = pd.read_csv(batchnorm_csv_path)\n",
    "\n",
    "\n",
    "# csv에 저장된 batch_norm 데이터를 읽어오는 함수\n",
    "\n",
    "def csv_txt_to_param(txt):\n",
    "    temp_txt = txt\n",
    "    temp_txt = temp_txt.replace(\"[\", \"\")\n",
    "    temp_txt = temp_txt.replace(\"]\", \"\")\n",
    "    temp_list = temp_txt.split()\n",
    "\n",
    "    np_txt = np.array(temp_list, dtype=np.float32)\n",
    "    torch_result = torch.Tensor(np_txt)\n",
    "    return torch_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "idx :  3\n",
      "layer name :  conv2_x.1.residual_function.1\n",
      "chunk based sum result : 160785/8323072 = 1.9317988157272339%\n",
      "chunk based sum result : 1353443/8323072 = 16.26133918762207%\n",
      "chunk based sum result : 1426712/8323072 = 17.141651153564453%\n",
      "chunk based sum result : 3479627/8323072 = 41.807003021240234%\n",
      "{'epoch': 0, 'layer': 'conv2_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0039, 0.0122, 0.0177, 0.0150, 0.0040, 0.0040, 0.0022, 0.0045, 0.0034,\n",
      "        0.0036, 0.0052, 0.0150, 0.0042, 0.0047, 0.0036, 0.0026, 0.0055, 0.0035,\n",
      "        0.0032, 0.0122, 0.0023, 0.0097, 0.0072, 0.0032, 0.0027, 0.0106, 0.0025,\n",
      "        0.0036, 0.0051, 0.0051, 0.0041, 0.0028, 0.0038, 0.0065, 0.0019, 0.0034,\n",
      "        0.0029, 0.0042, 0.0026, 0.0032, 0.0042, 0.0034, 0.0095, 0.0108, 0.0052,\n",
      "        0.0147, 0.0020, 0.0033, 0.0109, 0.0030, 0.0029, 0.0026, 0.0143, 0.0130,\n",
      "        0.0033, 0.0155, 0.0031, 0.0039, 0.0041, 0.0115, 0.0034, 0.0030, 0.0035,\n",
      "        0.0035]), 'FP32-FP16_L_inf': tensor([0.0950, 0.1259, 0.1558, 0.1922, 0.0809, 0.0921, 0.0754, 0.1013, 0.0971,\n",
      "        0.1087, 0.1443, 0.1080, 0.1295, 0.1072, 0.0849, 0.1003, 0.1229, 0.0881,\n",
      "        0.1140, 0.1711, 0.0741, 0.1563, 0.2143, 0.0828, 0.0918, 0.1587, 0.0847,\n",
      "        0.0738, 0.1394, 0.1182, 0.1440, 0.0579, 0.0634, 0.1213, 0.0774, 0.1411,\n",
      "        0.1183, 0.0782, 0.0804, 0.1119, 0.1232, 0.0694, 0.1656, 0.1719, 0.1073,\n",
      "        0.2061, 0.1024, 0.0914, 0.1053, 0.0962, 0.0583, 0.0939, 0.1651, 0.1680,\n",
      "        0.0689, 0.1441, 0.0835, 0.0924, 0.1384, 0.1801, 0.0696, 0.1718, 0.0854,\n",
      "        0.0884]), 'FP32-FP16 mean zero setting Error': '172113 / 8388544', 'FP32-FP16 mean std setting Error': '1369028 / 8388544', 'FP32-BF16_mse': tensor([0.8461, 1.0884, 1.6448, 1.2952, 1.0459, 0.5638, 0.5792, 0.6591, 0.4492,\n",
      "        0.3806, 1.4922, 1.1825, 0.9092, 0.3750, 0.6701, 0.5095, 0.4775, 0.5951,\n",
      "        1.2287, 1.4950, 0.5998, 1.0386, 1.1862, 0.6713, 0.5328, 1.4712, 0.9744,\n",
      "        0.8561, 1.3169, 1.5395, 1.0778, 0.6452, 0.6884, 1.1935, 0.8344, 0.5972,\n",
      "        0.7640, 0.9487, 0.3212, 0.8595, 1.4694, 0.8870, 1.9986, 1.3074, 0.7410,\n",
      "        1.5126, 0.7897, 0.7739, 2.2452, 0.5984, 0.5983, 0.3023, 2.5055, 1.5592,\n",
      "        0.5580, 0.9587, 0.4237, 0.3452, 0.5079, 0.9914, 0.7932, 0.4425, 0.4905,\n",
      "        0.9817]), 'FP32-bf16_L_inf': tensor([15.8834,  3.8124,  2.7887,  4.7239, 14.9695, 13.3513, 18.5434, 15.7082,\n",
      "         8.7828, 10.8837, 18.5129,  2.2147, 20.2704,  8.4315, 12.9045, 19.5378,\n",
      "         9.6359, 15.1022, 32.6428,  6.0656, 19.0301,  6.5978, 12.0496, 11.8867,\n",
      "        17.2301,  9.9926, 30.9825, 10.8049, 13.3098, 17.3153, 30.9612, 11.2588,\n",
      "         9.1162, 17.3191, 33.9676, 23.8945, 27.4020, 10.9933, 10.1532, 23.3402,\n",
      "        21.1556, 15.5838,  8.9971, 11.5666,  9.7926,  2.6584, 41.3010, 16.2450,\n",
      "         6.0211, 17.3010, 10.6136,  9.7849,  3.5477,  6.2235,  8.9182,  1.2729,\n",
      "         8.6441,  8.3506, 17.6612,  4.2636, 15.3657, 21.2006, 10.7549, 16.5759]), 'FP32-BF16 mean zero setting Error': '1475139 / 8388544', 'FP32-BF16 mean std setting Error': '3533221 / 8388544'}\n",
      "idx :  9\n",
      "layer name :  conv4_x.0.residual_function.1\n",
      "chunk based sum result : 2994/1835008 = 0.1631600558757782%\n",
      "chunk based sum result : 81611/1835008 = 4.447446346282959%\n",
      "chunk based sum result : 23659/1835008 = 1.2893131971359253%\n",
      "chunk based sum result : 215767/1835008 = 11.758368492126465%\n",
      "{'epoch': 0, 'layer': 'conv4_x.0.residual_function.1', 'FP32-FP16_mse': tensor([0.0062, 0.0052, 0.0068, 0.0029, 0.0031, 0.0029, 0.0063, 0.0055, 0.0035,\n",
      "        0.0120, 0.0108, 0.0022, 0.0030, 0.0025, 0.0047, 0.0032, 0.0041, 0.0024,\n",
      "        0.0036, 0.0062, 0.0100, 0.0033, 0.0147, 0.0065, 0.0026, 0.0052, 0.0027,\n",
      "        0.0030, 0.0031, 0.0026, 0.0089, 0.0058, 0.0044, 0.0027, 0.0064, 0.0062,\n",
      "        0.0033, 0.0058, 0.0040, 0.0029, 0.0039, 0.0170, 0.0046, 0.0019, 0.0025,\n",
      "        0.0027, 0.0034, 0.0044, 0.0022, 0.0030, 0.0023, 0.0048, 0.0030, 0.0040,\n",
      "        0.0023, 0.0032, 0.0064, 0.0025, 0.0036, 0.0030, 0.0029, 0.0023, 0.0068,\n",
      "        0.0026, 0.0022, 0.0028, 0.0031, 0.0117, 0.0027, 0.0026, 0.0029, 0.0041,\n",
      "        0.0020, 0.0036, 0.0026, 0.0077, 0.0052, 0.0027, 0.0138, 0.0033, 0.0078,\n",
      "        0.0102, 0.0039, 0.0065, 0.0036, 0.0054, 0.0030, 0.0020, 0.0025, 0.0027,\n",
      "        0.0025, 0.0027, 0.0028, 0.0030, 0.0030, 0.0089, 0.0036, 0.0027, 0.0036,\n",
      "        0.0042, 0.0030, 0.0028, 0.0038, 0.0028, 0.0044, 0.0022, 0.0106, 0.0054,\n",
      "        0.0032, 0.0035, 0.0037, 0.0032, 0.0037, 0.0040, 0.0037, 0.0027, 0.0045,\n",
      "        0.0025, 0.0049, 0.0034, 0.0146, 0.0037, 0.0054, 0.0026, 0.0110, 0.0034,\n",
      "        0.0028, 0.0021, 0.0070, 0.0097, 0.0051, 0.0123, 0.0028, 0.0219, 0.0033,\n",
      "        0.0025, 0.0128, 0.0029, 0.0026, 0.0062, 0.0028, 0.0019, 0.0024, 0.0027,\n",
      "        0.0100, 0.0029, 0.0029, 0.0026, 0.0066, 0.0076, 0.0031, 0.0032, 0.0090,\n",
      "        0.0055, 0.0071, 0.0047, 0.0064, 0.0058, 0.0032, 0.0038, 0.0041, 0.0030,\n",
      "        0.0031, 0.0030, 0.0048, 0.0035, 0.0028, 0.0066, 0.0077, 0.0034, 0.0040,\n",
      "        0.0032, 0.0031, 0.0024, 0.0031, 0.0173, 0.0035, 0.0069, 0.0064, 0.0028,\n",
      "        0.0026, 0.0027, 0.0085, 0.0151, 0.0027, 0.0109, 0.0029, 0.0025, 0.0052,\n",
      "        0.0042, 0.0026, 0.0142, 0.0037, 0.0056, 0.0039, 0.0115, 0.0094, 0.0038,\n",
      "        0.0027, 0.0023, 0.0043, 0.0044, 0.0024, 0.0026, 0.0032, 0.0159, 0.0025,\n",
      "        0.0063, 0.0035, 0.0039, 0.0028, 0.0028, 0.0027, 0.0130, 0.0032, 0.0186,\n",
      "        0.0028, 0.0086, 0.0035, 0.0032, 0.0071, 0.0031, 0.0084, 0.0029, 0.0047,\n",
      "        0.0113, 0.0056, 0.0025, 0.0113, 0.0034, 0.0027, 0.0088, 0.0091, 0.0033,\n",
      "        0.0021, 0.0034, 0.0078, 0.0035, 0.0029, 0.0070, 0.0087, 0.0037, 0.0117,\n",
      "        0.0030, 0.0042, 0.0041, 0.0029, 0.0024, 0.0062, 0.0039, 0.0031, 0.0027,\n",
      "        0.0026, 0.0025, 0.0035, 0.0024]), 'FP32-FP16_L_inf': tensor([0.1110, 0.0844, 0.1059, 0.0622, 0.0833, 0.0597, 0.0554, 0.0761, 0.0679,\n",
      "        0.1713, 0.0864, 0.0565, 0.0929, 0.0548, 0.0611, 0.0739, 0.0816, 0.0624,\n",
      "        0.0791, 0.0822, 0.1171, 0.0937, 0.1425, 0.0921, 0.0715, 0.0661, 0.0653,\n",
      "        0.0850, 0.0868, 0.0594, 0.1995, 0.1064, 0.0816, 0.0530, 0.1300, 0.0533,\n",
      "        0.0730, 0.0949, 0.0724, 0.0721, 0.0850, 0.1932, 0.0736, 0.0407, 0.0440,\n",
      "        0.0870, 0.0699, 0.0903, 0.0628, 0.0690, 0.0818, 0.0744, 0.0400, 0.0718,\n",
      "        0.0424, 0.0716, 0.0917, 0.1286, 0.0474, 0.0999, 0.0796, 0.0492, 0.1092,\n",
      "        0.1024, 0.0642, 0.0807, 0.0749, 0.1602, 0.0614, 0.0931, 0.0610, 0.0981,\n",
      "        0.0783, 0.0804, 0.1842, 0.1601, 0.0771, 0.0594, 0.1125, 0.0977, 0.0837,\n",
      "        0.0741, 0.0833, 0.1497, 0.1092, 0.1177, 0.0839, 0.0501, 0.0556, 0.0723,\n",
      "        0.0625, 0.0611, 0.0629, 0.0538, 0.0918, 0.1735, 0.0722, 0.0701, 0.1086,\n",
      "        0.1250, 0.1116, 0.0569, 0.0870, 0.0601, 0.1172, 0.0552, 0.1370, 0.1153,\n",
      "        0.0907, 0.0940, 0.0643, 0.0890, 0.0764, 0.0733, 0.0754, 0.0521, 0.1159,\n",
      "        0.0567, 0.0885, 0.0649, 0.1062, 0.0774, 0.0853, 0.0625, 0.1724, 0.1159,\n",
      "        0.0895, 0.0491, 0.0834, 0.1055, 0.0745, 0.2121, 0.0665, 0.2003, 0.0725,\n",
      "        0.0566, 0.1515, 0.0952, 0.1013, 0.1347, 0.1050, 0.0483, 0.0436, 0.0712,\n",
      "        0.1236, 0.0647, 0.0582, 0.0678, 0.1024, 0.1847, 0.0713, 0.1453, 0.0913,\n",
      "        0.1019, 0.1030, 0.0795, 0.1312, 0.1329, 0.0715, 0.1200, 0.0704, 0.0925,\n",
      "        0.0577, 0.0722, 0.0774, 0.0787, 0.0609, 0.0976, 0.1110, 0.0791, 0.1342,\n",
      "        0.0730, 0.0878, 0.0918, 0.0768, 0.1725, 0.0847, 0.0736, 0.1109, 0.0575,\n",
      "        0.0571, 0.0562, 0.1435, 0.1087, 0.0447, 0.1605, 0.0635, 0.0576, 0.0969,\n",
      "        0.0723, 0.0606, 0.0850, 0.1047, 0.1313, 0.0669, 0.1512, 0.1452, 0.0924,\n",
      "        0.0895, 0.0592, 0.0803, 0.0805, 0.0643, 0.0746, 0.0838, 0.0967, 0.0477,\n",
      "        0.1478, 0.1189, 0.0778, 0.0734, 0.0925, 0.0699, 0.1142, 0.0930, 0.1206,\n",
      "        0.0600, 0.1469, 0.0912, 0.1047, 0.0977, 0.0803, 0.0884, 0.0697, 0.1274,\n",
      "        0.1013, 0.1378, 0.0761, 0.1477, 0.1035, 0.0639, 0.1261, 0.0590, 0.0652,\n",
      "        0.0491, 0.0763, 0.1865, 0.0615, 0.0780, 0.0862, 0.1497, 0.0712, 0.0949,\n",
      "        0.0755, 0.0673, 0.0989, 0.0821, 0.0637, 0.0632, 0.1164, 0.0763, 0.0657,\n",
      "        0.0602, 0.0701, 0.0720, 0.0703]), 'FP32-FP16 mean zero setting Error': '46717 / 2096896', 'FP32-FP16 mean std setting Error': '149415 / 2096896', 'FP32-BF16_mse': tensor([0.8633, 0.9862, 0.7356, 0.4607, 0.3809, 0.5293, 1.1372, 1.0331, 0.3376,\n",
      "        1.3582, 1.3696, 0.4467, 0.3175, 0.3969, 1.0796, 0.5049, 0.5993, 0.4501,\n",
      "        0.4323, 1.0385, 1.5610, 0.4571, 1.2700, 1.1037, 0.4253, 0.9107, 0.4197,\n",
      "        0.4421, 0.3826, 0.5713, 0.7258, 0.7572, 1.2028, 0.3648, 0.6660, 0.9242,\n",
      "        0.3907, 0.8642, 1.1728, 0.4412, 0.5752, 1.2468, 0.5946, 0.4434, 0.4341,\n",
      "        0.3672, 0.6733, 0.6563, 0.4668, 0.4076, 0.2836, 0.9629, 0.7103, 0.8147,\n",
      "        0.6087, 0.3732, 1.4187, 0.2840, 0.7343, 0.3502, 0.3563, 0.6199, 0.8119,\n",
      "        0.3491, 0.4289, 0.4262, 0.4598, 0.9984, 0.4842, 0.2764, 0.3218, 0.6081,\n",
      "        0.3645, 0.8648, 0.3483, 1.2118, 0.7688, 0.4316, 1.3012, 0.4116, 1.3202,\n",
      "        1.3247, 0.3454, 1.0481, 0.4678, 0.5785, 0.3126, 0.4135, 0.3714, 0.5560,\n",
      "        0.5292, 0.5343, 0.7304, 0.4347, 0.5914, 1.0605, 0.6506, 0.6997, 0.4624,\n",
      "        0.6818, 0.5049, 0.6024, 0.7348, 0.4979, 0.8656, 0.4973, 1.1788, 0.4704,\n",
      "        0.5712, 0.5503, 0.7323, 0.4724, 0.5078, 0.9154, 0.5054, 0.6183, 0.5183,\n",
      "        0.4763, 0.8118, 0.4555, 1.6157, 0.5653, 0.6957, 0.4554, 1.3677, 0.5504,\n",
      "        0.5472, 0.3839, 1.3257, 0.7918, 1.3172, 1.0248, 0.4942, 1.2891, 0.3978,\n",
      "        0.5417, 0.8365, 0.3563, 0.3008, 0.6584, 0.3336, 0.4484, 0.6196, 0.4464,\n",
      "        0.8559, 0.4971, 0.4626, 0.4464, 1.0760, 1.1873, 0.4872, 0.4390, 0.9532,\n",
      "        0.7407, 1.0492, 1.0711, 0.7514, 0.5069, 0.6787, 0.4610, 0.6208, 0.4120,\n",
      "        0.5101, 0.4210, 0.7995, 0.5050, 0.4302, 1.2334, 0.5256, 0.4671, 0.6822,\n",
      "        0.5907, 0.5006, 0.3272, 0.3369, 2.0681, 0.4323, 1.2481, 0.6995, 0.3782,\n",
      "        0.3252, 0.4592, 0.9972, 1.4268, 0.5588, 1.3337, 0.4580, 0.5358, 1.2733,\n",
      "        0.8276, 0.5558, 2.0533, 0.6896, 0.8434, 0.3879, 0.9952, 1.3751, 0.5652,\n",
      "        0.3410, 0.3497, 0.8092, 0.9422, 0.5229, 0.5176, 0.4104, 1.9100, 0.5785,\n",
      "        0.8372, 0.3367, 0.5719, 0.4026, 0.4433, 0.4551, 1.2320, 0.4947, 1.8018,\n",
      "        0.4641, 1.0829, 0.6509, 0.4940, 1.0121, 0.5435, 1.9867, 0.3796, 1.3530,\n",
      "        1.2383, 0.6480, 0.3259, 1.0393, 0.5647, 0.3511, 1.2852, 1.5181, 0.5611,\n",
      "        0.4432, 0.5677, 0.7852, 0.6841, 0.4031, 0.9687, 0.9902, 0.3854, 1.5705,\n",
      "        0.3944, 0.7931, 0.4291, 0.6632, 0.4974, 0.9862, 0.5003, 0.4299, 0.3844,\n",
      "        0.4262, 0.5043, 0.6113, 0.4692]), 'FP32-bf16_L_inf': tensor([ 4.8017,  3.8866,  6.0578,  9.7139,  9.4762, 11.2455,  7.9012,  9.7295,\n",
      "         6.6423,  2.5539,  5.5850,  9.4676, 10.1196,  8.4367,  8.3897,  9.7290,\n",
      "         8.3706, 10.7678,  9.9785,  4.8320,  4.2176, 12.6114,  4.1343,  4.4598,\n",
      "        11.6864,  7.7694, 10.3074, 12.6581,  9.2474, 13.3421,  7.5145,  6.7680,\n",
      "        14.8148,  7.2661,  5.7758,  6.1432,  8.6238,  7.1244,  5.5227, 10.9732,\n",
      "         6.9160,  2.6750,  6.5196,  9.4965,  8.0097, 11.9772,  8.4905, 10.3780,\n",
      "        11.3339,  9.3486,  9.9516,  9.1757,  6.9201,  9.2483, 10.4878,  8.2950,\n",
      "         6.0359, 14.5463,  7.1280,  9.7892, 10.3751, 12.8951,  5.0554, 12.3981,\n",
      "         9.9312, 12.6649, 10.8619,  2.2730, 11.3231, 10.2032,  7.0591, 11.0817,\n",
      "        14.3798, 13.9950, 10.9396, 10.4092,  7.7865,  9.5057,  3.3236, 11.1191,\n",
      "         6.3029,  5.8776,  7.6944, 13.8038, 12.8566,  6.8356,  8.6804, 10.0384,\n",
      "         5.8668, 11.9940, 13.2468, 12.4460, 12.2900,  8.1010, 13.8818,  7.9822,\n",
      "         9.6930, 13.1804,  8.2772, 10.9848, 16.1811, 12.1300, 10.9016, 10.7301,\n",
      "        14.7669, 12.4595,  4.0691,  5.2715, 14.1377, 12.7279,  8.7674, 13.3196,\n",
      "         9.2232, 10.1436, 10.1784, 11.5449,  9.8048, 11.3959,  8.4647,  9.0050,\n",
      "         2.0181,  8.7932,  7.1362, 10.2100,  5.3514, 18.0812, 15.7450,  9.1294,\n",
      "         5.6019,  3.8080,  9.3930,  1.8695, 11.1074,  1.5611,  8.4648, 12.2693,\n",
      "         4.0549, 11.7686, 12.0696,  5.9186, 13.0409, 12.0150, 10.3281, 11.8979,\n",
      "         2.3299, 10.8818,  6.6886,  9.0712,  7.7776,  9.3262, 10.6150, 19.9381,\n",
      "         5.0125, 10.2855,  8.7908,  6.6792,  4.5091,  6.7150, 10.6284,  8.9103,\n",
      "         6.6983,  8.1926,  8.1023, 10.2560,  8.8257, 11.6100,  9.4154,  3.8610,\n",
      "         3.5975,  9.8601, 15.2461,  7.9005, 12.2735, 10.6558,  8.2119,  2.9523,\n",
      "        10.2895,  6.9990,  7.2141,  7.9279,  6.7095,  8.3155,  5.9375,  1.9499,\n",
      "         8.7872,  7.2347, 10.3656, 10.1245, 13.3226,  9.4312, 12.6487,  5.1982,\n",
      "        15.9256,  8.9673,  6.8798,  3.5276,  8.3925,  9.5957, 10.8691,  7.5485,\n",
      "         9.2413,  8.4239, 12.6140, 12.1479, 10.6369,  3.3465,  8.4485, 10.4571,\n",
      "         9.3571,  6.6003,  9.8557, 14.7580, 12.1159,  3.9926, 14.2861,  1.9716,\n",
      "         9.8761,  5.6014, 11.1354, 16.2938,  4.7164,  8.8395,  7.9821,  9.0344,\n",
      "        10.2729,  4.1630,  9.8961,  8.8075,  4.5367, 13.0137,  8.2512,  5.6094,\n",
      "         5.3050,  9.1084,  9.2154, 10.5524,  6.4186,  9.1986, 10.1124,  5.2708,\n",
      "         3.8244,  7.4675,  3.4824,  9.8422,  6.6615,  6.8952, 15.4926, 13.3552,\n",
      "         8.2449,  8.0686,  8.7766,  9.4015,  9.9843, 13.6258, 10.0481, 13.6104]), 'FP32-BF16 mean zero setting Error': '207570 / 2096896', 'FP32-BF16 mean std setting Error': '429229 / 2096896'}\n",
      "idx :  15\n",
      "layer name :  conv5_x.1.residual_function.1\n",
      "chunk based sum result : 617/524288 = 0.11768341064453125%\n",
      "chunk based sum result : 20728/524288 = 3.95355224609375%\n",
      "chunk based sum result : 5047/524288 = 0.9626388549804688%\n",
      "chunk based sum result : 58579/524288 = 11.173057556152344%\n",
      "{'epoch': 0, 'layer': 'conv5_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0020, 0.0026, 0.0030, 0.0037, 0.0021, 0.0031, 0.0030, 0.0023, 0.0027,\n",
      "        0.0023, 0.0026, 0.0027, 0.0021, 0.0027, 0.0023, 0.0036, 0.0040, 0.0026,\n",
      "        0.0027, 0.0030, 0.0026, 0.0026, 0.0021, 0.0023, 0.0086, 0.0024, 0.0026,\n",
      "        0.0022, 0.0026, 0.0023, 0.0024, 0.0021, 0.0029, 0.0027, 0.0034, 0.0020,\n",
      "        0.0037, 0.0102, 0.0023, 0.0105, 0.0025, 0.0022, 0.0029, 0.0019, 0.0023,\n",
      "        0.0025, 0.0030, 0.0025, 0.0024, 0.0028, 0.0024, 0.0021, 0.0021, 0.0029,\n",
      "        0.0022, 0.0022, 0.0028, 0.0025, 0.0025, 0.0020, 0.0028, 0.0029, 0.0034,\n",
      "        0.0032, 0.0021, 0.0030, 0.0026, 0.0021, 0.0026, 0.0028, 0.0047, 0.0026,\n",
      "        0.0039, 0.0024, 0.0027, 0.0041, 0.0024, 0.0020, 0.0019, 0.0023, 0.0023,\n",
      "        0.0025, 0.0028, 0.0023, 0.0027, 0.0026, 0.0031, 0.0024, 0.0058, 0.0025,\n",
      "        0.0023, 0.0033, 0.0021, 0.0021, 0.0057, 0.0030, 0.0025, 0.0029, 0.0039,\n",
      "        0.0027, 0.0021, 0.0025, 0.0025, 0.0022, 0.0026, 0.0022, 0.0023, 0.0026,\n",
      "        0.0023, 0.0029, 0.0020, 0.0054, 0.0024, 0.0025, 0.0027, 0.0018, 0.0026,\n",
      "        0.0021, 0.0021, 0.0028, 0.0026, 0.0027, 0.0024, 0.0028, 0.0030, 0.0026,\n",
      "        0.0027, 0.0021, 0.0026, 0.0028, 0.0025, 0.0026, 0.0030, 0.0057, 0.0025,\n",
      "        0.0021, 0.0030, 0.0024, 0.0024, 0.0038, 0.0026, 0.0046, 0.0026, 0.0024,\n",
      "        0.0031, 0.0031, 0.0025, 0.0023, 0.0025, 0.0022, 0.0029, 0.0026, 0.0025,\n",
      "        0.0023, 0.0062, 0.0020, 0.0028, 0.0035, 0.0029, 0.0019, 0.0031, 0.0027,\n",
      "        0.0025, 0.0026, 0.0031, 0.0023, 0.0023, 0.0025, 0.0041, 0.0028, 0.0023,\n",
      "        0.0029, 0.0023, 0.0025, 0.0028, 0.0028, 0.0030, 0.0038, 0.0023, 0.0034,\n",
      "        0.0032, 0.0023, 0.0019, 0.0028, 0.0028, 0.0029, 0.0031, 0.0029, 0.0025,\n",
      "        0.0027, 0.0023, 0.0022, 0.0029, 0.0025, 0.0027, 0.0022, 0.0034, 0.0020,\n",
      "        0.0022, 0.0025, 0.0023, 0.0031, 0.0029, 0.0023, 0.0021, 0.0026, 0.0018,\n",
      "        0.0022, 0.0026, 0.0024, 0.0022, 0.0030, 0.0024, 0.0020, 0.0023, 0.0023,\n",
      "        0.0043, 0.0023, 0.0025, 0.0027, 0.0060, 0.0022, 0.0067, 0.0025, 0.0029,\n",
      "        0.0025, 0.0041, 0.0021, 0.0031, 0.0149, 0.0028, 0.0025, 0.0027, 0.0028,\n",
      "        0.0024, 0.0049, 0.0026, 0.0088, 0.0024, 0.0024, 0.0021, 0.0027, 0.0032,\n",
      "        0.0039, 0.0024, 0.0022, 0.0026, 0.0026, 0.0025, 0.0025, 0.0025, 0.0029,\n",
      "        0.0030, 0.0024, 0.0023, 0.0023, 0.0024, 0.0063, 0.0025, 0.0016, 0.0022,\n",
      "        0.0051, 0.0044, 0.0025, 0.0022, 0.0026, 0.0025, 0.0031, 0.0027, 0.0058,\n",
      "        0.0049, 0.0026, 0.0027, 0.0024, 0.0024, 0.0025, 0.0026, 0.0022, 0.0025,\n",
      "        0.0030, 0.0027, 0.0027, 0.0023, 0.0026, 0.0020, 0.0024, 0.0022, 0.0027,\n",
      "        0.0039, 0.0025, 0.0024, 0.0022, 0.0031, 0.0034, 0.0037, 0.0024, 0.0018,\n",
      "        0.0023, 0.0023, 0.0042, 0.0024, 0.0022, 0.0018, 0.0024, 0.0028, 0.0026,\n",
      "        0.0028, 0.0018, 0.0027, 0.0024, 0.0026, 0.0025, 0.0058, 0.0036, 0.0028,\n",
      "        0.0033, 0.0034, 0.0023, 0.0023, 0.0020, 0.0022, 0.0025, 0.0024, 0.0020,\n",
      "        0.0062, 0.0023, 0.0021, 0.0026, 0.0025, 0.0021, 0.0040, 0.0064, 0.0023,\n",
      "        0.0030, 0.0021, 0.0024, 0.0024, 0.0022, 0.0027, 0.0028, 0.0018, 0.0023,\n",
      "        0.0026, 0.0024, 0.0023, 0.0024, 0.0020, 0.0026, 0.0026, 0.0023, 0.0022,\n",
      "        0.0027, 0.0026, 0.0023, 0.0021, 0.0021, 0.0025, 0.0027, 0.0031, 0.0023,\n",
      "        0.0022, 0.0034, 0.0024, 0.0029, 0.0033, 0.0030, 0.0026, 0.0026, 0.0023,\n",
      "        0.0055, 0.0040, 0.0023, 0.0029, 0.0031, 0.0026, 0.0026, 0.0024, 0.0026,\n",
      "        0.0031, 0.0026, 0.0024, 0.0024, 0.0027, 0.0035, 0.0028, 0.0022, 0.0024,\n",
      "        0.0035, 0.0024, 0.0025, 0.0021, 0.0029, 0.0022, 0.0028, 0.0021, 0.0024,\n",
      "        0.0028, 0.0031, 0.0028, 0.0110, 0.0027, 0.0021, 0.0021, 0.0024, 0.0021,\n",
      "        0.0021, 0.0031, 0.0031, 0.0029, 0.0027, 0.0028, 0.0067, 0.0029, 0.0025,\n",
      "        0.0032, 0.0025, 0.0027, 0.0022, 0.0019, 0.0022, 0.0027, 0.0025, 0.0020,\n",
      "        0.0036, 0.0023, 0.0027, 0.0022, 0.0047, 0.0026, 0.0027, 0.0023, 0.0028,\n",
      "        0.0038, 0.0028, 0.0065, 0.0021, 0.0023, 0.0022, 0.0024, 0.0025, 0.0021,\n",
      "        0.0028, 0.0027, 0.0028, 0.0018, 0.0023, 0.0052, 0.0043, 0.0132, 0.0022,\n",
      "        0.0021, 0.0039, 0.0026, 0.0024, 0.0022, 0.0023, 0.0026, 0.0023, 0.0023,\n",
      "        0.0024, 0.0024, 0.0022, 0.0024, 0.0023, 0.0019, 0.0021, 0.0028, 0.0027,\n",
      "        0.0050, 0.0039, 0.0023, 0.0022, 0.0027, 0.0032, 0.0026, 0.0019, 0.0031,\n",
      "        0.0026, 0.0023, 0.0022, 0.0028, 0.0019, 0.0031, 0.0030, 0.0101, 0.0021,\n",
      "        0.0019, 0.0020, 0.0023, 0.0028, 0.0022, 0.0026, 0.0024, 0.0030, 0.0021,\n",
      "        0.0025, 0.0025, 0.0023, 0.0048, 0.0024, 0.0026, 0.0023, 0.0022, 0.0034,\n",
      "        0.0027, 0.0023, 0.0036, 0.0021, 0.0025, 0.0028, 0.0023, 0.0025]), 'FP32-FP16_L_inf': tensor([0.0485, 0.0567, 0.0879, 0.0650, 0.0526, 0.0595, 0.0722, 0.0587, 0.0531,\n",
      "        0.1755, 0.0448, 0.0627, 0.0552, 0.0614, 0.0806, 0.0814, 0.0935, 0.0697,\n",
      "        0.0604, 0.0540, 0.0421, 0.1406, 0.0502, 0.0803, 0.0937, 0.0454, 0.0582,\n",
      "        0.0500, 0.0497, 0.0329, 0.0534, 0.0367, 0.0783, 0.0555, 0.0845, 0.0536,\n",
      "        0.0741, 0.1330, 0.0425, 0.0803, 0.0912, 0.0520, 0.0484, 0.0450, 0.0726,\n",
      "        0.0270, 0.0701, 0.0922, 0.0498, 0.0921, 0.1332, 0.0369, 0.0811, 0.0506,\n",
      "        0.0685, 0.0351, 0.1068, 0.1182, 0.0563, 0.0442, 0.0316, 0.0631, 0.0413,\n",
      "        0.0648, 0.0385, 0.0598, 0.0513, 0.0371, 0.0507, 0.0985, 0.1530, 0.0363,\n",
      "        0.1396, 0.0358, 0.0601, 0.0802, 0.0417, 0.0360, 0.0269, 0.0338, 0.0553,\n",
      "        0.0569, 0.0848, 0.0592, 0.0665, 0.0431, 0.1316, 0.0523, 0.0761, 0.0414,\n",
      "        0.0727, 0.0840, 0.0683, 0.0936, 0.0971, 0.0772, 0.0553, 0.0762, 0.0913,\n",
      "        0.0719, 0.0669, 0.0367, 0.0758, 0.0471, 0.0532, 0.0529, 0.0494, 0.0692,\n",
      "        0.0558, 0.0415, 0.0448, 0.0818, 0.0569, 0.0353, 0.0609, 0.0469, 0.0338,\n",
      "        0.0524, 0.1036, 0.0349, 0.0545, 0.0518, 0.0420, 0.0509, 0.0479, 0.0695,\n",
      "        0.0737, 0.0787, 0.0429, 0.0568, 0.0576, 0.0479, 0.0539, 0.0917, 0.0799,\n",
      "        0.1010, 0.0405, 0.0510, 0.0507, 0.0777, 0.0698, 0.0675, 0.0753, 0.0475,\n",
      "        0.0604, 0.0747, 0.0513, 0.0448, 0.0569, 0.0360, 0.0625, 0.0447, 0.0379,\n",
      "        0.0572, 0.0855, 0.0296, 0.0530, 0.0700, 0.0403, 0.0535, 0.0490, 0.0671,\n",
      "        0.0515, 0.1290, 0.0925, 0.0507, 0.0633, 0.0541, 0.0671, 0.0525, 0.0506,\n",
      "        0.0724, 0.0702, 0.0399, 0.0840, 0.0570, 0.0514, 0.0866, 0.0407, 0.0615,\n",
      "        0.0545, 0.0600, 0.0394, 0.0526, 0.0505, 0.0490, 0.0815, 0.0615, 0.0829,\n",
      "        0.0579, 0.1048, 0.0522, 0.0537, 0.0553, 0.0663, 0.0700, 0.1030, 0.0527,\n",
      "        0.0762, 0.0693, 0.0275, 0.0663, 0.0524, 0.0349, 0.0610, 0.0635, 0.0498,\n",
      "        0.0892, 0.0496, 0.0490, 0.0742, 0.1158, 0.0391, 0.0581, 0.0471, 0.0680,\n",
      "        0.1118, 0.0469, 0.0411, 0.0465, 0.1048, 0.0515, 0.0731, 0.0760, 0.0939,\n",
      "        0.0874, 0.0942, 0.0675, 0.0964, 0.0883, 0.0549, 0.0530, 0.0718, 0.0533,\n",
      "        0.0615, 0.0978, 0.0626, 0.0798, 0.0425, 0.0675, 0.0353, 0.0560, 0.0824,\n",
      "        0.0732, 0.0684, 0.0281, 0.0629, 0.0702, 0.0531, 0.0761, 0.0415, 0.0997,\n",
      "        0.0858, 0.0722, 0.0390, 0.1725, 0.0718, 0.1239, 0.0857, 0.0229, 0.0592,\n",
      "        0.0692, 0.1077, 0.0491, 0.0463, 0.0814, 0.0466, 0.0664, 0.0613, 0.0798,\n",
      "        0.0820, 0.0564, 0.0674, 0.0736, 0.0516, 0.0575, 0.0682, 0.0506, 0.0601,\n",
      "        0.0851, 0.0731, 0.0524, 0.0564, 0.1320, 0.0357, 0.0370, 0.0275, 0.0818,\n",
      "        0.0463, 0.0397, 0.0591, 0.0439, 0.0993, 0.0563, 0.0680, 0.0730, 0.0414,\n",
      "        0.0400, 0.0533, 0.1506, 0.0552, 0.0555, 0.0348, 0.0399, 0.0576, 0.0373,\n",
      "        0.0811, 0.0368, 0.0429, 0.0712, 0.0660, 0.0678, 0.1175, 0.0560, 0.0383,\n",
      "        0.0623, 0.1209, 0.0411, 0.0410, 0.0867, 0.0376, 0.0618, 0.0396, 0.0726,\n",
      "        0.1280, 0.0450, 0.0427, 0.1031, 0.0410, 0.0481, 0.0464, 0.0823, 0.0796,\n",
      "        0.0507, 0.0630, 0.0536, 0.0578, 0.0344, 0.0633, 0.0977, 0.0397, 0.0899,\n",
      "        0.0766, 0.0440, 0.0741, 0.0441, 0.0478, 0.0569, 0.0575, 0.0544, 0.0491,\n",
      "        0.0854, 0.0688, 0.1053, 0.0340, 0.0868, 0.0417, 0.0830, 0.0846, 0.0413,\n",
      "        0.0472, 0.0838, 0.0834, 0.0528, 0.0555, 0.0916, 0.0453, 0.0673, 0.0571,\n",
      "        0.0739, 0.1049, 0.0535, 0.0493, 0.0569, 0.0516, 0.0663, 0.0544, 0.1031,\n",
      "        0.0683, 0.0718, 0.0479, 0.0875, 0.0820, 0.0669, 0.0563, 0.0487, 0.0387,\n",
      "        0.0726, 0.0504, 0.0673, 0.0769, 0.0857, 0.0539, 0.0795, 0.0909, 0.0625,\n",
      "        0.0587, 0.0654, 0.0568, 0.1047, 0.0480, 0.0614, 0.0605, 0.0398, 0.0781,\n",
      "        0.0983, 0.0786, 0.0711, 0.0520, 0.0462, 0.0559, 0.1009, 0.0681, 0.0383,\n",
      "        0.0555, 0.0350, 0.0471, 0.0521, 0.0878, 0.0407, 0.0766, 0.0492, 0.0374,\n",
      "        0.0837, 0.0340, 0.0696, 0.0533, 0.0863, 0.0569, 0.0484, 0.0430, 0.0654,\n",
      "        0.0749, 0.0648, 0.0994, 0.0456, 0.0628, 0.0400, 0.0417, 0.0619, 0.0993,\n",
      "        0.0494, 0.0722, 0.0678, 0.0435, 0.0347, 0.0472, 0.0533, 0.1338, 0.0393,\n",
      "        0.0704, 0.0750, 0.1100, 0.0606, 0.0743, 0.0490, 0.0526, 0.0680, 0.0617,\n",
      "        0.0755, 0.0680, 0.1008, 0.0456, 0.0383, 0.0356, 0.0447, 0.0652, 0.0453,\n",
      "        0.0604, 0.0614, 0.0422, 0.0372, 0.0498, 0.0548, 0.0612, 0.0305, 0.0857,\n",
      "        0.0518, 0.0529, 0.0478, 0.0480, 0.0552, 0.0651, 0.0698, 0.0967, 0.0657,\n",
      "        0.0457, 0.0267, 0.0424, 0.0674, 0.0716, 0.0928, 0.0352, 0.0547, 0.0335,\n",
      "        0.0348, 0.0618, 0.0440, 0.0722, 0.0494, 0.0546, 0.0334, 0.0440, 0.0994,\n",
      "        0.0578, 0.0354, 0.0787, 0.0277, 0.0539, 0.0580, 0.0629, 0.0604]), 'FP32-FP16 mean zero setting Error': '82410 / 1048064', 'FP32-FP16 mean std setting Error': '220906 / 1048064', 'FP32-BF16_mse': tensor([0.2243, 0.2154, 0.2906, 0.4894, 0.2082, 0.3094, 0.2499, 0.1911, 0.2294,\n",
      "        0.1667, 0.2155, 0.1773, 0.2778, 0.2059, 0.2010, 0.5411, 0.4477, 0.2279,\n",
      "        0.2455, 0.3818, 0.2251, 0.2607, 0.3164, 0.2412, 0.9180, 0.2666, 0.2400,\n",
      "        0.3664, 0.2678, 0.2756, 0.2192, 0.2668, 0.2854, 0.3940, 0.3329, 0.2015,\n",
      "        0.5087, 0.9541, 0.2827, 1.1290, 0.2147, 0.2216, 0.2756, 0.2113, 0.2695,\n",
      "        0.4508, 0.2215, 0.1743, 0.2649, 0.3029, 0.2064, 0.2109, 0.2506, 0.2367,\n",
      "        0.1727, 0.2459, 0.2450, 0.2289, 0.1959, 0.2161, 0.2887, 0.2836, 0.5568,\n",
      "        0.1967, 0.2201, 0.4191, 0.2223, 0.3474, 0.2323, 0.2866, 0.5490, 0.2188,\n",
      "        0.4051, 0.2527, 0.3053, 0.5418, 0.2825, 0.1912, 0.2560, 0.3219, 0.2378,\n",
      "        0.2092, 0.3037, 0.1983, 0.2499, 0.3576, 0.2879, 0.2543, 0.6137, 0.2820,\n",
      "        0.1814, 0.3638, 0.2047, 0.2128, 0.5162, 0.2195, 0.2402, 0.1784, 0.3912,\n",
      "        0.2201, 0.1899, 0.2488, 0.2220, 0.2342, 0.2920, 0.2075, 0.1689, 0.2597,\n",
      "        0.2610, 0.3683, 0.2652, 0.7623, 0.3051, 0.2402, 0.2595, 0.2292, 0.3488,\n",
      "        0.2409, 0.2995, 0.2952, 0.3522, 0.3375, 0.2433, 0.2362, 0.2328, 0.4218,\n",
      "        0.2388, 0.2283, 0.2480, 0.2185, 0.3658, 0.2803, 0.3864, 0.7525, 0.3038,\n",
      "        0.1610, 0.4031, 0.1828, 0.3383, 0.4594, 0.2140, 0.5378, 0.2725, 0.2827,\n",
      "        0.3929, 0.4179, 0.2334, 0.2344, 0.3357, 0.2723, 0.2907, 0.2710, 0.4157,\n",
      "        0.2450, 0.8280, 0.2564, 0.1983, 0.5127, 0.2545, 0.1868, 0.2945, 0.4130,\n",
      "        0.2143, 0.1648, 0.4847, 0.3222, 0.1907, 0.2810, 0.6451, 0.3229, 0.3828,\n",
      "        0.3895, 0.2114, 0.3572, 0.2781, 0.4971, 0.3564, 0.5244, 0.3053, 0.4557,\n",
      "        0.5140, 0.2374, 0.2009, 0.3970, 0.4889, 0.2721, 0.3247, 0.2743, 0.2813,\n",
      "        0.2334, 0.2078, 0.2158, 0.2304, 0.1963, 0.2532, 0.1961, 0.2432, 0.3411,\n",
      "        0.3941, 0.2169, 0.3919, 0.3762, 0.4069, 0.2737, 0.2638, 0.3316, 0.1810,\n",
      "        0.1921, 0.4402, 0.2739, 0.1946, 0.2323, 0.1984, 0.2917, 0.2206, 0.1832,\n",
      "        0.4486, 0.2030, 0.2665, 0.3435, 0.5981, 0.3121, 0.7621, 0.2148, 0.2183,\n",
      "        0.2410, 0.5737, 0.2326, 0.2902, 1.2279, 0.2782, 0.2104, 0.1899, 0.2624,\n",
      "        0.2258, 0.6459, 0.2295, 0.6729, 0.2738, 0.2177, 0.2279, 0.2867, 0.5245,\n",
      "        0.6255, 0.2893, 0.2501, 0.3133, 0.2927, 0.2362, 0.3365, 0.2441, 0.1989,\n",
      "        0.3535, 0.2689, 0.2112, 0.1863, 0.2405, 0.6060, 0.2503, 0.2368, 0.1805,\n",
      "        0.7727, 0.5329, 0.2333, 0.2945, 0.2920, 0.2315, 0.2164, 0.2971, 0.7159,\n",
      "        0.5568, 0.2465, 0.2863, 0.1710, 0.1957, 0.2096, 0.2549, 0.2656, 0.2910,\n",
      "        0.4313, 0.4122, 0.2254, 0.2681, 0.1701, 0.2603, 0.2150, 0.2669, 0.2399,\n",
      "        0.7396, 0.2415, 0.2456, 0.2325, 0.1787, 0.4027, 0.3268, 0.1975, 0.2202,\n",
      "        0.3599, 0.2415, 0.4248, 0.4042, 0.2135, 0.2337, 0.2009, 0.2716, 0.2542,\n",
      "        0.3232, 0.2565, 0.2533, 0.2596, 0.2637, 0.2481, 0.5906, 0.2257, 0.4067,\n",
      "        0.4041, 0.3314, 0.2440, 0.2326, 0.2057, 0.3135, 0.1600, 0.4384, 0.4395,\n",
      "        0.5140, 0.2957, 0.1915, 0.1874, 0.2668, 0.2231, 0.9367, 0.6183, 0.3007,\n",
      "        0.3415, 0.3248, 0.3830, 0.2888, 0.2250, 0.4327, 0.1993, 0.2302, 0.2542,\n",
      "        0.3594, 0.2638, 0.3970, 0.2497, 0.2367, 0.2083, 0.2043, 0.2716, 0.2215,\n",
      "        0.2508, 0.2495, 0.1590, 0.2187, 0.1923, 0.2437, 0.2117, 0.2248, 0.2520,\n",
      "        0.2223, 0.4990, 0.2560, 0.2504, 0.5829, 0.2720, 0.2126, 0.1837, 0.3228,\n",
      "        0.6856, 0.5922, 0.2319, 0.2605, 0.3530, 0.2797, 0.3327, 0.1807, 0.2756,\n",
      "        0.4580, 0.4853, 0.2174, 0.1853, 0.2671, 0.4352, 0.2235, 0.2666, 0.2693,\n",
      "        0.4663, 0.1972, 0.2243, 0.2328, 0.1936, 0.2365, 0.3372, 0.2343, 0.3016,\n",
      "        0.4704, 0.5095, 0.2382, 1.2050, 0.2025, 0.1859, 0.2503, 0.2300, 0.1850,\n",
      "        0.1746, 0.2225, 0.1891, 0.5355, 0.3098, 0.3445, 0.7148, 0.2395, 0.2413,\n",
      "        0.3651, 0.2710, 0.2267, 0.2455, 0.1794, 0.2005, 0.4478, 0.4059, 0.3046,\n",
      "        0.4960, 0.2840, 0.4474, 0.3392, 0.5547, 0.3038, 0.4357, 0.3279, 0.2082,\n",
      "        0.6349, 0.2507, 0.6351, 0.2080, 0.2356, 0.2592, 0.2169, 0.3543, 0.1797,\n",
      "        0.2636, 0.2270, 0.3516, 0.2340, 0.2940, 0.7086, 0.7003, 0.7951, 0.2250,\n",
      "        0.1428, 0.4381, 0.3004, 0.4136, 0.3193, 0.2116, 0.4206, 0.1661, 0.2677,\n",
      "        0.2387, 0.4056, 0.2326, 0.3022, 0.2649, 0.1885, 0.2084, 0.3702, 0.2449,\n",
      "        0.6896, 0.5379, 0.2488, 0.2156, 0.2942, 0.4204, 0.2386, 0.2803, 0.2123,\n",
      "        0.1949, 0.3258, 0.2461, 0.2473, 0.2082, 0.3538, 0.2461, 0.8565, 0.2007,\n",
      "        0.2454, 0.2802, 0.2162, 0.2217, 0.1542, 0.1857, 0.2640, 0.4027, 0.2906,\n",
      "        0.2510, 0.2652, 0.2737, 0.6074, 0.1846, 0.2091, 0.3153, 0.1902, 0.2951,\n",
      "        0.2722, 0.2867, 0.5850, 0.2885, 0.3097, 0.2341, 0.2331, 0.2186]), 'FP32-bf16_L_inf': tensor([ 5.5559,  4.9416,  4.5119,  4.1417,  5.0087,  5.9146,  5.8481,  5.0071,\n",
      "         4.2952, 12.6608,  3.6296,  4.1058,  7.0756,  4.9758,  6.6037,  4.3158,\n",
      "         4.4268,  6.1466,  5.4356,  3.7168,  3.7576, 14.3258,  4.8738,  8.7122,\n",
      "         3.2302,  5.0511,  4.2674,  4.6044,  4.0107,  3.8876,  4.6635,  3.7163,\n",
      "         5.6579,  4.6787,  5.0811,  3.9022,  4.6431,  2.7241,  4.7652,  2.5362,\n",
      "         5.3077,  3.7225,  4.8372,  3.2712,  7.9089,  3.2240,  5.3220,  6.2329,\n",
      "         5.1405,  4.6204, 11.5523,  3.7289,  9.1690,  3.6510,  4.8611,  3.5328,\n",
      "         6.8033, 10.6845,  4.4071,  4.9498,  3.6381,  5.0505,  3.2191,  3.8838,\n",
      "         4.3803,  4.4945,  3.7155,  3.5532,  4.3143,  7.1892,  4.7155,  3.1704,\n",
      "         5.8255,  3.7459,  5.4690,  3.8015,  4.4094,  3.5031,  3.7090,  4.8513,\n",
      "         6.0884,  4.8155,  7.5157,  5.0135,  3.7004,  4.3916,  6.7677,  5.6246,\n",
      "         3.0649,  3.8416,  5.6469,  4.9015,  6.7999,  9.4635,  2.6292,  5.7865,\n",
      "         5.0961,  4.7625,  4.0537,  5.7396,  6.1201,  3.4549,  6.4247,  5.0971,\n",
      "         5.5373,  4.7889,  3.5558,  6.7676,  5.9296,  3.4985,  4.1527,  3.5201,\n",
      "         4.0713,  3.0924,  4.8718,  5.8255,  3.8017,  6.0092,  9.4814,  3.6234,\n",
      "         4.9700,  5.6148,  4.5006,  4.5537,  3.9223,  5.2036,  6.8484,  8.8522,\n",
      "         4.0490,  3.1449,  7.4168,  5.2674,  4.5335,  4.5534,  3.9011,  7.6361,\n",
      "         5.0949,  3.9977,  5.2448,  3.5529,  5.5000,  3.1500,  4.8020,  4.7304,\n",
      "         4.3919,  5.7511,  4.8180,  4.4430,  4.7070,  4.6041,  5.9499,  4.7490,\n",
      "         4.7591,  6.0577,  2.8159,  3.7348,  3.6431,  4.4616,  3.5509,  5.7346,\n",
      "         4.7282,  4.0377,  4.6064,  8.1847,  4.2360,  4.4454,  5.3616,  4.7746,\n",
      "         4.7736,  4.1433,  4.7484,  6.1150,  6.2652,  4.4688,  5.2633,  3.7983,\n",
      "         3.5051,  5.6837,  3.7541,  4.2961,  5.2126,  6.0105,  4.1111,  5.3891,\n",
      "         5.2077,  3.9181,  5.2724,  3.8912,  7.2759,  5.1992,  9.5902,  4.8808,\n",
      "         4.3033,  4.3205,  6.0145,  6.2169,  7.4590,  7.0266,  5.3337,  5.8725,\n",
      "         3.4798,  4.8120,  5.3569,  3.7374,  7.2666,  4.7349,  4.4692,  7.6493,\n",
      "         4.7102,  4.3779,  6.8536,  8.6314,  3.2277,  7.3905,  4.6138,  5.3239,\n",
      "         5.1571,  4.1820,  4.4123,  3.8515,  3.3679,  4.7856,  3.1442,  6.6097,\n",
      "         6.6146,  8.1363,  4.8099,  5.7370,  3.8769,  1.4852,  5.3676,  4.5775,\n",
      "         4.5797,  4.5507,  5.7380,  4.0201,  5.0952,  2.2113,  4.9176,  6.3157,\n",
      "         3.3957,  4.3104,  5.6537,  4.0212,  7.8578,  2.9484,  5.3812,  5.4512,\n",
      "         5.4426,  4.5727,  3.4688,  6.8217,  4.5655,  7.0635,  3.4141, 14.0611,\n",
      "         6.9323,  3.7330,  6.2627,  3.2273,  4.6457,  3.2644,  6.4946,  4.6338,\n",
      "         4.4897,  6.7519,  4.2759,  4.7325,  6.6891,  3.9535,  3.7351,  5.5657,\n",
      "         6.0838,  5.1830,  4.1151,  5.0105,  6.0184,  6.1550,  5.1226,  4.9847,\n",
      "         4.4743,  4.5160,  6.6423,  8.4621,  3.9616,  3.4119,  3.0887,  7.2228,\n",
      "         4.3009,  3.7517,  5.0147,  4.8297,  4.4018,  3.5518,  5.9210,  6.1083,\n",
      "         5.0923,  4.8126,  3.9543,  4.5636,  5.4356,  5.2040,  4.8932,  3.5501,\n",
      "         5.2508,  3.8193,  5.7940,  3.6166,  4.2009,  6.6590,  6.6794,  5.4116,\n",
      "         4.4663,  3.6048,  4.5509,  3.3189,  8.0368,  4.2711,  3.4781,  8.6378,\n",
      "         4.0252,  3.8698,  3.9257,  8.0137,  3.3560,  5.8553,  3.9225,  7.6249,\n",
      "         4.3662,  5.0814,  4.0547,  3.3606,  6.0803,  4.0761,  6.8984,  6.0118,\n",
      "         5.9896,  3.7345,  5.9856,  7.0480,  3.9937,  8.2138,  5.6405,  4.6892,\n",
      "         5.6975,  4.6711,  5.7390,  4.7381,  4.4131,  5.2323,  4.5064,  7.4618,\n",
      "         6.6940,  7.2284,  3.7218,  8.0926,  4.0315,  6.7145,  6.1680,  4.4728,\n",
      "         4.8090,  4.5340,  7.2258,  4.7789,  4.5630,  5.1293,  3.8345,  4.1409,\n",
      "         4.8495,  3.6503,  7.0440,  5.1757,  4.4811,  4.0676,  4.0606,  3.3217,\n",
      "         4.0658,  8.0767,  6.0933,  4.5564,  4.4319,  6.7950,  8.1942,  3.5256,\n",
      "         4.0582,  5.8378,  4.7230,  4.8590,  4.4733,  6.1157,  8.0569,  5.6376,\n",
      "         6.2788,  5.6480, 10.0952,  4.8470,  6.3042,  4.4557,  4.9954,  2.5705,\n",
      "         3.7509,  5.3831,  7.0573,  4.0389,  6.8958,  7.5176,  4.2630,  4.5661,\n",
      "         3.5842,  4.2196,  4.6335,  4.0124,  5.2728,  3.6223,  4.2635,  3.8974,\n",
      "         3.9637,  6.0721,  8.3296,  3.6468,  5.7675,  5.0256,  4.6243,  4.7465,\n",
      "         4.2685,  5.4355,  5.1682,  3.9897,  4.3208,  4.4744,  5.4503,  5.0152,\n",
      "         4.7665,  4.9294,  3.9847,  4.4142,  5.7420,  5.0126,  3.9111,  5.2081,\n",
      "         8.9752,  3.4965,  6.3543,  4.9183,  4.5180,  4.2008,  3.1087,  4.2861,\n",
      "         1.4225,  4.0642,  4.5119,  4.3149,  8.3459,  6.0594,  6.0400,  4.3893,\n",
      "         4.2394,  4.3228,  7.3656,  7.5910,  7.6621,  9.8006,  4.1378,  4.4099,\n",
      "         3.6317,  4.2092,  5.9223,  4.2443,  3.3879,  4.3725,  4.4050,  3.7754,\n",
      "         4.6962,  4.5245,  4.9557,  3.6861,  5.7825,  3.7187,  4.7635,  4.7294,\n",
      "         3.8320,  6.1765,  4.9716,  5.6520,  1.5440,  6.3821,  5.6517,  3.3401,\n",
      "         4.0138,  5.4588,  4.9262,  6.6259,  3.7570,  4.4546,  4.7716,  3.5810,\n",
      "         6.7340,  5.2976,  4.3800,  3.7698,  4.5318,  4.8189,  3.7284,  4.9699,\n",
      "         4.9153,  3.9865,  5.2755,  3.4089,  3.9479,  3.1425,  5.5889,  5.0388]), 'FP32-BF16 mean zero setting Error': '338871 / 1048064', 'FP32-BF16 mean std setting Error': '491207 / 1048064'}\n",
      "30\n",
      "idx :  3\n",
      "layer name :  conv2_x.1.residual_function.1\n",
      "chunk based sum result : 187180/8323072 = 2.248929262161255%\n",
      "chunk based sum result : 1519086/8323072 = 18.25150489807129%\n",
      "chunk based sum result : 1601090/8323072 = 19.236766815185547%\n",
      "chunk based sum result : 3883713/8323072 = 46.66201400756836%\n",
      "{'epoch': 30, 'layer': 'conv2_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0026, 0.0031, 0.0065, 0.0023, 0.0064, 0.0071, 0.0059, 0.0100, 0.0048,\n",
      "        0.0056, 0.0024, 0.0025, 0.0148, 0.0039, 0.0076, 0.0070, 0.0026, 0.0058,\n",
      "        0.0030, 0.0077, 0.0142, 0.0071, 0.0062, 0.0073, 0.0128, 0.0032, 0.0025,\n",
      "        0.0025, 0.0021, 0.0021, 0.0041, 0.0034, 0.0050, 0.0036, 0.0037, 0.0035,\n",
      "        0.0070, 0.0069, 0.0074, 0.0023, 0.0085, 0.0027, 0.0054, 0.0086, 0.0039,\n",
      "        0.0060, 0.0040, 0.0088, 0.0037, 0.0041, 0.0042, 0.0020, 0.0019, 0.0032,\n",
      "        0.0031, 0.0083, 0.0032, 0.0015, 0.0030, 0.0054, 0.0032, 0.0031, 0.0050,\n",
      "        0.0048]), 'FP32-FP16_L_inf': tensor([0.0813, 0.0889, 0.1838, 0.0751, 0.3271, 0.1420, 0.2361, 0.1460, 0.1507,\n",
      "        0.2673, 0.0822, 0.1071, 0.4578, 0.1248, 0.1940, 0.1619, 0.0872, 0.2616,\n",
      "        0.0672, 0.1221, 0.1771, 0.1747, 0.1346, 0.1373, 0.1075, 0.1723, 0.1288,\n",
      "        0.0509, 0.0890, 0.0507, 0.2645, 0.0845, 0.1046, 0.1440, 0.1199, 0.0939,\n",
      "        0.1972, 0.1709, 0.0907, 0.0967, 0.1688, 0.0813, 0.2525, 0.2843, 0.1071,\n",
      "        0.1673, 0.1287, 0.2484, 0.0833, 0.0760, 0.1404, 0.0541, 0.0340, 0.1247,\n",
      "        0.0968, 0.1204, 0.1467, 0.0363, 0.1261, 0.1297, 0.0558, 0.0816, 0.1017,\n",
      "        0.1284]), 'FP32-FP16 mean zero setting Error': '196179 / 8388544', 'FP32-FP16 mean std setting Error': '1531751 / 8388544', 'FP32-BF16_mse': tensor([1.1134, 1.1717, 2.7535, 0.9686, 0.9894, 2.2079, 1.6315, 2.5901, 1.5050,\n",
      "        1.7896, 0.9428, 0.6873, 0.3337, 1.3279, 1.9530, 3.3115, 0.8984, 0.9138,\n",
      "        1.1017, 2.3192, 1.9659, 2.6224, 1.5071, 2.1142, 1.8885, 0.5775, 0.6967,\n",
      "        1.3651, 0.9832, 0.8604, 0.4810, 1.2559, 1.3047, 1.0968, 1.1419, 1.3236,\n",
      "        1.1355, 1.7682, 2.2548, 0.8028, 2.3769, 0.9601, 0.9062, 1.2248, 0.7223,\n",
      "        1.4155, 1.2538, 2.2127, 1.1148, 1.4769, 1.3474, 0.9478, 0.8717, 0.7668,\n",
      "        1.1509, 3.2456, 0.8494, 1.0258, 0.6320, 1.0883, 1.5497, 1.3673, 1.8063,\n",
      "        1.4937]), 'FP32-bf16_L_inf': tensor([31.2292, 32.0924, 13.7225, 32.5514, 23.8308, 16.3082, 27.6916,  7.3938,\n",
      "        34.2025, 34.3287, 27.8290, 30.1230,  5.3237, 31.6217, 18.8967,  9.5963,\n",
      "        28.5219, 24.5428, 23.6329, 11.4582,  7.5933, 12.9076, 21.4318, 13.6023,\n",
      "         6.4703, 31.3231, 35.4083, 22.7622, 42.6338, 20.4690, 28.6572, 23.6227,\n",
      "        22.5093, 37.2039, 31.7260, 27.3985, 21.2001, 13.0777, 12.9343, 33.0653,\n",
      "        12.1495, 26.6687, 29.1838, 13.3657, 20.0754, 26.8802, 31.4821, 14.2956,\n",
      "        23.2267, 26.2545, 23.9892, 25.7291, 14.1460, 22.0331, 29.6465,  6.9672,\n",
      "        36.6917, 25.3981, 27.1712, 16.5699, 21.2096, 41.7105, 20.6911, 29.2481]), 'FP32-BF16 mean zero setting Error': '1651484 / 8388544', 'FP32-BF16 mean std setting Error': '3936546 / 8388544'}\n",
      "idx :  9\n",
      "layer name :  conv4_x.0.residual_function.1\n",
      "chunk based sum result : 2916/1835008 = 0.1589093953371048%\n",
      "chunk based sum result : 76546/1835008 = 4.171425819396973%\n",
      "chunk based sum result : 23278/1835008 = 1.2685502767562866%\n",
      "chunk based sum result : 201568/1835008 = 10.984583854675293%\n",
      "{'epoch': 30, 'layer': 'conv4_x.0.residual_function.1', 'FP32-FP16_mse': tensor([0.0025, 0.0034, 0.0084, 0.0021, 0.0037, 0.0028, 0.0017, 0.0090, 0.0037,\n",
      "        0.0023, 0.0211, 0.0039, 0.0037, 0.0034, 0.0020, 0.0042, 0.0027, 0.0028,\n",
      "        0.0026, 0.0025, 0.0022, 0.0041, 0.0030, 0.0030, 0.0049, 0.0046, 0.0113,\n",
      "        0.0031, 0.0034, 0.0032, 0.0031, 0.0021, 0.0059, 0.0030, 0.0130, 0.0044,\n",
      "        0.0029, 0.0031, 0.0092, 0.0029, 0.0034, 0.0058, 0.0033, 0.0049, 0.0037,\n",
      "        0.0027, 0.0030, 0.0025, 0.0034, 0.0033, 0.0028, 0.0032, 0.0043, 0.0028,\n",
      "        0.0068, 0.0026, 0.0051, 0.0030, 0.0031, 0.0026, 0.0030, 0.0025, 0.0028,\n",
      "        0.0025, 0.0092, 0.0035, 0.0035, 0.0026, 0.0072, 0.0029, 0.0040, 0.0027,\n",
      "        0.0027, 0.0055, 0.0030, 0.0057, 0.0052, 0.0049, 0.0022, 0.0038, 0.0042,\n",
      "        0.0034, 0.0045, 0.0136, 0.0070, 0.0029, 0.0027, 0.0022, 0.0036, 0.0084,\n",
      "        0.0024, 0.0023, 0.0018, 0.0035, 0.0024, 0.0031, 0.0080, 0.0026, 0.0029,\n",
      "        0.0032, 0.0056, 0.0038, 0.0031, 0.0024, 0.0035, 0.0061, 0.0024, 0.0027,\n",
      "        0.0045, 0.0032, 0.0049, 0.0026, 0.0033, 0.0075, 0.0021, 0.0029, 0.0030,\n",
      "        0.0031, 0.0026, 0.0035, 0.0053, 0.0061, 0.0034, 0.0028, 0.0043, 0.0027,\n",
      "        0.0043, 0.0042, 0.0025, 0.0022, 0.0033, 0.0027, 0.0024, 0.0030, 0.0043,\n",
      "        0.0062, 0.0029, 0.0023, 0.0024, 0.0024, 0.0057, 0.0031, 0.0030, 0.0097,\n",
      "        0.0030, 0.0061, 0.0073, 0.0031, 0.0047, 0.0033, 0.0073, 0.0046, 0.0029,\n",
      "        0.0170, 0.0057, 0.0029, 0.0035, 0.0041, 0.0040, 0.0034, 0.0062, 0.0058,\n",
      "        0.0025, 0.0025, 0.0043, 0.0024, 0.0051, 0.0029, 0.0033, 0.0022, 0.0025,\n",
      "        0.0024, 0.0026, 0.0039, 0.0045, 0.0044, 0.0029, 0.0030, 0.0023, 0.0145,\n",
      "        0.0102, 0.0032, 0.0055, 0.0037, 0.0026, 0.0064, 0.0026, 0.0038, 0.0069,\n",
      "        0.0026, 0.0038, 0.0032, 0.0034, 0.0035, 0.0029, 0.0032, 0.0024, 0.0083,\n",
      "        0.0027, 0.0032, 0.0029, 0.0022, 0.0037, 0.0024, 0.0029, 0.0026, 0.0043,\n",
      "        0.0032, 0.0027, 0.0026, 0.0024, 0.0027, 0.0027, 0.0030, 0.0033, 0.0031,\n",
      "        0.0031, 0.0143, 0.0025, 0.0038, 0.0059, 0.0032, 0.0028, 0.0024, 0.0029,\n",
      "        0.0037, 0.0034, 0.0027, 0.0033, 0.0043, 0.0026, 0.0026, 0.0041, 0.0045,\n",
      "        0.0028, 0.0026, 0.0032, 0.0029, 0.0024, 0.0058, 0.0032, 0.0037, 0.0033,\n",
      "        0.0028, 0.0040, 0.0052, 0.0022, 0.0027, 0.0054, 0.0020, 0.0056, 0.0051,\n",
      "        0.0029, 0.0111, 0.0051, 0.0024]), 'FP32-FP16_L_inf': tensor([0.0726, 0.0879, 0.1089, 0.0273, 0.0718, 0.0844, 0.0335, 0.0696, 0.0911,\n",
      "        0.0485, 0.1024, 0.0783, 0.0727, 0.0956, 0.0347, 0.1886, 0.0575, 0.1049,\n",
      "        0.0819, 0.0541, 0.0447, 0.1104, 0.0576, 0.0579, 0.0446, 0.0840, 0.0889,\n",
      "        0.0801, 0.0791, 0.0580, 0.0704, 0.0390, 0.0977, 0.1314, 0.1043, 0.0819,\n",
      "        0.0753, 0.1162, 0.0761, 0.0810, 0.1088, 0.0948, 0.1310, 0.0684, 0.0723,\n",
      "        0.0485, 0.0738, 0.0398, 0.1526, 0.0519, 0.0396, 0.0444, 0.0789, 0.0428,\n",
      "        0.0586, 0.0637, 0.0677, 0.0424, 0.1322, 0.0562, 0.0369, 0.0473, 0.0614,\n",
      "        0.0573, 0.0656, 0.0860, 0.1063, 0.0992, 0.0785, 0.0492, 0.0577, 0.0533,\n",
      "        0.0559, 0.1041, 0.0565, 0.0605, 0.0531, 0.0621, 0.0562, 0.0635, 0.0699,\n",
      "        0.0597, 0.1078, 0.1031, 0.0770, 0.0622, 0.0866, 0.0489, 0.1328, 0.0545,\n",
      "        0.0420, 0.0791, 0.0363, 0.0615, 0.0429, 0.0788, 0.1592, 0.0381, 0.0871,\n",
      "        0.0544, 0.0559, 0.0741, 0.0989, 0.0537, 0.0712, 0.0854, 0.0756, 0.0508,\n",
      "        0.0612, 0.0599, 0.0611, 0.1155, 0.0642, 0.0858, 0.0276, 0.0826, 0.0628,\n",
      "        0.0749, 0.0568, 0.0745, 0.0645, 0.0898, 0.0515, 0.0762, 0.0655, 0.0713,\n",
      "        0.0679, 0.0716, 0.0570, 0.0615, 0.0703, 0.0574, 0.0499, 0.0562, 0.0796,\n",
      "        0.0705, 0.0883, 0.0506, 0.0524, 0.0753, 0.0679, 0.0712, 0.0739, 0.0677,\n",
      "        0.1081, 0.0782, 0.0754, 0.0562, 0.0552, 0.0704, 0.0740, 0.0477, 0.0360,\n",
      "        0.0889, 0.0519, 0.0587, 0.0575, 0.0802, 0.0673, 0.0516, 0.0830, 0.0618,\n",
      "        0.0786, 0.1145, 0.0796, 0.0589, 0.0790, 0.0629, 0.0656, 0.0467, 0.0764,\n",
      "        0.0445, 0.0453, 0.0532, 0.0626, 0.0842, 0.0526, 0.0418, 0.0574, 0.1146,\n",
      "        0.0876, 0.0951, 0.0637, 0.0608, 0.0582, 0.0892, 0.0804, 0.0518, 0.0599,\n",
      "        0.0680, 0.0749, 0.0657, 0.0703, 0.0584, 0.0427, 0.1476, 0.0526, 0.0919,\n",
      "        0.0851, 0.0445, 0.0676, 0.0502, 0.0512, 0.0431, 0.0462, 0.0614, 0.0843,\n",
      "        0.0989, 0.0497, 0.0514, 0.0432, 0.0668, 0.0802, 0.0427, 0.1228, 0.0598,\n",
      "        0.0538, 0.0788, 0.0396, 0.1254, 0.0714, 0.0492, 0.0720, 0.0418, 0.0694,\n",
      "        0.0787, 0.0911, 0.0553, 0.1000, 0.0973, 0.0590, 0.0528, 0.0650, 0.0950,\n",
      "        0.0853, 0.0547, 0.0731, 0.0518, 0.0383, 0.0526, 0.0553, 0.0518, 0.0703,\n",
      "        0.0545, 0.1134, 0.0737, 0.0355, 0.0591, 0.1265, 0.0500, 0.0542, 0.0707,\n",
      "        0.0838, 0.1020, 0.0783, 0.0502]), 'FP32-FP16 mean zero setting Error': '47543 / 2096896', 'FP32-FP16 mean std setting Error': '142569 / 2096896', 'FP32-BF16_mse': tensor([0.5707, 0.6081, 1.0119, 0.7024, 0.9907, 0.5630, 0.6157, 1.7069, 0.4305,\n",
      "        0.5551, 1.8553, 0.8846, 0.7929, 0.5032, 0.4633, 0.3089, 0.5191, 0.5607,\n",
      "        0.5638, 0.5148, 0.3885, 0.5416, 0.5361, 0.5569, 1.1604, 0.7973, 1.6647,\n",
      "        0.4184, 0.4673, 0.4999, 0.5110, 0.5657, 0.7064, 0.5328, 1.7442, 0.9616,\n",
      "        0.3451, 0.5252, 1.6209, 0.4730, 0.4921, 0.7451, 0.4895, 1.0070, 0.8065,\n",
      "        0.6038, 0.5470, 0.7019, 0.5207, 0.4999, 0.4828, 0.8274, 0.7358, 0.5857,\n",
      "        1.0534, 0.5109, 1.2840, 0.3875, 0.4185, 0.5169, 0.7615, 0.6435, 0.5600,\n",
      "        0.4847, 1.1491, 0.3499, 0.4885, 0.6276, 1.2108, 0.6028, 0.8845, 0.5673,\n",
      "        0.5483, 0.9511, 0.4170, 1.0634, 1.0504, 1.1414, 0.6732, 0.7681, 1.1135,\n",
      "        1.0018, 0.5619, 1.6192, 1.3724, 0.4980, 0.4648, 0.5612, 0.6214, 1.5470,\n",
      "        0.7141, 0.6527, 0.5369, 0.3232, 0.4075, 0.4714, 1.1590, 0.4578, 0.4183,\n",
      "        0.8616, 1.1929, 0.4814, 0.3005, 0.5683, 0.4781, 1.3156, 0.4653, 0.5345,\n",
      "        0.8229, 0.7516, 1.1303, 0.5642, 0.6233, 1.1512, 0.5294, 0.4908, 0.4598,\n",
      "        0.5231, 0.4427, 0.4731, 0.9707, 0.9807, 0.5299, 0.6224, 1.0402, 0.5035,\n",
      "        0.9519, 0.8547, 0.4090, 0.4607, 0.5273, 0.5972, 0.6444, 0.5099, 0.8038,\n",
      "        1.3689, 0.5037, 0.6470, 0.7141, 0.5248, 0.9173, 0.5419, 0.6243, 1.3567,\n",
      "        0.4726, 1.2154, 1.2224, 0.7810, 1.0807, 0.4370, 1.2639, 0.8535, 0.8543,\n",
      "        2.3368, 1.3842, 0.5497, 0.7279, 0.5744, 0.6715, 0.4547, 0.8886, 1.1146,\n",
      "        0.5977, 0.4875, 0.7403, 0.6309, 1.0288, 0.5100, 0.5803, 0.6398, 0.5055,\n",
      "        0.5171, 0.6442, 0.6819, 1.0112, 0.6829, 0.6136, 0.4751, 0.5256, 1.5633,\n",
      "        1.6787, 0.5427, 1.1491, 0.7741, 0.4364, 1.0549, 0.3914, 0.7039, 1.2132,\n",
      "        0.5699, 0.8553, 0.6752, 0.4664, 0.7955, 0.7012, 0.4835, 0.3777, 1.5028,\n",
      "        0.3594, 0.7597, 0.4966, 0.4398, 0.6215, 0.5817, 0.5268, 0.4385, 0.8086,\n",
      "        0.6752, 0.3693, 0.4635, 0.5584, 0.5407, 0.4572, 0.4924, 0.4052, 0.5392,\n",
      "        0.5073, 1.9666, 0.5471, 0.7140, 0.9334, 0.8096, 0.4977, 0.4377, 0.4402,\n",
      "        0.8143, 0.6438, 0.4323, 0.4297, 0.6297, 0.4475, 0.5531, 0.7045, 0.8762,\n",
      "        0.5254, 0.5490, 0.5340, 0.5850, 0.4979, 1.4255, 0.7041, 0.8373, 0.5682,\n",
      "        0.4513, 0.7911, 0.7377, 0.5522, 0.5226, 0.7398, 0.4462, 1.4882, 1.2942,\n",
      "        0.5253, 1.1153, 0.7135, 0.4805]), 'FP32-bf16_L_inf': tensor([12.8482, 12.7353,  6.4799,  8.3247, 10.5493, 11.5467, 12.7853,  7.7024,\n",
      "        10.9122, 11.0497,  3.6404,  9.1304, 13.6845, 14.2519,  7.9714, 14.1663,\n",
      "        10.4464, 16.6913, 13.5029,  8.9672,  6.9254, 10.7653,  8.0610,  9.6246,\n",
      "         8.4575,  8.6415,  3.0246, 11.1955, 11.2400,  9.2847, 11.4248,  9.8171,\n",
      "         6.9742, 20.6941,  4.5055, 10.6490,  9.1674, 17.1162,  8.1379, 12.9676,\n",
      "        15.7343,  5.8394, 20.1722,  8.4345,  7.9490,  9.8583,  9.3651,  8.6116,\n",
      "        16.2855,  5.9446,  6.9116,  8.2646,  8.2143,  8.1185,  4.5720, 12.8435,\n",
      "         7.9983,  5.5845, 14.2059, 10.5494,  7.7467, 10.2277, 10.5835, 11.0859,\n",
      "         3.2765,  8.5375, 14.7984, 19.5059, 10.5359,  9.7128,  7.4974, 11.9294,\n",
      "        11.4869, 13.4032,  7.4694,  6.0785,  6.0416,  9.2968,  9.9854,  8.6532,\n",
      "        10.6880, 10.6659,  8.1867,  5.2019,  6.8078, 10.0731, 14.9403, 12.4990,\n",
      "        10.0761,  6.4623, 11.5792, 17.3029, 10.1384,  5.3593,  7.6487,  9.4970,\n",
      "        11.8678,  7.1928, 11.7989, 10.4653,  7.5693,  9.0782,  9.7744, 10.1238,\n",
      "         9.6163,  8.6093, 12.6876,  9.9848,  6.4452, 11.0764,  9.3958, 16.5976,\n",
      "         5.8168,  6.4029,  6.9752, 14.0016, 10.1336,  9.1077,  8.7326, 10.2822,\n",
      "         7.0217,  8.6358,  7.9821, 13.6972,  8.2982, 12.7506, 12.9898,  7.2559,\n",
      "         8.0229, 12.3125, 10.3101, 11.1773, 11.1557,  9.4625, 10.6341,  4.8384,\n",
      "        14.4980,  8.8225, 13.2544, 13.8799,  7.3104,  9.3560, 13.2777,  6.0702,\n",
      "        14.6340,  7.2090,  6.6749, 11.2258,  6.4704,  9.2603,  7.1129,  5.7525,\n",
      "         8.5459,  3.3342,  7.3199,  9.8525,  9.4883,  8.2566,  6.1699,  6.7909,\n",
      "         5.8832,  6.2851, 16.6685, 21.3993,  6.5765, 12.0471,  9.7601,  9.3514,\n",
      "         9.1450, 11.7511, 15.1265,  9.5537,  8.6168,  6.8902,  8.4162,  6.9746,\n",
      "         9.8056,  6.8370, 12.7846,  3.3929,  8.3200, 10.4209,  6.4279,  8.1082,\n",
      "         9.4953,  8.4191, 12.1982,  7.3154,  7.4107, 15.2674,  8.0581, 10.6751,\n",
      "         9.6436,  9.4521,  8.2069, 18.0794,  8.7918,  6.7088, 11.6175,  9.1766,\n",
      "         8.5213,  9.6797,  5.8863, 10.0240,  8.6347,  9.0818,  7.7806, 14.5382,\n",
      "         6.2272,  9.2533, 10.2599, 13.1233, 12.6958,  6.0639, 15.2259,  9.3309,\n",
      "         6.0637,  3.7166,  8.4729,  9.8437,  6.7626, 11.3110,  8.0119,  7.8529,\n",
      "        10.8988, 13.6700, 11.3827,  8.2773, 13.3047,  9.8202,  6.0612, 11.4157,\n",
      "         7.8387, 16.6377, 15.6294, 10.2088,  7.7824, 11.0063,  8.0989,  9.4001,\n",
      "         8.5290,  6.7999,  8.6006,  9.0014,  8.8445,  3.5802,  8.8993, 10.8397,\n",
      "         7.5980, 10.9220,  9.9168, 10.7705, 15.0031,  4.6109,  6.5454, 10.0174]), 'FP32-BF16 mean zero setting Error': '205962 / 2096896', 'FP32-BF16 mean std setting Error': '414213 / 2096896'}\n",
      "idx :  15\n",
      "layer name :  conv5_x.1.residual_function.1\n",
      "chunk based sum result : 308/524288 = 0.058746337890625%\n",
      "chunk based sum result : 14294/524288 = 2.7263641357421875%\n",
      "chunk based sum result : 2529/524288 = 0.48236846923828125%\n",
      "chunk based sum result : 35958/524288 = 6.8584442138671875%\n",
      "{'epoch': 30, 'layer': 'conv5_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0025, 0.0034, 0.0031, 0.0038, 0.0025, 0.0052, 0.0039, 0.0113, 0.0033,\n",
      "        0.0032, 0.0035, 0.0034, 0.0029, 0.0026, 0.0023, 0.0031, 0.0064, 0.0035,\n",
      "        0.0038, 0.0040, 0.0029, 0.0019, 0.0042, 0.0031, 0.0028, 0.0033, 0.0031,\n",
      "        0.0025, 0.0027, 0.0030, 0.0020, 0.0022, 0.0023, 0.0063, 0.0033, 0.0028,\n",
      "        0.0027, 0.0022, 0.0022, 0.0027, 0.0038, 0.0025, 0.0028, 0.0026, 0.0030,\n",
      "        0.0024, 0.0047, 0.0033, 0.0028, 0.0081, 0.0023, 0.0030, 0.0032, 0.0024,\n",
      "        0.0034, 0.0033, 0.0028, 0.0028, 0.0033, 0.0033, 0.0034, 0.0022, 0.0026,\n",
      "        0.0022, 0.0041, 0.0024, 0.0027, 0.0033, 0.0022, 0.0029, 0.0026, 0.0028,\n",
      "        0.0057, 0.0023, 0.0027, 0.0031, 0.0039, 0.0024, 0.0041, 0.0030, 0.0029,\n",
      "        0.0030, 0.0029, 0.0025, 0.0028, 0.0033, 0.0034, 0.0026, 0.0032, 0.0034,\n",
      "        0.0023, 0.0109, 0.0023, 0.0028, 0.0020, 0.0051, 0.0032, 0.0045, 0.0028,\n",
      "        0.0026, 0.0053, 0.0027, 0.0031, 0.0033, 0.0023, 0.0117, 0.0028, 0.0073,\n",
      "        0.0051, 0.0096, 0.0035, 0.0027, 0.0032, 0.0030, 0.0024, 0.0026, 0.0063,\n",
      "        0.0038, 0.0028, 0.0026, 0.0028, 0.0032, 0.0037, 0.0031, 0.0072, 0.0026,\n",
      "        0.0027, 0.0028, 0.0033, 0.0039, 0.0026, 0.0025, 0.0031, 0.0034, 0.0028,\n",
      "        0.0022, 0.0024, 0.0030, 0.0032, 0.0031, 0.0039, 0.0029, 0.0032, 0.0039,\n",
      "        0.0035, 0.0072, 0.0031, 0.0022, 0.0036, 0.0052, 0.0027, 0.0025, 0.0026,\n",
      "        0.0036, 0.0035, 0.0031, 0.0053, 0.0029, 0.0034, 0.0074, 0.0029, 0.0021,\n",
      "        0.0043, 0.0027, 0.0027, 0.0023, 0.0029, 0.0024, 0.0028, 0.0027, 0.0031,\n",
      "        0.0086, 0.0022, 0.0046, 0.0026, 0.0054, 0.0027, 0.0026, 0.0034, 0.0025,\n",
      "        0.0032, 0.0041, 0.0071, 0.0027, 0.0027, 0.0024, 0.0082, 0.0024, 0.0072,\n",
      "        0.0025, 0.0020, 0.0025, 0.0028, 0.0049, 0.0029, 0.0022, 0.0040, 0.0066,\n",
      "        0.0027, 0.0025, 0.0035, 0.0092, 0.0046, 0.0039, 0.0039, 0.0023, 0.0059,\n",
      "        0.0038, 0.0033, 0.0021, 0.0035, 0.0048, 0.0030, 0.0026, 0.0030, 0.0020,\n",
      "        0.0024, 0.0034, 0.0043, 0.0021, 0.0025, 0.0030, 0.0029, 0.0022, 0.0030,\n",
      "        0.0036, 0.0036, 0.0097, 0.0101, 0.0025, 0.0022, 0.0023, 0.0030, 0.0065,\n",
      "        0.0052, 0.0059, 0.0023, 0.0034, 0.0041, 0.0025, 0.0031, 0.0020, 0.0023,\n",
      "        0.0027, 0.0056, 0.0031, 0.0023, 0.0024, 0.0028, 0.0029, 0.0039, 0.0022,\n",
      "        0.0030, 0.0033, 0.0028, 0.0026, 0.0022, 0.0039, 0.0026, 0.0034, 0.0036,\n",
      "        0.0032, 0.0029, 0.0029, 0.0016, 0.0023, 0.0021, 0.0030, 0.0031, 0.0075,\n",
      "        0.0037, 0.0028, 0.0035, 0.0043, 0.0032, 0.0033, 0.0027, 0.0028, 0.0028,\n",
      "        0.0038, 0.0029, 0.0025, 0.0026, 0.0028, 0.0030, 0.0025, 0.0022, 0.0039,\n",
      "        0.0038, 0.0022, 0.0028, 0.0034, 0.0027, 0.0047, 0.0048, 0.0035, 0.0027,\n",
      "        0.0044, 0.0024, 0.0030, 0.0022, 0.0027, 0.0039, 0.0064, 0.0032, 0.0034,\n",
      "        0.0040, 0.0028, 0.0094, 0.0026, 0.0035, 0.0028, 0.0024, 0.0049, 0.0024,\n",
      "        0.0025, 0.0050, 0.0028, 0.0021, 0.0032, 0.0042, 0.0028, 0.0024, 0.0033,\n",
      "        0.0028, 0.0039, 0.0020, 0.0023, 0.0046, 0.0024, 0.0036, 0.0031, 0.0026,\n",
      "        0.0031, 0.0042, 0.0037, 0.0035, 0.0031, 0.0034, 0.0036, 0.0061, 0.0028,\n",
      "        0.0031, 0.0027, 0.0023, 0.0025, 0.0034, 0.0025, 0.0039, 0.0022, 0.0025,\n",
      "        0.0028, 0.0077, 0.0032, 0.0126, 0.0029, 0.0034, 0.0024, 0.0027, 0.0026,\n",
      "        0.0040, 0.0026, 0.0049, 0.0027, 0.0024, 0.0020, 0.0027, 0.0027, 0.0035,\n",
      "        0.0062, 0.0033, 0.0026, 0.0029, 0.0038, 0.0028, 0.0033, 0.0036, 0.0024,\n",
      "        0.0029, 0.0119, 0.0023, 0.0020, 0.0035, 0.0051, 0.0025, 0.0033, 0.0023,\n",
      "        0.0036, 0.0099, 0.0022, 0.0034, 0.0037, 0.0024, 0.0022, 0.0026, 0.0021,\n",
      "        0.0032, 0.0023, 0.0023, 0.0021, 0.0025, 0.0029, 0.0030, 0.0026, 0.0030,\n",
      "        0.0027, 0.0032, 0.0069, 0.0022, 0.0050, 0.0028, 0.0066, 0.0029, 0.0055,\n",
      "        0.0024, 0.0028, 0.0028, 0.0089, 0.0023, 0.0024, 0.0034, 0.0027, 0.0041,\n",
      "        0.0030, 0.0023, 0.0035, 0.0028, 0.0023, 0.0031, 0.0115, 0.0026, 0.0028,\n",
      "        0.0028, 0.0031, 0.0022, 0.0026, 0.0041, 0.0033, 0.0026, 0.0037, 0.0028,\n",
      "        0.0021, 0.0030, 0.0028, 0.0025, 0.0028, 0.0031, 0.0030, 0.0053, 0.0029,\n",
      "        0.0023, 0.0022, 0.0036, 0.0049, 0.0022, 0.0035, 0.0044, 0.0024, 0.0031,\n",
      "        0.0028, 0.0025, 0.0031, 0.0020, 0.0035, 0.0025, 0.0045, 0.0047, 0.0027,\n",
      "        0.0025, 0.0028, 0.0035, 0.0029, 0.0034, 0.0023, 0.0028, 0.0051, 0.0035,\n",
      "        0.0051, 0.0032, 0.0022, 0.0038, 0.0026, 0.0035, 0.0026, 0.0030, 0.0027,\n",
      "        0.0027, 0.0039, 0.0039, 0.0043, 0.0027, 0.0042, 0.0044, 0.0018, 0.0023,\n",
      "        0.0025, 0.0051, 0.0046, 0.0026, 0.0027, 0.0026, 0.0039, 0.0031, 0.0022,\n",
      "        0.0038, 0.0046, 0.0026, 0.0032, 0.0026, 0.0053, 0.0032, 0.0069]), 'FP32-FP16_L_inf': tensor([0.0404, 0.0553, 0.0771, 0.0721, 0.0525, 0.0522, 0.0710, 0.1451, 0.0735,\n",
      "        0.0639, 0.0842, 0.0588, 0.0715, 0.0523, 0.0705, 0.0559, 0.0767, 0.0741,\n",
      "        0.0587, 0.0467, 0.0753, 0.0428, 0.0596, 0.0553, 0.0566, 0.0689, 0.0679,\n",
      "        0.0434, 0.0560, 0.0917, 0.0452, 0.0434, 0.0430, 0.0794, 0.0934, 0.0434,\n",
      "        0.0635, 0.0464, 0.0493, 0.1009, 0.0717, 0.0285, 0.1005, 0.0465, 0.0570,\n",
      "        0.0567, 0.0496, 0.1156, 0.0707, 0.0899, 0.0497, 0.0498, 0.0699, 0.0512,\n",
      "        0.0694, 0.0724, 0.0804, 0.0435, 0.0831, 0.0775, 0.0563, 0.0428, 0.0532,\n",
      "        0.0367, 0.0908, 0.0501, 0.0387, 0.0491, 0.0403, 0.0736, 0.0440, 0.0743,\n",
      "        0.1041, 0.0602, 0.0728, 0.0524, 0.0637, 0.0325, 0.0613, 0.0559, 0.0635,\n",
      "        0.1005, 0.0645, 0.0432, 0.0722, 0.0649, 0.0636, 0.0671, 0.0444, 0.0642,\n",
      "        0.0526, 0.1003, 0.0427, 0.0617, 0.0494, 0.0785, 0.0685, 0.0636, 0.0584,\n",
      "        0.0705, 0.1080, 0.0547, 0.0523, 0.0759, 0.0433, 0.0918, 0.0501, 0.0875,\n",
      "        0.1093, 0.0955, 0.0525, 0.0514, 0.0423, 0.0601, 0.0798, 0.0824, 0.1700,\n",
      "        0.0770, 0.0493, 0.0503, 0.0672, 0.0735, 0.1482, 0.0616, 0.1189, 0.0395,\n",
      "        0.0473, 0.0604, 0.0758, 0.1019, 0.0513, 0.0386, 0.0587, 0.0488, 0.0708,\n",
      "        0.0403, 0.0502, 0.0602, 0.1174, 0.0780, 0.0924, 0.0744, 0.0776, 0.1272,\n",
      "        0.1169, 0.0961, 0.0559, 0.0472, 0.1009, 0.0896, 0.0599, 0.0780, 0.0538,\n",
      "        0.0832, 0.1145, 0.0567, 0.0931, 0.0735, 0.0467, 0.1999, 0.0620, 0.0618,\n",
      "        0.1107, 0.0708, 0.0519, 0.0532, 0.0473, 0.0576, 0.0445, 0.0671, 0.0445,\n",
      "        0.1099, 0.0348, 0.0653, 0.0609, 0.1185, 0.0614, 0.0628, 0.0458, 0.0643,\n",
      "        0.1015, 0.0745, 0.0801, 0.0525, 0.0511, 0.0947, 0.0792, 0.0584, 0.0870,\n",
      "        0.0609, 0.0451, 0.0431, 0.0596, 0.0779, 0.0483, 0.0497, 0.1693, 0.0610,\n",
      "        0.0533, 0.0527, 0.1008, 0.0846, 0.0877, 0.0630, 0.0566, 0.0510, 0.1651,\n",
      "        0.0866, 0.0802, 0.0386, 0.0671, 0.0759, 0.0878, 0.0504, 0.0645, 0.0306,\n",
      "        0.0478, 0.1101, 0.0979, 0.0591, 0.0534, 0.0659, 0.0410, 0.0438, 0.0502,\n",
      "        0.0744, 0.0777, 0.1638, 0.1336, 0.0814, 0.0337, 0.0385, 0.0524, 0.1299,\n",
      "        0.0929, 0.0975, 0.0699, 0.0936, 0.0578, 0.0619, 0.0717, 0.0427, 0.0376,\n",
      "        0.0438, 0.0893, 0.0619, 0.0554, 0.0390, 0.0618, 0.0555, 0.0837, 0.0385,\n",
      "        0.0401, 0.0773, 0.0506, 0.0489, 0.0630, 0.1056, 0.0442, 0.1081, 0.1141,\n",
      "        0.0838, 0.0714, 0.0533, 0.0449, 0.0482, 0.0641, 0.0592, 0.0566, 0.1081,\n",
      "        0.0759, 0.0507, 0.0443, 0.0948, 0.0733, 0.0578, 0.0694, 0.0799, 0.0726,\n",
      "        0.0608, 0.0683, 0.0898, 0.0401, 0.0549, 0.0395, 0.0646, 0.0348, 0.0807,\n",
      "        0.1061, 0.0514, 0.0485, 0.0745, 0.0479, 0.0533, 0.0760, 0.0855, 0.0674,\n",
      "        0.0868, 0.0489, 0.0516, 0.0516, 0.0484, 0.1373, 0.1208, 0.1073, 0.0745,\n",
      "        0.0862, 0.0584, 0.0767, 0.0516, 0.0719, 0.0538, 0.0939, 0.0785, 0.0693,\n",
      "        0.0522, 0.1037, 0.0519, 0.1026, 0.0703, 0.0665, 0.0501, 0.0412, 0.0488,\n",
      "        0.0870, 0.0618, 0.0518, 0.0605, 0.0789, 0.0571, 0.0879, 0.0739, 0.0473,\n",
      "        0.0723, 0.0644, 0.0636, 0.1123, 0.0501, 0.0620, 0.0646, 0.0707, 0.0578,\n",
      "        0.0572, 0.0368, 0.0329, 0.0481, 0.0790, 0.0381, 0.0700, 0.0605, 0.0475,\n",
      "        0.0711, 0.0851, 0.0886, 0.0935, 0.0789, 0.1922, 0.0584, 0.0933, 0.0497,\n",
      "        0.0886, 0.0529, 0.0940, 0.0451, 0.0578, 0.0503, 0.0732, 0.0462, 0.0714,\n",
      "        0.1271, 0.0667, 0.0431, 0.0417, 0.0559, 0.0541, 0.0448, 0.0616, 0.0790,\n",
      "        0.0415, 0.0854, 0.1012, 0.0438, 0.0882, 0.0920, 0.0619, 0.0644, 0.0565,\n",
      "        0.0730, 0.0813, 0.0502, 0.0584, 0.0485, 0.0498, 0.0345, 0.0514, 0.0330,\n",
      "        0.0760, 0.0381, 0.0479, 0.0456, 0.0436, 0.0470, 0.0741, 0.0861, 0.0557,\n",
      "        0.0555, 0.0507, 0.1341, 0.0481, 0.1089, 0.0579, 0.0854, 0.0585, 0.1169,\n",
      "        0.0465, 0.0527, 0.0722, 0.1059, 0.0426, 0.0303, 0.0602, 0.0455, 0.0682,\n",
      "        0.0499, 0.0378, 0.0758, 0.0480, 0.0393, 0.0783, 0.0972, 0.0395, 0.0622,\n",
      "        0.0527, 0.0884, 0.0425, 0.0458, 0.0812, 0.0602, 0.0458, 0.0692, 0.0602,\n",
      "        0.0470, 0.0657, 0.0524, 0.0655, 0.0904, 0.0807, 0.0487, 0.0730, 0.0709,\n",
      "        0.0323, 0.0319, 0.0901, 0.0519, 0.0385, 0.0918, 0.0632, 0.0539, 0.0546,\n",
      "        0.0857, 0.0495, 0.0601, 0.0357, 0.0765, 0.0490, 0.0691, 0.1018, 0.0359,\n",
      "        0.0350, 0.0629, 0.0616, 0.0956, 0.0454, 0.0550, 0.0956, 0.0815, 0.0689,\n",
      "        0.1015, 0.0787, 0.0287, 0.0683, 0.0355, 0.0787, 0.0446, 0.0718, 0.0505,\n",
      "        0.0583, 0.0710, 0.0704, 0.0584, 0.0588, 0.0707, 0.0591, 0.0277, 0.0547,\n",
      "        0.0541, 0.1040, 0.1134, 0.0483, 0.0412, 0.0493, 0.0932, 0.0630, 0.0273,\n",
      "        0.0956, 0.0673, 0.0428, 0.0811, 0.0803, 0.0655, 0.0866, 0.0943]), 'FP32-FP16 mean zero setting Error': '98344 / 1048064', 'FP32-FP16 mean std setting Error': '254430 / 1048064', 'FP32-BF16_mse': tensor([0.1581, 0.2900, 0.1520, 0.4705, 0.2816, 0.6785, 0.3658, 0.8116, 0.1508,\n",
      "        0.2645, 0.1710, 0.4598, 0.1949, 0.1899, 0.1578, 0.3003, 0.7304, 0.2421,\n",
      "        0.5184, 0.5772, 0.1547, 0.2176, 0.4996, 0.1820, 0.2163, 0.2823, 0.3847,\n",
      "        0.2470, 0.3331, 0.2582, 0.2030, 0.1932, 0.1737, 0.5691, 0.2298, 0.5225,\n",
      "        0.2570, 0.1520, 0.1511, 0.3763, 0.3052, 0.2686, 0.2223, 0.2105, 0.3627,\n",
      "        0.1909, 0.6376, 0.1519, 0.3372, 0.7321, 0.2519, 0.4611, 0.3954, 0.1960,\n",
      "        0.4018, 0.2256, 0.1562, 0.1991, 0.1406, 0.2727, 0.4737, 0.3098, 0.1781,\n",
      "        0.2079, 0.3699, 0.1705, 0.1753, 0.2338, 0.2449, 0.1298, 0.1836, 0.3895,\n",
      "        0.5450, 0.1925, 0.2658, 0.2127, 0.4394, 0.2673, 0.5613, 0.1326, 0.1525,\n",
      "        0.2837, 0.3003, 0.1460, 0.2288, 0.3563, 0.2255, 0.3220, 0.4168, 0.2284,\n",
      "        0.1701, 0.9293, 0.1220, 0.3331, 0.1370, 0.5766, 0.5034, 0.5864, 0.1838,\n",
      "        0.2826, 0.5275, 0.2478, 0.2420, 0.4690, 0.2379, 0.8936, 0.2224, 0.6570,\n",
      "        0.3770, 0.9954, 0.3034, 0.1770, 0.4686, 0.4285, 0.1804, 0.2618, 0.8258,\n",
      "        0.4920, 0.2676, 0.2244, 0.2314, 0.2512, 0.2867, 0.2121, 0.6098, 0.1874,\n",
      "        0.2969, 0.3055, 0.4294, 0.5828, 0.2362, 0.2073, 0.5540, 0.6030, 0.2504,\n",
      "        0.2955, 0.1501, 0.1803, 0.3371, 0.3667, 0.5803, 0.3603, 0.2889, 0.4366,\n",
      "        0.2781, 0.7835, 0.4765, 0.1607, 0.2338, 0.3992, 0.1484, 0.1531, 0.3033,\n",
      "        0.1910, 0.4347, 0.1728, 0.4209, 0.3797, 0.1536, 0.5361, 0.1772, 0.1484,\n",
      "        0.4965, 0.1870, 0.2944, 0.1946, 0.3259, 0.1725, 0.1744, 0.2069, 0.2588,\n",
      "        0.8314, 0.1806, 0.5267, 0.2533, 0.8139, 0.1961, 0.2178, 0.3874, 0.1640,\n",
      "        0.1427, 0.4478, 0.7467, 0.3061, 0.1996, 0.2209, 0.8612, 0.1807, 0.7596,\n",
      "        0.3888, 0.1876, 0.2423, 0.1502, 0.5131, 0.2476, 0.1796, 0.4907, 0.7233,\n",
      "        0.1608, 0.1800, 0.2408, 0.9194, 0.4721, 0.4409, 0.4412, 0.1596, 0.5351,\n",
      "        0.4907, 0.1902, 0.2340, 0.4107, 0.4377, 0.2994, 0.1714, 0.2835, 0.2113,\n",
      "        0.1664, 0.2713, 0.5680, 0.1904, 0.1551, 0.4104, 0.1787, 0.1630, 0.1732,\n",
      "        0.3640, 0.1923, 0.8529, 0.9647, 0.2376, 0.1883, 0.2137, 0.2523, 0.7174,\n",
      "        0.5409, 0.6620, 0.2092, 0.3644, 0.5039, 0.2261, 0.3154, 0.1877, 0.2291,\n",
      "        0.1514, 0.6847, 0.3554, 0.1271, 0.1912, 0.1602, 0.1798, 0.3041, 0.2054,\n",
      "        0.1609, 0.2057, 0.1884, 0.1938, 0.2349, 0.3910, 0.2253, 0.1965, 0.2749,\n",
      "        0.3201, 0.2656, 0.2152, 0.1577, 0.1525, 0.2131, 0.3789, 0.3617, 0.6967,\n",
      "        0.5225, 0.1469, 0.5539, 0.4448, 0.1776, 0.2799, 0.2969, 0.1667, 0.2562,\n",
      "        0.4847, 0.4207, 0.1496, 0.4367, 0.3635, 0.5893, 0.4664, 0.2951, 0.4971,\n",
      "        0.6776, 0.3042, 0.2960, 0.1465, 0.2014, 0.5841, 0.6182, 0.3550, 0.2567,\n",
      "        0.2868, 0.1524, 0.1839, 0.2236, 0.1994, 0.3429, 0.8191, 0.2156, 0.3290,\n",
      "        0.4616, 0.3170, 1.1434, 0.1676, 0.5003, 0.1767, 0.1903, 0.5733, 0.1806,\n",
      "        0.3724, 0.5955, 0.2057, 0.1914, 0.3978, 0.5314, 0.2169, 0.1412, 0.3981,\n",
      "        0.1569, 0.4007, 0.1109, 0.1966, 0.5309, 0.1654, 0.2270, 0.1602, 0.1698,\n",
      "        0.4798, 0.5201, 0.5664, 0.4918, 0.4645, 0.3165, 0.2220, 0.7388, 0.1637,\n",
      "        0.3291, 0.4546, 0.1671, 0.1675, 0.2409, 0.3007, 0.5125, 0.1728, 0.2658,\n",
      "        0.3821, 0.7899, 0.3518, 1.1640, 0.3147, 0.3722, 0.1684, 0.2246, 0.3546,\n",
      "        0.4994, 0.2810, 0.4926, 0.3793, 0.1657, 0.3153, 0.2849, 0.2354, 0.4431,\n",
      "        0.5756, 0.2155, 0.1719, 0.1943, 0.4867, 0.4045, 0.3709, 0.3805, 0.3329,\n",
      "        0.2713, 0.9000, 0.1324, 0.2582, 0.3667, 0.6097, 0.2670, 0.2913, 0.3057,\n",
      "        0.4894, 0.8519, 0.1716, 0.3665, 0.5470, 0.1946, 0.1549, 0.2938, 0.3566,\n",
      "        0.4392, 0.1677, 0.2634, 0.1640, 0.1961, 0.4051, 0.1830, 0.1647, 0.4153,\n",
      "        0.2069, 0.1458, 0.6085, 0.1415, 0.4587, 0.2765, 0.7289, 0.3626, 0.4486,\n",
      "        0.1458, 0.2620, 0.2333, 0.8758, 0.2603, 0.1905, 0.4378, 0.1735, 0.4838,\n",
      "        0.2521, 0.1404, 0.1920, 0.3227, 0.2023, 0.1450, 1.0830, 0.2019, 0.1271,\n",
      "        0.1602, 0.2455, 0.2491, 0.1636, 0.3747, 0.2749, 0.2744, 0.2329, 0.2958,\n",
      "        0.1825, 0.2703, 0.3289, 0.1699, 0.1758, 0.2312, 0.2006, 0.6262, 0.2884,\n",
      "        0.1929, 0.1207, 0.4683, 0.7833, 0.1676, 0.3420, 0.7135, 0.3120, 0.4084,\n",
      "        0.2837, 0.3265, 0.2922, 0.2321, 0.4446, 0.2015, 0.3503, 0.5286, 0.1584,\n",
      "        0.4000, 0.3927, 0.5224, 0.2777, 0.4552, 0.1446, 0.1780, 0.4313, 0.3732,\n",
      "        0.6428, 0.1840, 0.1361, 0.5688, 0.2194, 0.2971, 0.2939, 0.1381, 0.1542,\n",
      "        0.1258, 0.5154, 0.4386, 0.6617, 0.3205, 0.5614, 0.5518, 0.1761, 0.1710,\n",
      "        0.2956, 0.6064, 0.5683, 0.2164, 0.4358, 0.2965, 0.3506, 0.1744, 0.3317,\n",
      "        0.1931, 0.4228, 0.1616, 0.4209, 0.2768, 0.6673, 0.1994, 0.5800]), 'FP32-bf16_L_inf': tensor([2.3993, 2.8768, 3.0595, 4.0701, 4.8869, 1.3415, 2.8085, 1.9047, 2.7728,\n",
      "        3.6446, 3.9245, 4.3568, 4.7278, 3.7985, 3.9782, 2.5183, 2.5487, 3.5046,\n",
      "        2.9181, 2.4559, 4.1152, 3.2861, 2.6112, 2.5428, 3.1548, 3.9605, 3.5440,\n",
      "        3.4210, 2.9730, 4.9311, 3.9538, 3.7408, 3.0499, 2.4940, 5.5555, 3.0093,\n",
      "        3.3830, 2.9519, 3.3302, 4.3821, 2.9488, 2.4473, 8.2085, 2.4387, 3.5275,\n",
      "        3.3838, 2.5872, 4.9882, 3.8877, 1.3695, 4.0179, 2.7954, 3.3822, 4.4135,\n",
      "        3.5565, 4.2394, 3.9466, 3.0959, 3.5427, 3.0090, 3.4987, 3.1396, 3.0451,\n",
      "        3.3570, 3.2266, 2.8119, 2.5875, 3.4947, 3.1783, 3.4319, 2.3394, 5.2014,\n",
      "        2.8430, 3.6821, 4.0618, 3.4029, 2.9945, 2.5745, 2.1753, 2.4777, 3.3434,\n",
      "        5.9063, 4.4050, 2.3586, 4.6605, 3.2217, 4.0427, 3.5244, 2.6886, 3.0982,\n",
      "        3.7137, 3.2128, 2.2093, 3.8569, 3.4191, 1.9657, 3.4954, 2.5157, 3.7553,\n",
      "        3.9327, 2.6668, 3.0769, 3.0028, 4.3591, 2.9213, 0.9642, 3.9288, 1.7724,\n",
      "        3.6663, 1.9280, 2.3450, 2.2587, 2.3765, 3.4635, 4.1336, 2.5781, 3.9329,\n",
      "        3.2870, 3.1743, 4.1085, 5.7186, 3.8116, 7.1408, 2.8840, 1.8177, 3.0006,\n",
      "        2.8084, 3.8282, 3.4144, 4.3543, 3.2191, 3.0377, 4.5396, 2.7189, 4.6225,\n",
      "        2.2211, 3.1057, 3.7107, 5.7606, 3.2986, 3.1033, 4.5464, 4.3318, 7.1564,\n",
      "        4.0865, 1.9614, 2.5834, 3.3994, 4.5125, 2.2765, 2.9983, 4.5192, 3.6181,\n",
      "        3.5820, 7.8540, 2.7952, 3.4098, 3.8060, 2.0728, 3.0449, 3.8152, 3.4901,\n",
      "        3.4378, 5.1004, 3.4670, 3.1051, 2.3917, 4.3108, 2.8812, 2.8280, 2.3197,\n",
      "        1.5046, 2.8841, 3.3707, 3.5543, 2.6309, 4.2586, 3.5844, 2.4352, 4.2869,\n",
      "        4.6690, 3.0175, 2.1280, 3.4380, 3.8017, 3.8218, 1.8946, 3.1196, 2.5209,\n",
      "        2.6543, 3.6283, 3.4977, 3.1770, 2.8564, 3.6532, 2.3388, 6.4854, 2.0869,\n",
      "        3.1245, 3.4935, 4.9624, 1.7632, 3.2478, 3.0014, 2.0944, 3.4120, 4.9304,\n",
      "        4.4003, 4.2212, 2.4306, 2.6658, 2.7241, 4.8345, 3.3627, 3.9414, 3.4028,\n",
      "        3.4521, 5.0548, 3.3285, 3.7932, 3.3027, 3.1760, 2.5390, 3.0649, 2.4378,\n",
      "        2.7670, 3.8662, 1.8258, 2.9065, 5.8711, 2.9138, 3.0392, 3.6984, 2.7755,\n",
      "        3.0610, 2.5785, 4.2393, 4.7892, 2.5011, 4.1696, 4.4194, 4.1741, 3.2987,\n",
      "        2.6083, 2.6762, 3.1995, 3.0545, 3.0986, 3.6490, 2.6053, 4.1070, 3.7654,\n",
      "        2.2868, 3.9694, 3.3267, 3.4530, 2.3437, 3.7889, 4.1412, 4.2614, 5.4158,\n",
      "        2.7324, 4.3603, 3.0107, 4.4967, 3.1990, 5.2547, 2.9854, 2.9936, 1.4650,\n",
      "        4.3502, 2.7254, 2.2905, 3.4611, 2.9516, 3.7263, 4.2461, 4.3451, 4.6258,\n",
      "        2.2410, 3.4845, 5.2829, 2.3762, 2.5426, 2.2660, 5.3403, 2.3939, 2.9665,\n",
      "        3.9290, 2.1427, 3.0986, 3.2512, 3.2789, 2.1316, 2.9873, 4.6865, 2.8708,\n",
      "        4.0453, 3.0701, 3.3315, 3.0758, 3.3305, 5.4760, 3.3919, 6.4132, 3.4274,\n",
      "        2.6909, 3.3341, 2.1131, 3.1681, 2.3680, 3.3107, 6.6666, 3.5752, 4.9917,\n",
      "        3.0638, 4.0293, 3.4290, 6.9645, 3.8690, 3.0027, 3.3915, 2.3907, 3.3393,\n",
      "        4.8529, 2.4400, 2.8900, 4.6619, 3.5455, 3.2419, 3.8093, 3.9779, 3.1294,\n",
      "        2.5721, 2.8433, 3.0769, 4.1571, 2.7798, 4.7756, 4.0186, 1.4588, 3.4573,\n",
      "        3.4607, 2.4681, 2.3638, 3.1078, 4.3517, 2.2778, 2.6947, 3.5602, 3.4547,\n",
      "        3.7479, 1.4442, 4.5925, 1.4041, 4.2719, 8.7120, 4.0398, 3.3927, 2.0657,\n",
      "        3.4858, 4.0416, 2.8228, 2.9052, 3.9917, 2.7638, 4.9413, 3.0355, 3.7041,\n",
      "        3.4189, 4.4809, 2.7313, 2.9545, 1.9281, 3.5191, 2.7673, 3.0054, 5.5255,\n",
      "        2.5351, 1.1762, 5.8550, 3.0507, 3.9488, 1.8743, 4.5825, 3.2214, 3.4676,\n",
      "        2.7335, 1.6607, 3.5972, 2.3924, 2.7609, 2.4528, 2.5220, 3.7004, 2.2901,\n",
      "        3.1370, 2.2625, 4.4899, 3.5197, 2.7091, 4.2104, 4.5625, 5.3699, 2.6290,\n",
      "        4.2332, 2.2754, 2.2362, 2.2414, 2.6549, 3.5879, 3.1591, 2.8799, 2.7169,\n",
      "        2.8160, 2.8416, 4.3375, 1.2624, 2.5795, 2.3742, 2.9998, 2.8852, 2.9285,\n",
      "        3.6975, 2.2395, 3.4215, 3.8293, 3.6772, 3.5969, 1.1398, 2.5793, 3.0150,\n",
      "        3.0806, 6.1003, 3.6909, 2.9663, 3.0169, 3.1506, 3.3209, 3.0500, 4.7681,\n",
      "        4.1009, 3.0571, 3.6909, 4.3286, 4.2771, 3.9949, 3.2472, 2.5544, 4.1961,\n",
      "        2.6708, 1.7218, 4.1367, 1.8203, 2.9418, 2.5550, 2.7325, 4.7523, 2.9385,\n",
      "        5.3841, 3.4769, 3.0901, 2.7198, 3.3657, 2.7025, 2.8482, 3.3673, 2.3089,\n",
      "        2.6440, 3.7690, 2.7025, 5.4614, 2.3111, 3.5636, 5.1671, 2.2060, 3.2648,\n",
      "        2.8300, 4.6567, 1.8572, 2.7112, 2.6212, 4.4177, 2.8634, 3.2949, 2.9808,\n",
      "        2.7811, 3.5805, 3.5708, 2.4206, 4.3729, 2.5103, 2.3796, 2.8252, 3.4947,\n",
      "        2.7033, 2.9250, 3.7309, 3.2947, 3.2382, 3.3944, 4.2107, 3.5676, 4.3283,\n",
      "        4.8632, 2.5255, 2.5140, 3.9878, 5.4967, 1.9862, 2.5820, 2.4901]), 'FP32-BF16 mean zero setting Error': '369579 / 1048064', 'FP32-BF16 mean std setting Error': '474873 / 1048064'}\n",
      "50\n",
      "idx :  3\n",
      "layer name :  conv2_x.1.residual_function.1\n",
      "chunk based sum result : 186782/8323072 = 2.244147300720215%\n",
      "chunk based sum result : 1516538/8323072 = 18.22089195251465%\n",
      "chunk based sum result : 1597895/8323072 = 19.198379516601562%\n",
      "chunk based sum result : 3886095/8323072 = 46.690635681152344%\n",
      "{'epoch': 50, 'layer': 'conv2_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0021, 0.0033, 0.0073, 0.0022, 0.0039, 0.0081, 0.0065, 0.0086, 0.0054,\n",
      "        0.0059, 0.0021, 0.0029, 0.0088, 0.0029, 0.0074, 0.0061, 0.0040, 0.0079,\n",
      "        0.0030, 0.0063, 0.0110, 0.0068, 0.0058, 0.0075, 0.0167, 0.0030, 0.0037,\n",
      "        0.0037, 0.0023, 0.0018, 0.0064, 0.0055, 0.0046, 0.0034, 0.0030, 0.0040,\n",
      "        0.0063, 0.0066, 0.0070, 0.0023, 0.0093, 0.0028, 0.0041, 0.0094, 0.0032,\n",
      "        0.0052, 0.0053, 0.0094, 0.0043, 0.0062, 0.0042, 0.0018, 0.0041, 0.0037,\n",
      "        0.0035, 0.0077, 0.0025, 0.0018, 0.0030, 0.0054, 0.0034, 0.0031, 0.0056,\n",
      "        0.0047]), 'FP32-FP16_L_inf': tensor([0.0700, 0.0933, 0.1709, 0.0700, 0.2203, 0.1615, 0.2236, 0.1555, 0.1535,\n",
      "        0.2342, 0.0658, 0.1186, 0.4747, 0.1167, 0.1795, 0.1443, 0.0997, 0.2666,\n",
      "        0.0770, 0.1202, 0.0854, 0.1894, 0.1462, 0.1553, 0.1269, 0.1447, 0.1571,\n",
      "        0.0567, 0.0920, 0.0430, 0.3430, 0.1163, 0.1092, 0.1473, 0.1093, 0.1313,\n",
      "        0.1798, 0.1755, 0.1040, 0.1040, 0.1925, 0.0835, 0.1877, 0.3667, 0.0756,\n",
      "        0.1432, 0.1643, 0.3053, 0.0854, 0.1081, 0.1535, 0.0425, 0.0657, 0.1783,\n",
      "        0.1063, 0.1175, 0.0881, 0.0440, 0.1298, 0.1345, 0.0620, 0.0790, 0.1141,\n",
      "        0.1289]), 'FP32-FP16 mean zero setting Error': '195788 / 8388544', 'FP32-FP16 mean std setting Error': '1529296 / 8388544', 'FP32-BF16_mse': tensor([0.9876, 1.2447, 2.8586, 1.0241, 0.4695, 2.2870, 1.9280, 2.4248, 1.4816,\n",
      "        1.6250, 0.8899, 0.6807, 0.1582, 1.0822, 1.7038, 3.6255, 1.0783, 1.3197,\n",
      "        0.9378, 2.4789, 2.7394, 2.7204, 1.4162, 2.0643, 2.3716, 0.6103, 0.8275,\n",
      "        1.4852, 0.9514, 0.8599, 0.6032, 1.4685, 1.1459, 0.9890, 1.0825, 1.0906,\n",
      "        1.0544, 1.8791, 2.0438, 0.8297, 2.7960, 0.9179, 0.9611, 1.2261, 0.8357,\n",
      "        1.5527, 1.3112, 2.0613, 1.3216, 1.9382, 1.1757, 0.9260, 1.1483, 0.5524,\n",
      "        1.0448, 3.0101, 0.8362, 1.1612, 0.6503, 1.0914, 1.4237, 1.5241, 1.7127,\n",
      "        1.3411]), 'FP32-bf16_L_inf': tensor([30.7955, 32.7841, 11.6315, 32.5172, 26.6915, 16.8263, 18.4112, 10.0163,\n",
      "        29.5608, 33.5396, 25.6858, 27.7113,  6.9505, 43.0383, 19.9802,  6.5234,\n",
      "        22.2237, 16.1728, 23.5524, 13.6919,  7.5923, 12.2613, 17.7852, 14.4218,\n",
      "         5.1167, 28.8563, 33.7121, 17.7099, 36.7844, 20.6511, 26.0124, 19.6526,\n",
      "        22.9147, 37.2220, 32.9395, 32.4007, 22.2125, 12.0721, 13.7671, 39.2842,\n",
      "        11.7968, 26.8766, 34.4350, 15.2473, 19.8585, 27.6390, 31.0977, 15.3077,\n",
      "        20.7579, 19.1948, 25.6600, 22.8886, 20.6713, 25.8613, 25.8342, 10.9549,\n",
      "        29.1144, 24.8033, 28.4861, 16.9046, 20.8810, 44.7997, 19.9926, 29.5268]), 'FP32-BF16 mean zero setting Error': '1648588 / 8388544', 'FP32-BF16 mean std setting Error': '3938913 / 8388544'}\n",
      "idx :  9\n",
      "layer name :  conv4_x.0.residual_function.1\n",
      "chunk based sum result : 2901/1835008 = 0.1580919474363327%\n",
      "chunk based sum result : 75978/1835008 = 4.140472412109375%\n",
      "chunk based sum result : 22779/1835008 = 1.2413569688796997%\n",
      "chunk based sum result : 197291/1835008 = 10.751505851745605%\n",
      "{'epoch': 50, 'layer': 'conv4_x.0.residual_function.1', 'FP32-FP16_mse': tensor([0.0028, 0.0042, 0.0095, 0.0025, 0.0039, 0.0032, 0.0018, 0.0086, 0.0031,\n",
      "        0.0023, 0.0248, 0.0041, 0.0068, 0.0027, 0.0023, 0.0037, 0.0031, 0.0027,\n",
      "        0.0026, 0.0025, 0.0022, 0.0032, 0.0030, 0.0033, 0.0042, 0.0028, 0.0107,\n",
      "        0.0030, 0.0036, 0.0027, 0.0032, 0.0022, 0.0080, 0.0029, 0.0109, 0.0036,\n",
      "        0.0029, 0.0034, 0.0091, 0.0026, 0.0030, 0.0052, 0.0038, 0.0058, 0.0039,\n",
      "        0.0026, 0.0027, 0.0024, 0.0043, 0.0031, 0.0029, 0.0023, 0.0082, 0.0026,\n",
      "        0.0080, 0.0027, 0.0066, 0.0026, 0.0029, 0.0025, 0.0025, 0.0023, 0.0029,\n",
      "        0.0029, 0.0098, 0.0036, 0.0031, 0.0022, 0.0115, 0.0034, 0.0033, 0.0027,\n",
      "        0.0028, 0.0038, 0.0039, 0.0054, 0.0040, 0.0067, 0.0026, 0.0056, 0.0029,\n",
      "        0.0052, 0.0037, 0.0086, 0.0061, 0.0028, 0.0040, 0.0020, 0.0038, 0.0102,\n",
      "        0.0028, 0.0027, 0.0016, 0.0033, 0.0026, 0.0032, 0.0084, 0.0028, 0.0031,\n",
      "        0.0040, 0.0058, 0.0042, 0.0035, 0.0025, 0.0031, 0.0061, 0.0023, 0.0028,\n",
      "        0.0045, 0.0038, 0.0070, 0.0045, 0.0038, 0.0071, 0.0026, 0.0027, 0.0033,\n",
      "        0.0029, 0.0031, 0.0031, 0.0042, 0.0051, 0.0035, 0.0023, 0.0024, 0.0029,\n",
      "        0.0063, 0.0043, 0.0029, 0.0025, 0.0034, 0.0027, 0.0025, 0.0027, 0.0037,\n",
      "        0.0057, 0.0027, 0.0028, 0.0027, 0.0027, 0.0046, 0.0029, 0.0030, 0.0111,\n",
      "        0.0033, 0.0056, 0.0070, 0.0029, 0.0032, 0.0032, 0.0076, 0.0057, 0.0029,\n",
      "        0.0141, 0.0057, 0.0035, 0.0069, 0.0035, 0.0032, 0.0031, 0.0059, 0.0103,\n",
      "        0.0033, 0.0023, 0.0036, 0.0061, 0.0051, 0.0033, 0.0035, 0.0026, 0.0023,\n",
      "        0.0024, 0.0048, 0.0056, 0.0045, 0.0052, 0.0033, 0.0032, 0.0021, 0.0182,\n",
      "        0.0091, 0.0035, 0.0090, 0.0031, 0.0025, 0.0039, 0.0026, 0.0031, 0.0058,\n",
      "        0.0022, 0.0035, 0.0028, 0.0029, 0.0037, 0.0023, 0.0027, 0.0022, 0.0059,\n",
      "        0.0026, 0.0039, 0.0033, 0.0025, 0.0026, 0.0024, 0.0030, 0.0023, 0.0047,\n",
      "        0.0030, 0.0024, 0.0029, 0.0021, 0.0023, 0.0032, 0.0034, 0.0029, 0.0030,\n",
      "        0.0025, 0.0128, 0.0020, 0.0031, 0.0042, 0.0073, 0.0025, 0.0030, 0.0025,\n",
      "        0.0036, 0.0043, 0.0027, 0.0030, 0.0035, 0.0023, 0.0026, 0.0036, 0.0032,\n",
      "        0.0029, 0.0028, 0.0037, 0.0029, 0.0025, 0.0081, 0.0039, 0.0032, 0.0043,\n",
      "        0.0032, 0.0037, 0.0094, 0.0028, 0.0037, 0.0125, 0.0023, 0.0045, 0.0049,\n",
      "        0.0030, 0.0104, 0.0059, 0.0025]), 'FP32-FP16_L_inf': tensor([0.0635, 0.0548, 0.0826, 0.0439, 0.0829, 0.0838, 0.0344, 0.0648, 0.0680,\n",
      "        0.0469, 0.1242, 0.0915, 0.0868, 0.0627, 0.0498, 0.1183, 0.0647, 0.0768,\n",
      "        0.0566, 0.0465, 0.0409, 0.0821, 0.0533, 0.0393, 0.0546, 0.0768, 0.0862,\n",
      "        0.0737, 0.1112, 0.0486, 0.0707, 0.0463, 0.0960, 0.1058, 0.0742, 0.0619,\n",
      "        0.0814, 0.1601, 0.0799, 0.0649, 0.1034, 0.0818, 0.1629, 0.0800, 0.0782,\n",
      "        0.0371, 0.0739, 0.0433, 0.0704, 0.0497, 0.0427, 0.0486, 0.0915, 0.0454,\n",
      "        0.0915, 0.0559, 0.0874, 0.0416, 0.1266, 0.0587, 0.0452, 0.0432, 0.0676,\n",
      "        0.0600, 0.0717, 0.0797, 0.1066, 0.0862, 0.1019, 0.0450, 0.0490, 0.0510,\n",
      "        0.0694, 0.0986, 0.0732, 0.0482, 0.0423, 0.0757, 0.0529, 0.0596, 0.0753,\n",
      "        0.0631, 0.0782, 0.0819, 0.0862, 0.0478, 0.1399, 0.0462, 0.1057, 0.0728,\n",
      "        0.0429, 0.1217, 0.0337, 0.0666, 0.0436, 0.0934, 0.1459, 0.0482, 0.0858,\n",
      "        0.0509, 0.0625, 0.0831, 0.1128, 0.0610, 0.0538, 0.0829, 0.0589, 0.0692,\n",
      "        0.0567, 0.0638, 0.0627, 0.0518, 0.0844, 0.0902, 0.0524, 0.0887, 0.0800,\n",
      "        0.0837, 0.0670, 0.0643, 0.0653, 0.0847, 0.0544, 0.0574, 0.0550, 0.0985,\n",
      "        0.0683, 0.0596, 0.0647, 0.0860, 0.0650, 0.0504, 0.0436, 0.0545, 0.0893,\n",
      "        0.0594, 0.0819, 0.0492, 0.0627, 0.0629, 0.0580, 0.0810, 0.0698, 0.0652,\n",
      "        0.0926, 0.0901, 0.0646, 0.0482, 0.0480, 0.0716, 0.0833, 0.0596, 0.0564,\n",
      "        0.0783, 0.0677, 0.0775, 0.0699, 0.0662, 0.0493, 0.0447, 0.0939, 0.0838,\n",
      "        0.0799, 0.0696, 0.0730, 0.0770, 0.0766, 0.0733, 0.0825, 0.0569, 0.0447,\n",
      "        0.0358, 0.0755, 0.0759, 0.0574, 0.0891, 0.0563, 0.0406, 0.0499, 0.1560,\n",
      "        0.1002, 0.0941, 0.0815, 0.0551, 0.0506, 0.0761, 0.0713, 0.0443, 0.0554,\n",
      "        0.0705, 0.0627, 0.0391, 0.0687, 0.1000, 0.0325, 0.0954, 0.0445, 0.0579,\n",
      "        0.0759, 0.0459, 0.0661, 0.0700, 0.0334, 0.0366, 0.0456, 0.0579, 0.0758,\n",
      "        0.0959, 0.0519, 0.0658, 0.0403, 0.0699, 0.0775, 0.0411, 0.0987, 0.0684,\n",
      "        0.0499, 0.0845, 0.0333, 0.1089, 0.0602, 0.0712, 0.0617, 0.0596, 0.0495,\n",
      "        0.0878, 0.0877, 0.0521, 0.1664, 0.0662, 0.0514, 0.0474, 0.0637, 0.0729,\n",
      "        0.0584, 0.0726, 0.0583, 0.0517, 0.0448, 0.0617, 0.0601, 0.0626, 0.1248,\n",
      "        0.0534, 0.1252, 0.1012, 0.0507, 0.0757, 0.1419, 0.0576, 0.0494, 0.0727,\n",
      "        0.0683, 0.0954, 0.1047, 0.0543]), 'FP32-FP16 mean zero setting Error': '48294 / 2096896', 'FP32-FP16 mean std setting Error': '142218 / 2096896', 'FP32-BF16_mse': tensor([0.6160, 0.8303, 1.0771, 0.6814, 0.7645, 0.6581, 0.6055, 1.7002, 0.4241,\n",
      "        0.4865, 2.8135, 0.6718, 1.1445, 0.5292, 0.4713, 0.3764, 0.5270, 0.6240,\n",
      "        0.6168, 0.4944, 0.4360, 0.4950, 0.6365, 0.6494, 1.0703, 0.5787, 1.4550,\n",
      "        0.4487, 0.4294, 0.6146, 0.4621, 0.5468, 0.8778, 0.5617, 1.5374, 0.6363,\n",
      "        0.3921, 0.5088, 1.6505, 0.4671, 0.4426, 0.7589, 0.5070, 1.0028, 0.7908,\n",
      "        0.5728, 0.4667, 0.7045, 0.8804, 0.6374, 0.5199, 0.7263, 0.9481, 0.5794,\n",
      "        1.4233, 0.5290, 1.4073, 0.3584, 0.4961, 0.4591, 0.5339, 0.5144, 0.5993,\n",
      "        0.5189, 1.3621, 0.3470, 0.5103, 0.5233, 1.5604, 0.6492, 0.7924, 0.5395,\n",
      "        0.5336, 0.8282, 0.3724, 1.1363, 1.0490, 1.3511, 0.6760, 1.0681, 0.6635,\n",
      "        1.1346, 0.5014, 1.5447, 1.2708, 0.5685, 0.4329, 0.5964, 0.6708, 1.5000,\n",
      "        0.8324, 0.6846, 0.6261, 0.4209, 0.5154, 0.4428, 1.1107, 0.4831, 0.4700,\n",
      "        1.0466, 1.2096, 0.5390, 0.3604, 0.5467, 0.5203, 1.4347, 0.5999, 0.4979,\n",
      "        0.8573, 0.8220, 1.2511, 1.0350, 0.5896, 0.9956, 0.5493, 0.5095, 0.4648,\n",
      "        0.6245, 0.4536, 0.5052, 0.8906, 1.0889, 0.4649, 0.6594, 0.6837, 0.4623,\n",
      "        1.1147, 0.7978, 0.4533, 0.3965, 0.4913, 0.5158, 0.5295, 0.4943, 0.5151,\n",
      "        1.4516, 0.4708, 0.7246, 0.7334, 0.7167, 0.8246, 0.5457, 0.6322, 1.9306,\n",
      "        0.5389, 1.0875, 1.1896, 0.5937, 0.8109, 0.4285, 1.2049, 1.0700, 0.7405,\n",
      "        1.8924, 1.3513, 0.5873, 1.1451, 0.4966, 0.5618, 0.4850, 0.9661, 1.4857,\n",
      "        0.6092, 0.5316, 0.6088, 1.1875, 0.9880, 0.5852, 0.5441, 0.5871, 0.6701,\n",
      "        0.5514, 0.8664, 0.8606, 1.0274, 0.8247, 0.6406, 0.5151, 0.5093, 2.0422,\n",
      "        1.5098, 0.4959, 1.4335, 0.7732, 0.4351, 0.8524, 0.4271, 0.6141, 1.2462,\n",
      "        0.5321, 0.7978, 0.6329, 0.4549, 0.6500, 0.7883, 0.4490, 0.4687, 1.0895,\n",
      "        0.3703, 0.9431, 0.4932, 0.4510, 0.5730, 0.6353, 0.5784, 0.4577, 0.7928,\n",
      "        0.5188, 0.4246, 0.4720, 0.6135, 0.5608, 0.4195, 0.4458, 0.4006, 0.5782,\n",
      "        0.5059, 2.2137, 0.5040, 0.6590, 0.6666, 1.4618, 0.4223, 0.5221, 0.4634,\n",
      "        0.7329, 0.7116, 0.4452, 0.4296, 0.5488, 0.5367, 0.5738, 0.6305, 0.7792,\n",
      "        0.7879, 0.5291, 0.6873, 0.6663, 0.4485, 1.4085, 1.0032, 0.5909, 0.6332,\n",
      "        0.5061, 0.6913, 1.0477, 0.5029, 0.4987, 1.2760, 0.4320, 1.2084, 1.2436,\n",
      "        0.5301, 1.0764, 0.7361, 0.4822]), 'FP32-bf16_L_inf': tensor([ 9.4458,  8.7554,  6.1876,  8.9995,  9.7582,  9.5334, 11.5176,  7.2779,\n",
      "         9.6309, 10.5187,  4.6277,  8.5201, 11.2946, 12.1855,  9.9929, 10.9754,\n",
      "         9.9375, 13.0545,  8.9978,  9.3844,  6.6498, 12.1677,  8.6669,  6.2998,\n",
      "        10.0071, 11.0440,  4.0370, 11.1211, 13.5113,  9.6426, 10.2897, 11.4114,\n",
      "         5.0729, 19.9420,  3.8560,  9.8608, 11.0714, 18.6335,  7.6186, 10.7908,\n",
      "        15.3815,  5.5288, 21.0696,  8.0313,  9.6763,  7.9930, 10.5989,  9.5221,\n",
      "         9.1064,  6.4739,  7.6769, 10.2627,  5.1918,  9.5431,  5.8879, 11.3291,\n",
      "         9.1776,  5.8671, 16.8420, 10.3462,  7.7163, 10.0784, 10.1160, 10.1510,\n",
      "         3.5331,  7.6493, 15.6095, 16.4234,  7.2426,  7.4991,  7.1948, 10.7161,\n",
      "        14.1192, 16.5845,  6.8590,  6.2030,  6.7545,  7.3930,  8.5256,  6.0720,\n",
      "        13.5576,  9.0166,  6.3919,  4.9216,  7.4503,  9.4592, 15.5753, 14.0376,\n",
      "         8.5984,  6.2047, 11.1412, 19.9219, 13.6333,  7.3063,  8.1710,  9.8332,\n",
      "        11.2507,  7.5204,  9.8260,  8.1413,  7.4370,  8.2148, 11.5938, 10.1526,\n",
      "         8.7336,  7.8425, 11.0568, 12.3378,  5.8874,  8.3642,  6.4864,  6.9458,\n",
      "         6.8958,  6.9859,  8.3923, 16.9505, 11.7348, 10.8303,  7.6737, 10.4474,\n",
      "         7.1061, 10.2820,  7.0750, 12.0036,  8.3314, 15.5387, 10.4754,  7.0064,\n",
      "         6.8882, 14.2129,  8.6084,  9.6389,  9.0761, 10.2166,  7.9293,  4.4429,\n",
      "        12.1593, 10.0867, 12.0734,  9.9860,  7.4230, 11.5780, 11.7120,  4.9414,\n",
      "        10.7851,  6.9455,  5.8642, 10.1564,  8.1945,  9.7372,  6.7770,  5.3549,\n",
      "         8.5955,  3.2788,  7.8302,  9.8698,  7.1520,  9.4316,  5.9093,  6.9285,\n",
      "         6.5338,  5.0912, 13.3421, 15.4340,  6.6814, 11.4214, 10.5263, 10.3846,\n",
      "        10.3964, 12.3390,  9.7544,  7.3352,  7.8576,  7.4940,  7.3289,  6.4105,\n",
      "         9.1844,  6.5820, 12.6403,  2.3721,  8.7016,  7.0825,  4.6130,  9.8129,\n",
      "         8.5796,  9.9848, 11.0214,  8.5764,  7.7719, 15.7006,  9.5670,  7.8749,\n",
      "        10.7542, 13.9158,  9.1218, 15.7551,  7.7587,  6.7763, 10.7348,  9.3783,\n",
      "         8.2594, 12.3522,  5.5362,  9.3049,  7.5147, 10.8118,  6.9667, 16.2300,\n",
      "         6.1712, 10.9119, 12.0917, 17.0379, 10.6115,  5.4994, 13.1253, 11.3135,\n",
      "         7.9207,  4.3337,  7.2954, 10.4513,  6.3721,  9.1510,  8.1600, 10.1806,\n",
      "         8.8987, 13.9840,  9.0893,  7.9261, 23.7018,  8.5664,  7.2099,  9.7241,\n",
      "         8.3230, 15.7418,  9.2303, 12.0255,  6.2390, 10.6326,  7.7390,  8.2001,\n",
      "         8.5665,  5.9881,  9.6225,  8.9984, 10.9163,  2.8425,  8.6413,  9.8765,\n",
      "         4.0073, 10.8944,  9.8008, 12.6307, 11.0364,  4.6983,  7.5218, 10.4647]), 'FP32-BF16 mean zero setting Error': '210458 / 2096896', 'FP32-BF16 mean std setting Error': '410075 / 2096896'}\n",
      "idx :  15\n",
      "layer name :  conv5_x.1.residual_function.1\n",
      "chunk based sum result : 322/524288 = 0.0614166259765625%\n",
      "chunk based sum result : 14130/524288 = 2.6950836181640625%\n",
      "chunk based sum result : 2634/524288 = 0.5023956298828125%\n",
      "chunk based sum result : 36082/524288 = 6.8820953369140625%\n",
      "{'epoch': 50, 'layer': 'conv5_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0022, 0.0043, 0.0032, 0.0053, 0.0027, 0.0037, 0.0025, 0.0131, 0.0023,\n",
      "        0.0033, 0.0034, 0.0041, 0.0032, 0.0028, 0.0028, 0.0022, 0.0071, 0.0022,\n",
      "        0.0032, 0.0071, 0.0028, 0.0025, 0.0044, 0.0045, 0.0032, 0.0030, 0.0024,\n",
      "        0.0027, 0.0029, 0.0033, 0.0021, 0.0020, 0.0024, 0.0029, 0.0031, 0.0058,\n",
      "        0.0030, 0.0024, 0.0024, 0.0033, 0.0027, 0.0023, 0.0032, 0.0043, 0.0028,\n",
      "        0.0024, 0.0031, 0.0032, 0.0028, 0.0080, 0.0028, 0.0029, 0.0032, 0.0031,\n",
      "        0.0033, 0.0024, 0.0026, 0.0033, 0.0027, 0.0036, 0.0048, 0.0024, 0.0030,\n",
      "        0.0022, 0.0051, 0.0021, 0.0021, 0.0032, 0.0025, 0.0035, 0.0026, 0.0023,\n",
      "        0.0084, 0.0032, 0.0028, 0.0026, 0.0029, 0.0022, 0.0038, 0.0019, 0.0028,\n",
      "        0.0035, 0.0039, 0.0020, 0.0027, 0.0025, 0.0034, 0.0025, 0.0031, 0.0031,\n",
      "        0.0023, 0.0093, 0.0031, 0.0031, 0.0018, 0.0022, 0.0060, 0.0048, 0.0022,\n",
      "        0.0021, 0.0027, 0.0031, 0.0024, 0.0031, 0.0029, 0.0068, 0.0030, 0.0095,\n",
      "        0.0036, 0.0076, 0.0046, 0.0032, 0.0043, 0.0043, 0.0034, 0.0029, 0.0037,\n",
      "        0.0032, 0.0026, 0.0027, 0.0030, 0.0034, 0.0025, 0.0026, 0.0033, 0.0021,\n",
      "        0.0027, 0.0032, 0.0037, 0.0054, 0.0030, 0.0027, 0.0032, 0.0051, 0.0022,\n",
      "        0.0025, 0.0026, 0.0028, 0.0025, 0.0029, 0.0043, 0.0051, 0.0039, 0.0037,\n",
      "        0.0043, 0.0040, 0.0024, 0.0029, 0.0033, 0.0028, 0.0025, 0.0018, 0.0030,\n",
      "        0.0031, 0.0035, 0.0028, 0.0044, 0.0040, 0.0025, 0.0055, 0.0029, 0.0023,\n",
      "        0.0033, 0.0024, 0.0035, 0.0027, 0.0020, 0.0019, 0.0028, 0.0024, 0.0028,\n",
      "        0.0047, 0.0021, 0.0035, 0.0021, 0.0072, 0.0034, 0.0024, 0.0033, 0.0023,\n",
      "        0.0035, 0.0025, 0.0037, 0.0041, 0.0033, 0.0024, 0.0076, 0.0022, 0.0077,\n",
      "        0.0018, 0.0024, 0.0025, 0.0025, 0.0060, 0.0025, 0.0027, 0.0041, 0.0052,\n",
      "        0.0022, 0.0026, 0.0038, 0.0083, 0.0041, 0.0051, 0.0037, 0.0023, 0.0030,\n",
      "        0.0024, 0.0022, 0.0026, 0.0034, 0.0040, 0.0032, 0.0026, 0.0027, 0.0022,\n",
      "        0.0030, 0.0042, 0.0046, 0.0021, 0.0027, 0.0028, 0.0037, 0.0021, 0.0034,\n",
      "        0.0028, 0.0035, 0.0090, 0.0125, 0.0024, 0.0026, 0.0026, 0.0029, 0.0080,\n",
      "        0.0027, 0.0092, 0.0037, 0.0032, 0.0033, 0.0023, 0.0028, 0.0021, 0.0026,\n",
      "        0.0022, 0.0042, 0.0034, 0.0023, 0.0023, 0.0024, 0.0023, 0.0032, 0.0030,\n",
      "        0.0033, 0.0027, 0.0032, 0.0026, 0.0025, 0.0036, 0.0032, 0.0038, 0.0035,\n",
      "        0.0020, 0.0028, 0.0026, 0.0016, 0.0018, 0.0025, 0.0058, 0.0030, 0.0045,\n",
      "        0.0033, 0.0026, 0.0032, 0.0030, 0.0024, 0.0027, 0.0030, 0.0022, 0.0022,\n",
      "        0.0034, 0.0043, 0.0028, 0.0026, 0.0029, 0.0037, 0.0046, 0.0027, 0.0060,\n",
      "        0.0041, 0.0023, 0.0031, 0.0033, 0.0028, 0.0057, 0.0039, 0.0024, 0.0026,\n",
      "        0.0036, 0.0028, 0.0025, 0.0027, 0.0030, 0.0047, 0.0050, 0.0033, 0.0032,\n",
      "        0.0043, 0.0028, 0.0100, 0.0033, 0.0049, 0.0029, 0.0029, 0.0048, 0.0028,\n",
      "        0.0038, 0.0032, 0.0030, 0.0022, 0.0031, 0.0046, 0.0030, 0.0031, 0.0041,\n",
      "        0.0028, 0.0037, 0.0028, 0.0024, 0.0040, 0.0023, 0.0028, 0.0027, 0.0028,\n",
      "        0.0025, 0.0042, 0.0022, 0.0025, 0.0062, 0.0048, 0.0030, 0.0099, 0.0033,\n",
      "        0.0033, 0.0030, 0.0021, 0.0022, 0.0024, 0.0026, 0.0036, 0.0022, 0.0022,\n",
      "        0.0026, 0.0061, 0.0025, 0.0058, 0.0027, 0.0040, 0.0031, 0.0034, 0.0037,\n",
      "        0.0039, 0.0025, 0.0050, 0.0033, 0.0024, 0.0024, 0.0029, 0.0027, 0.0038,\n",
      "        0.0075, 0.0033, 0.0027, 0.0025, 0.0074, 0.0031, 0.0027, 0.0029, 0.0030,\n",
      "        0.0047, 0.0083, 0.0025, 0.0026, 0.0042, 0.0028, 0.0023, 0.0029, 0.0019,\n",
      "        0.0059, 0.0058, 0.0029, 0.0023, 0.0046, 0.0027, 0.0029, 0.0026, 0.0028,\n",
      "        0.0034, 0.0032, 0.0031, 0.0025, 0.0031, 0.0026, 0.0025, 0.0025, 0.0050,\n",
      "        0.0027, 0.0025, 0.0057, 0.0025, 0.0042, 0.0032, 0.0062, 0.0028, 0.0059,\n",
      "        0.0024, 0.0029, 0.0031, 0.0050, 0.0027, 0.0024, 0.0031, 0.0026, 0.0032,\n",
      "        0.0032, 0.0020, 0.0030, 0.0027, 0.0027, 0.0033, 0.0094, 0.0030, 0.0030,\n",
      "        0.0025, 0.0032, 0.0026, 0.0030, 0.0028, 0.0030, 0.0029, 0.0038, 0.0024,\n",
      "        0.0027, 0.0034, 0.0027, 0.0032, 0.0037, 0.0028, 0.0027, 0.0034, 0.0043,\n",
      "        0.0022, 0.0023, 0.0042, 0.0083, 0.0027, 0.0023, 0.0046, 0.0024, 0.0035,\n",
      "        0.0023, 0.0042, 0.0034, 0.0036, 0.0046, 0.0027, 0.0030, 0.0046, 0.0027,\n",
      "        0.0028, 0.0023, 0.0081, 0.0030, 0.0022, 0.0027, 0.0031, 0.0034, 0.0033,\n",
      "        0.0037, 0.0030, 0.0025, 0.0043, 0.0025, 0.0028, 0.0025, 0.0027, 0.0025,\n",
      "        0.0026, 0.0043, 0.0036, 0.0069, 0.0035, 0.0060, 0.0038, 0.0021, 0.0024,\n",
      "        0.0022, 0.0030, 0.0046, 0.0028, 0.0023, 0.0031, 0.0035, 0.0030, 0.0023,\n",
      "        0.0037, 0.0029, 0.0025, 0.0036, 0.0031, 0.0042, 0.0030, 0.0102]), 'FP32-FP16_L_inf': tensor([0.0595, 0.1136, 0.0873, 0.0776, 0.0762, 0.0448, 0.0629, 0.1134, 0.0562,\n",
      "        0.0725, 0.1148, 0.1166, 0.0835, 0.0768, 0.0708, 0.0396, 0.0799, 0.0554,\n",
      "        0.0558, 0.0738, 0.0514, 0.0469, 0.0724, 0.0815, 0.0616, 0.0491, 0.0386,\n",
      "        0.0479, 0.0521, 0.0662, 0.0520, 0.0343, 0.0443, 0.0570, 0.0634, 0.0709,\n",
      "        0.0801, 0.0483, 0.0560, 0.1394, 0.0541, 0.0509, 0.0947, 0.0613, 0.0462,\n",
      "        0.0815, 0.0406, 0.0629, 0.0520, 0.0791, 0.0601, 0.0623, 0.0572, 0.0760,\n",
      "        0.0722, 0.0437, 0.0821, 0.0613, 0.0422, 0.0971, 0.0993, 0.0498, 0.0552,\n",
      "        0.0567, 0.1200, 0.0399, 0.0312, 0.0480, 0.0557, 0.1059, 0.0592, 0.0510,\n",
      "        0.1107, 0.0952, 0.0558, 0.0644, 0.0796, 0.0327, 0.0683, 0.0346, 0.0832,\n",
      "        0.0541, 0.0824, 0.0326, 0.0541, 0.0437, 0.0676, 0.0490, 0.0482, 0.0565,\n",
      "        0.0426, 0.1048, 0.0673, 0.0593, 0.0582, 0.0450, 0.0808, 0.0733, 0.0347,\n",
      "        0.0445, 0.0662, 0.0749, 0.0414, 0.0920, 0.0847, 0.0974, 0.0528, 0.0877,\n",
      "        0.1111, 0.0781, 0.0868, 0.0659, 0.0622, 0.0767, 0.0700, 0.0426, 0.0705,\n",
      "        0.0504, 0.0359, 0.0465, 0.0620, 0.0628, 0.0578, 0.0640, 0.0669, 0.0308,\n",
      "        0.0658, 0.0658, 0.1057, 0.0684, 0.0511, 0.0571, 0.0801, 0.0545, 0.0452,\n",
      "        0.0415, 0.0416, 0.0664, 0.0759, 0.0775, 0.1180, 0.0757, 0.1026, 0.1246,\n",
      "        0.1186, 0.0692, 0.0627, 0.0535, 0.0749, 0.0536, 0.0592, 0.0428, 0.0477,\n",
      "        0.0701, 0.0856, 0.0427, 0.0832, 0.1184, 0.0312, 0.1358, 0.0857, 0.0465,\n",
      "        0.0740, 0.0591, 0.0719, 0.0476, 0.0361, 0.0553, 0.0701, 0.0567, 0.0616,\n",
      "        0.0655, 0.0386, 0.0591, 0.0288, 0.1247, 0.0989, 0.0573, 0.0563, 0.0549,\n",
      "        0.0779, 0.0622, 0.0660, 0.0745, 0.1097, 0.0736, 0.0852, 0.0487, 0.1478,\n",
      "        0.0411, 0.0618, 0.0565, 0.0376, 0.0809, 0.0404, 0.0446, 0.1588, 0.1052,\n",
      "        0.0340, 0.0760, 0.0893, 0.1070, 0.0828, 0.0853, 0.0693, 0.0390, 0.0906,\n",
      "        0.0542, 0.0562, 0.0637, 0.0647, 0.0655, 0.0675, 0.0531, 0.0577, 0.0418,\n",
      "        0.0775, 0.1520, 0.0792, 0.0653, 0.0673, 0.0718, 0.0504, 0.0534, 0.0600,\n",
      "        0.0675, 0.0716, 0.0968, 0.1541, 0.0754, 0.0513, 0.0606, 0.0526, 0.1850,\n",
      "        0.0623, 0.0889, 0.0792, 0.0879, 0.0544, 0.0570, 0.0462, 0.0432, 0.0429,\n",
      "        0.0330, 0.0694, 0.0853, 0.0552, 0.0383, 0.0439, 0.0425, 0.0824, 0.0691,\n",
      "        0.0528, 0.0707, 0.0695, 0.0517, 0.0406, 0.0671, 0.0858, 0.1139, 0.0753,\n",
      "        0.0472, 0.0580, 0.0362, 0.0269, 0.0336, 0.0955, 0.0775, 0.0607, 0.0784,\n",
      "        0.0573, 0.0495, 0.0479, 0.0749, 0.0692, 0.0389, 0.0551, 0.0401, 0.0486,\n",
      "        0.0653, 0.0765, 0.1369, 0.0703, 0.0490, 0.0567, 0.0834, 0.0702, 0.0969,\n",
      "        0.0988, 0.0460, 0.0517, 0.0845, 0.0527, 0.0630, 0.0688, 0.0584, 0.0433,\n",
      "        0.0727, 0.0786, 0.0443, 0.0459, 0.0495, 0.1353, 0.0637, 0.0937, 0.0532,\n",
      "        0.0818, 0.0599, 0.0797, 0.0464, 0.0878, 0.0474, 0.1587, 0.0579, 0.0829,\n",
      "        0.0855, 0.1049, 0.0700, 0.1267, 0.0571, 0.0998, 0.0549, 0.0803, 0.1002,\n",
      "        0.0562, 0.0938, 0.0661, 0.0476, 0.0711, 0.0590, 0.0693, 0.0599, 0.0524,\n",
      "        0.0561, 0.0724, 0.0536, 0.0766, 0.0665, 0.0875, 0.0488, 0.1004, 0.0577,\n",
      "        0.0800, 0.0563, 0.0372, 0.0460, 0.0365, 0.0498, 0.0600, 0.0448, 0.0488,\n",
      "        0.0528, 0.0759, 0.0559, 0.0809, 0.0535, 0.1795, 0.0876, 0.0868, 0.0588,\n",
      "        0.1031, 0.0552, 0.1073, 0.0395, 0.0438, 0.0592, 0.1575, 0.0498, 0.0834,\n",
      "        0.1087, 0.0624, 0.0417, 0.0324, 0.1186, 0.0517, 0.0501, 0.0554, 0.0861,\n",
      "        0.0667, 0.0851, 0.0627, 0.0414, 0.1526, 0.0516, 0.0481, 0.0690, 0.0460,\n",
      "        0.1318, 0.0915, 0.0453, 0.0475, 0.0672, 0.0660, 0.0412, 0.0891, 0.0370,\n",
      "        0.0936, 0.0618, 0.0752, 0.0713, 0.0569, 0.0451, 0.0459, 0.0519, 0.0786,\n",
      "        0.0479, 0.0502, 0.1095, 0.0490, 0.0780, 0.0750, 0.0838, 0.0655, 0.1486,\n",
      "        0.0575, 0.0507, 0.0669, 0.0550, 0.0442, 0.0362, 0.0877, 0.0370, 0.0567,\n",
      "        0.0554, 0.0389, 0.0699, 0.0420, 0.0482, 0.0528, 0.0906, 0.0565, 0.0716,\n",
      "        0.0385, 0.1009, 0.0550, 0.0468, 0.0491, 0.0759, 0.0588, 0.0554, 0.0377,\n",
      "        0.0599, 0.0779, 0.0570, 0.0602, 0.0838, 0.0606, 0.0732, 0.0508, 0.0824,\n",
      "        0.0327, 0.0414, 0.0870, 0.1077, 0.0526, 0.0815, 0.0655, 0.0412, 0.0578,\n",
      "        0.0714, 0.0698, 0.0466, 0.0926, 0.0857, 0.0604, 0.0804, 0.0718, 0.0483,\n",
      "        0.0521, 0.0812, 0.0992, 0.0876, 0.0329, 0.0600, 0.1084, 0.0856, 0.0730,\n",
      "        0.0739, 0.0507, 0.0392, 0.0676, 0.0360, 0.0510, 0.0518, 0.0607, 0.0495,\n",
      "        0.0516, 0.0521, 0.0881, 0.0910, 0.0555, 0.0970, 0.0692, 0.0315, 0.0422,\n",
      "        0.0598, 0.0565, 0.0690, 0.0562, 0.0451, 0.0774, 0.1035, 0.0477, 0.0408,\n",
      "        0.1607, 0.0398, 0.0511, 0.0917, 0.0797, 0.0815, 0.0876, 0.1341]), 'FP32-FP16 mean zero setting Error': '100448 / 1048064', 'FP32-FP16 mean std setting Error': '255764 / 1048064', 'FP32-BF16_mse': tensor([0.2811, 0.3146, 0.1764, 0.6962, 0.2719, 0.6007, 0.3593, 0.9875, 0.1325,\n",
      "        0.2700, 0.1353, 0.2910, 0.1689, 0.1902, 0.2595, 0.2626, 0.8311, 0.1867,\n",
      "        0.7290, 0.6643, 0.1946, 0.3074, 0.5205, 0.3740, 0.2047, 0.2304, 0.2175,\n",
      "        0.3548, 0.3384, 0.2272, 0.2358, 0.1476, 0.1844, 0.3228, 0.2550, 0.7746,\n",
      "        0.2578, 0.1528, 0.1577, 0.5152, 0.2088, 0.3137, 0.2359, 0.4028, 0.2907,\n",
      "        0.1686, 0.5304, 0.1943, 0.3843, 0.6572, 0.3087, 0.3250, 0.4430, 0.2295,\n",
      "        0.3986, 0.1449, 0.1861, 0.2227, 0.1628, 0.3155, 0.5108, 0.2644, 0.4106,\n",
      "        0.1627, 0.4559, 0.1318, 0.1579, 0.3197, 0.2784, 0.2172, 0.1551, 0.2185,\n",
      "        0.7416, 0.2525, 0.2187, 0.1820, 0.3107, 0.2125, 0.5101, 0.1705, 0.2513,\n",
      "        0.4383, 0.4374, 0.1681, 0.3299, 0.3295, 0.1874, 0.2266, 0.3486, 0.4393,\n",
      "        0.1438, 1.0176, 0.1321, 0.2899, 0.1126, 0.2634, 0.5902, 0.5214, 0.1974,\n",
      "        0.2281, 0.2783, 0.2235, 0.2522, 0.3832, 0.2678, 0.6441, 0.1959, 0.7481,\n",
      "        0.2703, 0.8789, 0.4639, 0.2025, 0.5099, 0.5486, 0.2091, 0.3817, 0.4714,\n",
      "        0.5097, 0.2332, 0.2739, 0.2044, 0.4402, 0.2328, 0.2144, 0.3406, 0.1744,\n",
      "        0.2588, 0.3998, 0.4282, 0.7921, 0.2387, 0.2129, 0.4146, 0.6724, 0.2720,\n",
      "        0.3210, 0.1549, 0.1527, 0.2729, 0.4587, 0.5462, 0.6349, 0.4447, 0.3204,\n",
      "        0.3708, 0.4486, 0.4053, 0.1470, 0.4288, 0.2027, 0.1598, 0.1736, 0.3365,\n",
      "        0.2694, 0.2737, 0.3169, 0.4358, 0.5456, 0.2012, 0.5015, 0.2074, 0.1483,\n",
      "        0.3632, 0.1905, 0.3470, 0.2413, 0.2472, 0.1556, 0.1663, 0.1606, 0.2316,\n",
      "        0.7280, 0.1658, 0.4442, 0.1491, 0.8397, 0.3358, 0.1486, 0.3578, 0.1395,\n",
      "        0.1714, 0.2121, 0.4521, 0.3447, 0.2298, 0.2378, 0.8840, 0.2650, 0.7689,\n",
      "        0.2392, 0.1979, 0.1785, 0.1635, 0.6890, 0.1965, 0.3668, 0.4275, 0.7656,\n",
      "        0.2041, 0.1668, 0.2806, 0.9058, 0.5855, 0.5693, 0.3660, 0.1740, 0.2843,\n",
      "        0.2292, 0.1883, 0.2082, 0.3745, 0.4374, 0.2485, 0.1757, 0.1862, 0.2239,\n",
      "        0.2653, 0.3330, 0.6481, 0.2130, 0.1327, 0.3718, 0.4055, 0.2144, 0.3002,\n",
      "        0.2390, 0.1460, 0.8689, 1.0471, 0.1943, 0.1899, 0.1774, 0.2917, 0.7274,\n",
      "        0.4358, 0.7710, 0.3992, 0.2218, 0.3250, 0.1539, 0.2417, 0.1355, 0.2135,\n",
      "        0.1666, 0.4898, 0.4034, 0.2029, 0.2025, 0.1505, 0.2176, 0.2625, 0.2364,\n",
      "        0.1729, 0.1722, 0.1816, 0.2439, 0.2773, 0.4273, 0.3081, 0.3262, 0.3485,\n",
      "        0.1736, 0.2743, 0.2235, 0.1789, 0.1253, 0.1579, 0.6131, 0.2541, 0.4645,\n",
      "        0.5289, 0.1293, 0.4956, 0.2864, 0.1585, 0.2015, 0.2601, 0.1485, 0.2145,\n",
      "        0.5402, 0.5958, 0.1731, 0.2200, 0.3778, 0.5470, 0.5910, 0.2946, 0.7038,\n",
      "        0.5923, 0.2143, 0.3115, 0.1525, 0.1819, 0.7815, 0.5650, 0.3169, 0.2232,\n",
      "        0.3191, 0.1937, 0.2725, 0.2961, 0.3122, 0.3680, 0.6862, 0.2384, 0.2207,\n",
      "        0.6286, 0.3456, 1.0788, 0.1625, 0.6356, 0.1712, 0.1747, 0.6602, 0.2137,\n",
      "        0.5453, 0.3718, 0.1868, 0.1770, 0.3150, 0.6019, 0.2486, 0.1811, 0.4372,\n",
      "        0.2353, 0.3090, 0.1920, 0.2017, 0.3924, 0.1931, 0.1938, 0.2064, 0.2543,\n",
      "        0.5063, 0.4791, 0.3386, 0.2832, 0.6235, 0.5221, 0.1843, 0.9732, 0.1743,\n",
      "        0.4675, 0.4542, 0.1817, 0.1315, 0.2346, 0.2415, 0.4859, 0.2466, 0.1691,\n",
      "        0.2284, 0.6799, 0.2212, 0.8301, 0.2781, 0.2255, 0.2541, 0.4321, 0.5181,\n",
      "        0.4700, 0.2868, 0.6315, 0.3916, 0.2324, 0.1924, 0.2331, 0.3010, 0.4648,\n",
      "        0.5634, 0.2029, 0.2183, 0.2059, 0.7054, 0.3679, 0.2985, 0.3220, 0.4733,\n",
      "        0.5141, 0.6244, 0.1507, 0.3312, 0.3016, 0.4369, 0.3124, 0.1798, 0.1380,\n",
      "        0.5667, 0.5863, 0.2227, 0.2977, 0.6592, 0.1573, 0.1905, 0.3137, 0.4104,\n",
      "        0.3901, 0.3221, 0.3667, 0.1958, 0.2730, 0.3724, 0.1574, 0.1561, 0.4959,\n",
      "        0.1763, 0.1635, 0.4773, 0.3112, 0.5043, 0.3955, 0.6771, 0.3411, 0.4946,\n",
      "        0.1348, 0.2812, 0.3172, 0.6505, 0.3835, 0.1966, 0.2965, 0.2012, 0.2427,\n",
      "        0.3828, 0.1738, 0.2060, 0.3279, 0.2717, 0.1498, 0.8246, 0.2303, 0.1473,\n",
      "        0.1692, 0.2366, 0.1987, 0.1396, 0.2122, 0.2458, 0.2660, 0.4150, 0.2715,\n",
      "        0.1751, 0.3491, 0.2002, 0.1903, 0.3491, 0.1883, 0.1594, 0.4319, 0.4498,\n",
      "        0.1911, 0.1410, 0.4226, 0.8011, 0.1789, 0.2320, 0.5482, 0.3436, 0.4781,\n",
      "        0.2895, 0.4837, 0.3508, 0.5122, 0.5581, 0.1706, 0.2485, 0.4699, 0.1538,\n",
      "        0.4598, 0.3627, 0.8249, 0.3409, 0.3459, 0.1305, 0.2126, 0.3079, 0.3233,\n",
      "        0.4450, 0.1933, 0.1440, 0.4627, 0.2086, 0.2434, 0.1809, 0.1556, 0.1796,\n",
      "        0.1395, 0.5859, 0.3708, 0.8263, 0.5412, 0.6738, 0.4779, 0.1410, 0.1899,\n",
      "        0.2774, 0.5239, 0.5278, 0.1677, 0.3893, 0.4432, 0.3533, 0.1711, 0.2834,\n",
      "        0.2244, 0.3701, 0.1744, 0.3353, 0.3777, 0.6133, 0.1974, 0.8388]), 'FP32-bf16_L_inf': tensor([4.0280, 3.8055, 3.8921, 3.1739, 4.7832, 2.0650, 2.9754, 1.2026, 3.2876,\n",
      "        2.8993, 4.3800, 3.0328, 4.3521, 4.9479, 4.8631, 3.2837, 2.5675, 3.1924,\n",
      "        3.2432, 1.7337, 3.2162, 3.2554, 2.6753, 2.6391, 3.0984, 3.7650, 3.1818,\n",
      "        3.8951, 2.7880, 3.6573, 3.6443, 2.5929, 3.2278, 3.0487, 4.0228, 2.1566,\n",
      "        2.9554, 2.7041, 3.8841, 4.5337, 3.7717, 3.5753, 7.0759, 2.4080, 2.7278,\n",
      "        3.6086, 3.2422, 3.0462, 2.4974, 1.5783, 3.2334, 4.1218, 3.0143, 4.2930,\n",
      "        3.4073, 2.5796, 3.9409, 3.7817, 2.4469, 3.2926, 3.6042, 2.9157, 2.9891,\n",
      "        4.1845, 3.0083, 2.2953, 2.2549, 4.5874, 3.8077, 5.6355, 3.5141, 3.2204,\n",
      "        2.2531, 4.3530, 3.0304, 3.4983, 3.3636, 2.3665, 2.9523, 3.2948, 4.6484,\n",
      "        3.4861, 3.4939, 2.7359, 3.1916, 3.5079, 2.7466, 3.4758, 2.5504, 3.4889,\n",
      "        2.7345, 3.7396, 2.6193, 3.6133, 2.9405, 2.1587, 2.4433, 2.6342, 3.2790,\n",
      "        3.1606, 2.7194, 4.3490, 2.6890, 6.6716, 4.3945, 2.1354, 3.5807, 1.4850,\n",
      "        5.3261, 2.1203, 3.2906, 3.8998, 2.5156, 2.8592, 4.4453, 2.4884, 3.7281,\n",
      "        2.4918, 2.7440, 3.5764, 4.3472, 3.1588, 4.3421, 4.7349, 2.8470, 2.5802,\n",
      "        4.4641, 4.2468, 3.5461, 3.1183, 2.8995, 3.0069, 4.6508, 2.3049, 4.2927,\n",
      "        2.7576, 2.3877, 3.5128, 5.8810, 3.7682, 3.8914, 2.8724, 4.3776, 5.0979,\n",
      "        3.6506, 2.7006, 3.1948, 2.7403, 4.3091, 2.8173, 3.8170, 4.2558, 3.2437,\n",
      "        3.1098, 6.0197, 3.2718, 3.0844, 3.9617, 2.5182, 2.4031, 4.6533, 2.8281,\n",
      "        4.1857, 4.5790, 2.9982, 3.0214, 2.5867, 4.1672, 3.2906, 3.4862, 3.8184,\n",
      "        2.0500, 2.7603, 3.1546, 2.0902, 2.6590, 3.3540, 3.6547, 3.5865, 3.1809,\n",
      "        3.8887, 4.0593, 2.8679, 2.6698, 7.9724, 3.6246, 2.1903, 3.2097, 3.4292,\n",
      "        2.8207, 4.1109, 4.2921, 2.2815, 1.8415, 2.6396, 3.3750, 5.8231, 3.3150,\n",
      "        2.9373, 4.5739, 3.9874, 1.8768, 2.5545, 2.9065, 2.6918, 2.9360, 5.8366,\n",
      "        3.3723, 3.9397, 3.2366, 2.4836, 3.3719, 3.5093, 3.8873, 3.8004, 4.2297,\n",
      "        3.8344, 4.6126, 3.1458, 5.0167, 3.3095, 3.8460, 2.2783, 3.8011, 2.3726,\n",
      "        4.3361, 3.0611, 1.4841, 2.1851, 6.3808, 2.9190, 3.7410, 3.2510, 3.6276,\n",
      "        4.1330, 1.4364, 4.5387, 5.3470, 2.7116, 3.8972, 3.1990, 2.8871, 3.0177,\n",
      "        2.1327, 3.1469, 4.0919, 2.6628, 3.2995, 2.8951, 2.6392, 5.3839, 4.2041,\n",
      "        2.8261, 4.5390, 3.9896, 3.5034, 2.3542, 3.5112, 6.0923, 3.7221, 3.5152,\n",
      "        2.5620, 3.2141, 2.8131, 3.1660, 2.2978, 6.0343, 2.0872, 4.7778, 2.3215,\n",
      "        4.1706, 2.4489, 2.9476, 3.8928, 4.6302, 2.8310, 4.2447, 2.7839, 3.7425,\n",
      "        2.9189, 3.2995, 7.1011, 3.6313, 2.6218, 1.9920, 2.8898, 3.1066, 2.6542,\n",
      "        4.5485, 2.6655, 3.1222, 3.7086, 3.1044, 1.8599, 2.8515, 3.9185, 2.5018,\n",
      "        4.5971, 5.3994, 3.8818, 2.5792, 3.7524, 4.5281, 2.5617, 5.6153, 2.7858,\n",
      "        2.9397, 3.5921, 2.0714, 2.2744, 2.9077, 2.8403, 8.6109, 2.9045, 5.3635,\n",
      "        3.0355, 5.9895, 4.3129, 8.4192, 3.4111, 4.2520, 4.2729, 4.3067, 3.9816,\n",
      "        3.9288, 3.8684, 3.1216, 3.5042, 3.2715, 3.1516, 3.7659, 4.1364, 3.4756,\n",
      "        2.4552, 3.1182, 3.7968, 4.7001, 1.8841, 3.4621, 3.1044, 1.1246, 3.2044,\n",
      "        3.7844, 2.7980, 3.3771, 2.6953, 3.3345, 3.2362, 3.6081, 2.5392, 2.5589,\n",
      "        4.0207, 1.7706, 4.2868, 3.6191, 3.8658, 9.5696, 5.5410, 2.6100, 2.1034,\n",
      "        3.8081, 4.1897, 3.5620, 2.2819, 2.9471, 3.4753, 5.8119, 3.1076, 3.6960,\n",
      "        2.4079, 3.8762, 2.8113, 2.3895, 2.1368, 3.2395, 3.5199, 3.5542, 5.0395,\n",
      "        2.4359, 2.1037, 3.7423, 3.4903, 4.6068, 2.4424, 3.4024, 4.4780, 2.0369,\n",
      "        2.5818, 2.7894, 2.7568, 3.3978, 2.9340, 3.1983, 2.7814, 6.2682, 2.0058,\n",
      "        3.7176, 3.2458, 5.0596, 5.1483, 3.7069, 3.6693, 2.2890, 3.3840, 1.8096,\n",
      "        3.0729, 2.5399, 2.2154, 3.4531, 2.2829, 4.0982, 2.3174, 3.7754, 2.9639,\n",
      "        3.2497, 2.6623, 3.6676, 1.7448, 2.0555, 3.0133, 4.9879, 2.8635, 3.3680,\n",
      "        3.3540, 3.0804, 3.5003, 3.3753, 3.1422, 2.3223, 1.1431, 3.5904, 3.4288,\n",
      "        2.3852, 6.1965, 4.2051, 2.3249, 3.6703, 3.4061, 4.3310, 2.8004, 3.1234,\n",
      "        3.7610, 3.5407, 4.0632, 3.2545, 3.7897, 4.0265, 3.6648, 2.5610, 2.9773,\n",
      "        2.9219, 2.5430, 3.5912, 1.8926, 3.6658, 3.1312, 3.2102, 4.4463, 3.0179,\n",
      "        6.2549, 2.2575, 2.1712, 3.7837, 2.8936, 3.5098, 3.5258, 2.8157, 2.6565,\n",
      "        3.0922, 4.4831, 1.9442, 5.6361, 3.1047, 2.9285, 5.8060, 3.3475, 4.3414,\n",
      "        3.4646, 3.3394, 2.1805, 2.4978, 2.8463, 3.7140, 3.5263, 3.3630, 3.6740,\n",
      "        2.6926, 2.2302, 4.7074, 2.0164, 3.4452, 2.4387, 3.2222, 2.0663, 2.7659,\n",
      "        3.0455, 2.6647, 2.6328, 3.0597, 3.8654, 4.6701, 4.0422, 2.7603, 5.2224,\n",
      "        7.9596, 2.4077, 3.0093, 3.4215, 4.2013, 3.2153, 3.3247, 2.6770]), 'FP32-BF16 mean zero setting Error': '374302 / 1048064', 'FP32-BF16 mean std setting Error': '476381 / 1048064'}\n",
      "70\n",
      "idx :  3\n",
      "layer name :  conv2_x.1.residual_function.1\n",
      "chunk based sum result : 191545/8323072 = 2.3013739585876465%\n",
      "chunk based sum result : 1520186/8323072 = 18.26472282409668%\n",
      "chunk based sum result : 1629123/8323072 = 19.573577880859375%\n",
      "chunk based sum result : 3896702/8323072 = 46.81807327270508%\n",
      "{'epoch': 70, 'layer': 'conv2_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0023, 0.0042, 0.0081, 0.0021, 0.0057, 0.0080, 0.0057, 0.0108, 0.0062,\n",
      "        0.0059, 0.0023, 0.0025, 0.0134, 0.0025, 0.0063, 0.0077, 0.0043, 0.0092,\n",
      "        0.0037, 0.0066, 0.0114, 0.0063, 0.0052, 0.0069, 0.0185, 0.0031, 0.0030,\n",
      "        0.0045, 0.0023, 0.0022, 0.0044, 0.0038, 0.0041, 0.0038, 0.0038, 0.0040,\n",
      "        0.0094, 0.0068, 0.0069, 0.0023, 0.0073, 0.0028, 0.0037, 0.0101, 0.0034,\n",
      "        0.0059, 0.0044, 0.0097, 0.0041, 0.0065, 0.0047, 0.0019, 0.0056, 0.0049,\n",
      "        0.0040, 0.0081, 0.0028, 0.0025, 0.0032, 0.0052, 0.0033, 0.0027, 0.0054,\n",
      "        0.0045]), 'FP32-FP16_L_inf': tensor([0.0737, 0.0854, 0.1735, 0.0615, 0.4232, 0.1484, 0.1982, 0.1460, 0.1500,\n",
      "        0.2347, 0.0722, 0.0899, 0.3880, 0.0989, 0.1918, 0.1618, 0.1141, 0.2679,\n",
      "        0.0852, 0.1192, 0.1068, 0.1749, 0.1326, 0.1370, 0.1278, 0.1413, 0.1396,\n",
      "        0.0702, 0.0888, 0.0553, 0.2825, 0.0962, 0.0934, 0.1470, 0.1166, 0.1095,\n",
      "        0.2612, 0.1780, 0.1075, 0.1212, 0.1441, 0.0785, 0.1463, 0.3809, 0.0815,\n",
      "        0.1575, 0.1393, 0.2449, 0.0904, 0.1115, 0.1694, 0.0492, 0.0729, 0.2596,\n",
      "        0.1114, 0.1063, 0.1107, 0.0346, 0.1498, 0.1452, 0.0619, 0.0710, 0.1101,\n",
      "        0.1086]), 'FP32-FP16 mean zero setting Error': '200662 / 8388544', 'FP32-FP16 mean std setting Error': '1533060 / 8388544', 'FP32-BF16_mse': tensor([0.9554, 1.3922, 2.3618, 1.0463, 0.4917, 2.2335, 2.0083, 2.5808, 1.7174,\n",
      "        1.6038, 0.9261, 0.6910, 0.2694, 1.0142, 1.5829, 3.4265, 1.1693, 1.3994,\n",
      "        1.0629, 2.4974, 2.5352, 2.7065, 1.3181, 2.0087, 2.1867, 0.6130, 0.7200,\n",
      "        1.4542, 1.0059, 0.8366, 0.5430, 1.2610, 1.1959, 1.0683, 1.1339, 1.1584,\n",
      "        0.9871, 1.7654, 2.0708, 0.7969, 2.3358, 0.9220, 0.9537, 1.2680, 0.8003,\n",
      "        1.5683, 1.2782, 2.3409, 1.2302, 1.9739, 1.1359, 0.9477, 1.1799, 0.4658,\n",
      "        1.1544, 3.2214, 0.8111, 1.2706, 0.6407, 0.8988, 1.4176, 1.3232, 1.8774,\n",
      "        1.4293]), 'FP32-bf16_L_inf': tensor([30.3619, 25.4145, 15.3855, 32.4003, 31.0911, 15.8540, 26.7789,  8.0676,\n",
      "        25.7146, 35.0452, 24.0442, 25.3986,  4.3067, 40.4357, 26.4557,  6.7212,\n",
      "        23.8417, 12.4658, 25.0809, 11.8330,  6.7546, 14.5385, 19.5416, 15.9534,\n",
      "         4.1783, 27.5492, 33.2509, 16.3532, 36.0284, 20.4488, 32.0365, 21.6375,\n",
      "        23.9781, 35.1772, 33.1520, 27.4480, 19.1982, 13.8506, 14.8021, 40.2171,\n",
      "        14.6988, 23.3124, 31.8939, 12.3606, 19.1907, 27.2299, 30.2925, 12.8069,\n",
      "        22.0740, 20.7114, 23.6586, 23.9340, 17.1593, 24.4781, 24.9915,  9.0981,\n",
      "        31.3563, 17.9217, 29.2542, 15.8821, 21.3870, 43.3827, 19.9045, 27.9318]), 'FP32-BF16 mean zero setting Error': '1680121 / 8388544', 'FP32-BF16 mean std setting Error': '3949566 / 8388544'}\n",
      "idx :  9\n",
      "layer name :  conv4_x.0.residual_function.1\n",
      "chunk based sum result : 2820/1835008 = 0.1536778062582016%\n",
      "chunk based sum result : 75475/1835008 = 4.11306095123291%\n",
      "chunk based sum result : 22606/1835008 = 1.2319291830062866%\n",
      "chunk based sum result : 196644/1835008 = 10.71624755859375%\n",
      "{'epoch': 70, 'layer': 'conv4_x.0.residual_function.1', 'FP32-FP16_mse': tensor([0.0025, 0.0041, 0.0085, 0.0021, 0.0031, 0.0029, 0.0021, 0.0088, 0.0031,\n",
      "        0.0025, 0.0299, 0.0028, 0.0089, 0.0034, 0.0024, 0.0043, 0.0030, 0.0051,\n",
      "        0.0026, 0.0024, 0.0023, 0.0036, 0.0034, 0.0030, 0.0025, 0.0034, 0.0109,\n",
      "        0.0031, 0.0039, 0.0032, 0.0037, 0.0025, 0.0066, 0.0032, 0.0124, 0.0040,\n",
      "        0.0026, 0.0031, 0.0094, 0.0033, 0.0032, 0.0049, 0.0040, 0.0055, 0.0033,\n",
      "        0.0028, 0.0035, 0.0020, 0.0039, 0.0035, 0.0031, 0.0025, 0.0054, 0.0026,\n",
      "        0.0083, 0.0025, 0.0064, 0.0028, 0.0029, 0.0022, 0.0026, 0.0027, 0.0030,\n",
      "        0.0027, 0.0099, 0.0038, 0.0034, 0.0022, 0.0101, 0.0031, 0.0044, 0.0030,\n",
      "        0.0028, 0.0035, 0.0036, 0.0053, 0.0038, 0.0045, 0.0031, 0.0053, 0.0035,\n",
      "        0.0058, 0.0048, 0.0084, 0.0064, 0.0031, 0.0037, 0.0022, 0.0031, 0.0080,\n",
      "        0.0034, 0.0028, 0.0015, 0.0034, 0.0027, 0.0030, 0.0079, 0.0024, 0.0028,\n",
      "        0.0032, 0.0074, 0.0042, 0.0038, 0.0025, 0.0033, 0.0071, 0.0024, 0.0028,\n",
      "        0.0056, 0.0030, 0.0089, 0.0030, 0.0036, 0.0085, 0.0030, 0.0029, 0.0033,\n",
      "        0.0035, 0.0031, 0.0030, 0.0043, 0.0034, 0.0031, 0.0029, 0.0029, 0.0028,\n",
      "        0.0071, 0.0036, 0.0030, 0.0018, 0.0040, 0.0026, 0.0031, 0.0029, 0.0033,\n",
      "        0.0057, 0.0028, 0.0025, 0.0025, 0.0025, 0.0065, 0.0031, 0.0045, 0.0102,\n",
      "        0.0039, 0.0056, 0.0079, 0.0032, 0.0043, 0.0036, 0.0073, 0.0063, 0.0042,\n",
      "        0.0150, 0.0052, 0.0036, 0.0059, 0.0039, 0.0037, 0.0034, 0.0061, 0.0123,\n",
      "        0.0029, 0.0021, 0.0045, 0.0069, 0.0059, 0.0029, 0.0039, 0.0025, 0.0026,\n",
      "        0.0022, 0.0047, 0.0039, 0.0086, 0.0050, 0.0032, 0.0034, 0.0021, 0.0137,\n",
      "        0.0079, 0.0036, 0.0043, 0.0029, 0.0025, 0.0035, 0.0025, 0.0031, 0.0105,\n",
      "        0.0025, 0.0030, 0.0034, 0.0028, 0.0035, 0.0026, 0.0032, 0.0022, 0.0087,\n",
      "        0.0020, 0.0036, 0.0033, 0.0022, 0.0023, 0.0025, 0.0029, 0.0028, 0.0043,\n",
      "        0.0030, 0.0030, 0.0029, 0.0023, 0.0022, 0.0034, 0.0031, 0.0034, 0.0030,\n",
      "        0.0031, 0.0140, 0.0021, 0.0051, 0.0068, 0.0087, 0.0025, 0.0033, 0.0029,\n",
      "        0.0050, 0.0052, 0.0029, 0.0034, 0.0042, 0.0025, 0.0028, 0.0033, 0.0035,\n",
      "        0.0027, 0.0027, 0.0036, 0.0025, 0.0022, 0.0066, 0.0047, 0.0038, 0.0033,\n",
      "        0.0032, 0.0037, 0.0119, 0.0032, 0.0031, 0.0086, 0.0021, 0.0054, 0.0053,\n",
      "        0.0030, 0.0156, 0.0054, 0.0025]), 'FP32-FP16_L_inf': tensor([0.0718, 0.0670, 0.0911, 0.0510, 0.0676, 0.1059, 0.0424, 0.0759, 0.0773,\n",
      "        0.0513, 0.1275, 0.0760, 0.1066, 0.0850, 0.0409, 0.1098, 0.0531, 0.0856,\n",
      "        0.0693, 0.0390, 0.0421, 0.0993, 0.0532, 0.0400, 0.0397, 0.0714, 0.0961,\n",
      "        0.0779, 0.0993, 0.0552, 0.0819, 0.0451, 0.0953, 0.1346, 0.0875, 0.0712,\n",
      "        0.0749, 0.1505, 0.0704, 0.0731, 0.1118, 0.0791, 0.1907, 0.0878, 0.0717,\n",
      "        0.0420, 0.1133, 0.0346, 0.1024, 0.0468, 0.0375, 0.0567, 0.0721, 0.0389,\n",
      "        0.0864, 0.0522, 0.0877, 0.0394, 0.1178, 0.0423, 0.0456, 0.0529, 0.0546,\n",
      "        0.0611, 0.0830, 0.1116, 0.1077, 0.0800, 0.0828, 0.0530, 0.0538, 0.0567,\n",
      "        0.0610, 0.0796, 0.0746, 0.0526, 0.0538, 0.0495, 0.0563, 0.0570, 0.0919,\n",
      "        0.0571, 0.0900, 0.0927, 0.0880, 0.0529, 0.1163, 0.0502, 0.1129, 0.0644,\n",
      "        0.0493, 0.0854, 0.0303, 0.0675, 0.0420, 0.0715, 0.1439, 0.0344, 0.0772,\n",
      "        0.0589, 0.0615, 0.0867, 0.1194, 0.0606, 0.0788, 0.0776, 0.0722, 0.0807,\n",
      "        0.0621, 0.0505, 0.0757, 0.0712, 0.0666, 0.0942, 0.0494, 0.0839, 0.0805,\n",
      "        0.0763, 0.0590, 0.0691, 0.0511, 0.0637, 0.0424, 0.0815, 0.0523, 0.0944,\n",
      "        0.0706, 0.0525, 0.0826, 0.0583, 0.0862, 0.0506, 0.0606, 0.0457, 0.0985,\n",
      "        0.0685, 0.0805, 0.0426, 0.0547, 0.0738, 0.0690, 0.0753, 0.1075, 0.0643,\n",
      "        0.0882, 0.0651, 0.0658, 0.0586, 0.0612, 0.0775, 0.0860, 0.0649, 0.0569,\n",
      "        0.0802, 0.0692, 0.0885, 0.0656, 0.0717, 0.0611, 0.0438, 0.0730, 0.0900,\n",
      "        0.0730, 0.0641, 0.0824, 0.0814, 0.0896, 0.0568, 0.0832, 0.0614, 0.0609,\n",
      "        0.0342, 0.0671, 0.0620, 0.0794, 0.0849, 0.0573, 0.0505, 0.0623, 0.1253,\n",
      "        0.0815, 0.1050, 0.0508, 0.0454, 0.0613, 0.0650, 0.0684, 0.0598, 0.0649,\n",
      "        0.0630, 0.0719, 0.0678, 0.0656, 0.0753, 0.0383, 0.1262, 0.0489, 0.0675,\n",
      "        0.0639, 0.0424, 0.0650, 0.0705, 0.0268, 0.0392, 0.0403, 0.0873, 0.0673,\n",
      "        0.0958, 0.0616, 0.0605, 0.0471, 0.0547, 0.0779, 0.0464, 0.1023, 0.0707,\n",
      "        0.0739, 0.0939, 0.0350, 0.0780, 0.0721, 0.0781, 0.0645, 0.0558, 0.0722,\n",
      "        0.1057, 0.1170, 0.0459, 0.1995, 0.1007, 0.0473, 0.0580, 0.0510, 0.0911,\n",
      "        0.0856, 0.0685, 0.0597, 0.0399, 0.0386, 0.0554, 0.0643, 0.0619, 0.0886,\n",
      "        0.0552, 0.1356, 0.1011, 0.0561, 0.0681, 0.1337, 0.0514, 0.0505, 0.0737,\n",
      "        0.0588, 0.0856, 0.0944, 0.0567]), 'FP32-FP16 mean zero setting Error': '47692 / 2096896', 'FP32-FP16 mean std setting Error': '142425 / 2096896', 'FP32-BF16_mse': tensor([0.6424, 0.8509, 1.0332, 0.5952, 0.7694, 0.5399, 0.6841, 1.7654, 0.4936,\n",
      "        0.4959, 2.5314, 0.4950, 1.2000, 0.5284, 0.5220, 0.4614, 0.5297, 0.9857,\n",
      "        0.5443, 0.4990, 0.4115, 0.5208, 0.6425, 0.6243, 0.7125, 0.6876, 1.5484,\n",
      "        0.4393, 0.3917, 0.5336, 0.4554, 0.7382, 0.7958, 0.5359, 1.6837, 0.7888,\n",
      "        0.3537, 0.5045, 1.6826, 0.4557, 0.4839, 0.7094, 0.4439, 0.9549, 0.6539,\n",
      "        0.6741, 0.4839, 0.6281, 0.7135, 0.7194, 0.5379, 0.6579, 0.8194, 0.5993,\n",
      "        1.2065, 0.4617, 1.4191, 0.3640, 0.4702, 0.4535, 0.5784, 0.4792, 0.6298,\n",
      "        0.4798, 1.2469, 0.3578, 0.4782, 0.5365, 1.5106, 0.5178, 0.9606, 0.5636,\n",
      "        0.5364, 0.7684, 0.3644, 1.0198, 0.9075, 1.1749, 0.7091, 1.1658, 0.8594,\n",
      "        1.2152, 0.5653, 1.5334, 1.3446, 0.5378, 0.4295, 0.5777, 0.5447, 1.3792,\n",
      "        0.9194, 0.7519, 0.6579, 0.3792, 0.5761, 0.4758, 1.1776, 0.5189, 0.4920,\n",
      "        0.8446, 1.3529, 0.5730, 0.3297, 0.4964, 0.4523, 1.4758, 0.4594, 0.4797,\n",
      "        0.8608, 0.6952, 1.3699, 0.6999, 0.5662, 1.0822, 0.5622, 0.4750, 0.4622,\n",
      "        0.6507, 0.5306, 0.4840, 1.0727, 0.8401, 0.5150, 0.7376, 0.7425, 0.4841,\n",
      "        1.4513, 0.7951, 0.3921, 0.4287, 0.4549, 0.5871, 0.5405, 0.4647, 0.4089,\n",
      "        1.2347, 0.4624, 0.6903, 0.7961, 0.4733, 0.9696, 0.5765, 0.7096, 1.7251,\n",
      "        0.5986, 1.1686, 1.3792, 0.6126, 1.1673, 0.4482, 1.2078, 1.1392, 1.0917,\n",
      "        2.0898, 1.2649, 0.5596, 1.0299, 0.5692, 0.5763, 0.5077, 0.9244, 1.5826,\n",
      "        0.6070, 0.4600, 0.7011, 1.3011, 1.1705, 0.5804, 0.6568, 0.6337, 0.6093,\n",
      "        0.5932, 0.8285, 0.7039, 1.3403, 0.7434, 0.5767, 0.4720, 0.4855, 1.7090,\n",
      "        1.3943, 0.5352, 1.0367, 0.7395, 0.3952, 0.7752, 0.3970, 0.5981, 1.5891,\n",
      "        0.5669, 0.6781, 0.7320, 0.4538, 0.6573, 0.7461, 0.4653, 0.4576, 1.6064,\n",
      "        0.3677, 0.9233, 0.4644, 0.4542, 0.5106, 0.5497, 0.7156, 0.3726, 0.8490,\n",
      "        0.5677, 0.3585, 0.4492, 0.5477, 0.5547, 0.4150, 0.4496, 0.3985, 0.5849,\n",
      "        0.4218, 2.2917, 0.4706, 1.0546, 0.8664, 1.3635, 0.4188, 0.5092, 0.4418,\n",
      "        0.9781, 0.8563, 0.4535, 0.4397, 0.5528, 0.5722, 0.5671, 0.6619, 0.8059,\n",
      "        0.6390, 0.5278, 0.7016, 0.6239, 0.4763, 1.5134, 1.1357, 0.6993, 0.6970,\n",
      "        0.5322, 0.6671, 1.1917, 0.5915, 0.4914, 0.9789, 0.4586, 1.4352, 1.5560,\n",
      "        0.4975, 1.3576, 0.7677, 0.4881]), 'FP32-bf16_L_inf': tensor([11.1021,  9.0810,  6.1829, 10.3702, 12.2897, 13.7539, 12.8402,  7.3705,\n",
      "        12.0033,  9.5578,  3.3329, 10.6199,  8.4377, 13.0019,  9.1692,  8.1728,\n",
      "         8.4973, 10.3793, 10.4230,  8.3644,  6.3552, 10.5896,  9.0558,  7.2672,\n",
      "         9.3900,  9.4962,  4.3117, 11.2364, 10.1057,  9.8159, 10.2295, 11.3798,\n",
      "         6.2973, 22.8513,  3.4858, 10.9424, 10.0443, 22.6164,  6.2723,  9.6228,\n",
      "        17.8185,  5.5150, 21.2291,  8.4780, 10.4978,  8.3833, 12.2564,  9.5640,\n",
      "         8.7860,  6.1149,  6.5065, 10.4204,  6.0506,  8.7911,  5.7775,  9.6996,\n",
      "         8.2592,  5.3150, 15.6192,  8.5043,  7.7488,  9.4176,  8.7831, 11.0556,\n",
      "         3.8041,  8.7199, 15.5840, 19.4056,  7.9504,  7.4377,  6.3515, 11.3579,\n",
      "        11.9572, 13.8064,  6.7297,  5.5186,  8.1623,  8.1868,  7.8640,  6.1561,\n",
      "        15.9296,  8.2677,  5.5563,  5.5986,  7.8097,  7.4011, 13.6570, 11.7926,\n",
      "         9.7632,  6.8735, 10.3151, 12.3131, 13.7369,  7.4250,  7.3720, 10.6456,\n",
      "        10.5398,  7.0250, 10.6835,  9.6582,  6.1726,  8.7112, 10.5790, 11.8077,\n",
      "        10.6419,  7.8282, 13.4400, 13.6978,  5.4482,  9.0772,  5.5998, 10.9293,\n",
      "         7.0721,  5.3987,  6.3538, 13.7358, 11.7384,  9.6280,  8.5905, 10.9275,\n",
      "         7.0822, 11.8280,  7.5358, 13.0890,  7.8398, 16.4340, 10.9997,  7.6194,\n",
      "        10.2897, 14.4216,  9.6753,  9.6081, 10.2264,  7.1208, 11.8359,  5.0785,\n",
      "        13.5508,  9.4331, 13.2567, 13.0872,  6.9980, 10.2969, 11.0989,  5.4284,\n",
      "         8.2055,  6.5831,  5.0361, 10.5247,  8.2750,  9.5958,  7.5927,  5.1822,\n",
      "         8.6203,  2.9959,  9.4227, 11.0250,  8.9217,  8.9168,  5.5938,  6.7390,\n",
      "         5.2066,  4.2399, 12.7206, 13.1926,  7.9120, 10.0435, 10.6714, 10.0172,\n",
      "         9.5754, 12.6350,  9.5356,  8.1772,  7.8081,  7.8034,  5.7843,  5.8432,\n",
      "         9.8169,  6.9655, 14.8383,  2.3187, 10.3687,  8.2160,  6.9115,  8.8962,\n",
      "         9.2773,  8.8211, 10.4629,  9.0083,  5.6319, 13.2719, 11.3353, 10.7699,\n",
      "        10.6154, 11.4016,  8.4866, 18.2564,  7.8328,  4.3080, 10.6880,  9.6478,\n",
      "         8.0218, 13.8927,  5.3638,  8.8013,  7.9919, 11.8484,  6.6648, 15.9066,\n",
      "         6.1167,  9.8385, 11.4741, 11.5893,  9.3568,  6.7246, 12.2810, 10.5454,\n",
      "         9.3306,  3.9154,  8.0664,  6.4364,  5.4240,  8.4165,  9.3618,  8.6336,\n",
      "        11.8079, 13.8423,  9.6894,  7.0117, 26.0832,  9.2368,  6.9781, 11.9128,\n",
      "         7.4370, 18.1406, 15.2345, 11.1373,  6.0703, 10.2159,  8.4209,  7.4936,\n",
      "         7.8545,  5.7898, 10.3785,  8.7624, 12.4165,  2.3206,  9.0695, 10.7780,\n",
      "         5.6317, 10.8253,  9.7018, 12.0714,  8.7428,  3.0123,  7.2668, 11.2409]), 'FP32-BF16 mean zero setting Error': '211043 / 2096896', 'FP32-BF16 mean std setting Error': '409614 / 2096896'}\n",
      "idx :  15\n",
      "layer name :  conv5_x.1.residual_function.1\n",
      "chunk based sum result : 315/524288 = 0.06008148193359375%\n",
      "chunk based sum result : 13866/524288 = 2.6447296142578125%\n",
      "chunk based sum result : 2640/524288 = 0.5035400390625%\n",
      "chunk based sum result : 35642/524288 = 6.7981719970703125%\n",
      "{'epoch': 70, 'layer': 'conv5_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0021, 0.0039, 0.0031, 0.0079, 0.0023, 0.0034, 0.0030, 0.0109, 0.0025,\n",
      "        0.0030, 0.0035, 0.0044, 0.0037, 0.0028, 0.0027, 0.0023, 0.0062, 0.0037,\n",
      "        0.0026, 0.0034, 0.0025, 0.0028, 0.0050, 0.0047, 0.0031, 0.0021, 0.0033,\n",
      "        0.0027, 0.0031, 0.0028, 0.0020, 0.0021, 0.0028, 0.0039, 0.0028, 0.0074,\n",
      "        0.0026, 0.0023, 0.0028, 0.0026, 0.0032, 0.0029, 0.0030, 0.0028, 0.0025,\n",
      "        0.0023, 0.0031, 0.0031, 0.0030, 0.0083, 0.0022, 0.0036, 0.0028, 0.0032,\n",
      "        0.0043, 0.0028, 0.0028, 0.0028, 0.0033, 0.0032, 0.0043, 0.0034, 0.0028,\n",
      "        0.0023, 0.0042, 0.0022, 0.0028, 0.0041, 0.0027, 0.0032, 0.0028, 0.0026,\n",
      "        0.0084, 0.0025, 0.0031, 0.0026, 0.0027, 0.0021, 0.0044, 0.0030, 0.0027,\n",
      "        0.0035, 0.0027, 0.0022, 0.0025, 0.0031, 0.0033, 0.0031, 0.0032, 0.0035,\n",
      "        0.0025, 0.0089, 0.0024, 0.0028, 0.0022, 0.0024, 0.0050, 0.0033, 0.0026,\n",
      "        0.0026, 0.0031, 0.0031, 0.0022, 0.0028, 0.0019, 0.0076, 0.0023, 0.0080,\n",
      "        0.0030, 0.0044, 0.0026, 0.0033, 0.0041, 0.0040, 0.0032, 0.0037, 0.0051,\n",
      "        0.0035, 0.0030, 0.0024, 0.0030, 0.0027, 0.0022, 0.0032, 0.0018, 0.0026,\n",
      "        0.0025, 0.0031, 0.0040, 0.0071, 0.0032, 0.0026, 0.0034, 0.0036, 0.0024,\n",
      "        0.0027, 0.0030, 0.0026, 0.0045, 0.0030, 0.0078, 0.0051, 0.0043, 0.0037,\n",
      "        0.0035, 0.0075, 0.0022, 0.0032, 0.0046, 0.0026, 0.0023, 0.0025, 0.0033,\n",
      "        0.0026, 0.0031, 0.0022, 0.0053, 0.0034, 0.0029, 0.0043, 0.0029, 0.0025,\n",
      "        0.0050, 0.0021, 0.0032, 0.0023, 0.0026, 0.0023, 0.0027, 0.0027, 0.0023,\n",
      "        0.0045, 0.0022, 0.0041, 0.0020, 0.0053, 0.0031, 0.0024, 0.0030, 0.0025,\n",
      "        0.0037, 0.0027, 0.0052, 0.0038, 0.0031, 0.0022, 0.0091, 0.0019, 0.0084,\n",
      "        0.0018, 0.0023, 0.0030, 0.0023, 0.0055, 0.0029, 0.0026, 0.0032, 0.0090,\n",
      "        0.0022, 0.0023, 0.0044, 0.0114, 0.0028, 0.0049, 0.0033, 0.0024, 0.0041,\n",
      "        0.0028, 0.0033, 0.0026, 0.0023, 0.0045, 0.0031, 0.0022, 0.0028, 0.0017,\n",
      "        0.0023, 0.0029, 0.0032, 0.0027, 0.0028, 0.0041, 0.0032, 0.0022, 0.0031,\n",
      "        0.0024, 0.0035, 0.0044, 0.0070, 0.0025, 0.0031, 0.0028, 0.0039, 0.0081,\n",
      "        0.0042, 0.0060, 0.0037, 0.0031, 0.0027, 0.0024, 0.0030, 0.0015, 0.0031,\n",
      "        0.0020, 0.0050, 0.0031, 0.0021, 0.0024, 0.0031, 0.0024, 0.0029, 0.0022,\n",
      "        0.0025, 0.0030, 0.0031, 0.0026, 0.0025, 0.0047, 0.0026, 0.0030, 0.0033,\n",
      "        0.0015, 0.0033, 0.0027, 0.0020, 0.0018, 0.0023, 0.0039, 0.0034, 0.0066,\n",
      "        0.0033, 0.0029, 0.0041, 0.0034, 0.0033, 0.0023, 0.0027, 0.0025, 0.0031,\n",
      "        0.0056, 0.0037, 0.0031, 0.0027, 0.0055, 0.0039, 0.0053, 0.0031, 0.0030,\n",
      "        0.0028, 0.0021, 0.0027, 0.0029, 0.0033, 0.0067, 0.0036, 0.0037, 0.0030,\n",
      "        0.0043, 0.0029, 0.0030, 0.0025, 0.0028, 0.0037, 0.0045, 0.0029, 0.0029,\n",
      "        0.0059, 0.0032, 0.0081, 0.0031, 0.0041, 0.0027, 0.0030, 0.0052, 0.0030,\n",
      "        0.0042, 0.0031, 0.0036, 0.0022, 0.0027, 0.0078, 0.0031, 0.0030, 0.0042,\n",
      "        0.0027, 0.0045, 0.0027, 0.0030, 0.0033, 0.0025, 0.0030, 0.0021, 0.0023,\n",
      "        0.0034, 0.0027, 0.0031, 0.0026, 0.0041, 0.0047, 0.0032, 0.0079, 0.0032,\n",
      "        0.0039, 0.0030, 0.0025, 0.0019, 0.0025, 0.0026, 0.0036, 0.0018, 0.0022,\n",
      "        0.0026, 0.0087, 0.0027, 0.0079, 0.0033, 0.0034, 0.0033, 0.0029, 0.0025,\n",
      "        0.0028, 0.0029, 0.0068, 0.0045, 0.0031, 0.0022, 0.0036, 0.0023, 0.0035,\n",
      "        0.0037, 0.0033, 0.0021, 0.0024, 0.0064, 0.0024, 0.0023, 0.0029, 0.0036,\n",
      "        0.0040, 0.0080, 0.0023, 0.0024, 0.0028, 0.0030, 0.0029, 0.0027, 0.0019,\n",
      "        0.0066, 0.0074, 0.0030, 0.0026, 0.0025, 0.0027, 0.0026, 0.0028, 0.0018,\n",
      "        0.0031, 0.0027, 0.0034, 0.0023, 0.0028, 0.0033, 0.0024, 0.0025, 0.0029,\n",
      "        0.0022, 0.0030, 0.0061, 0.0029, 0.0039, 0.0020, 0.0036, 0.0036, 0.0043,\n",
      "        0.0029, 0.0028, 0.0029, 0.0080, 0.0028, 0.0025, 0.0033, 0.0030, 0.0033,\n",
      "        0.0030, 0.0021, 0.0034, 0.0023, 0.0023, 0.0036, 0.0097, 0.0026, 0.0023,\n",
      "        0.0025, 0.0030, 0.0028, 0.0029, 0.0027, 0.0043, 0.0033, 0.0032, 0.0025,\n",
      "        0.0026, 0.0036, 0.0033, 0.0032, 0.0050, 0.0027, 0.0026, 0.0035, 0.0035,\n",
      "        0.0022, 0.0024, 0.0044, 0.0032, 0.0028, 0.0028, 0.0030, 0.0023, 0.0037,\n",
      "        0.0023, 0.0038, 0.0034, 0.0040, 0.0045, 0.0026, 0.0031, 0.0042, 0.0028,\n",
      "        0.0034, 0.0022, 0.0083, 0.0036, 0.0021, 0.0023, 0.0026, 0.0060, 0.0038,\n",
      "        0.0061, 0.0032, 0.0024, 0.0024, 0.0024, 0.0036, 0.0022, 0.0033, 0.0028,\n",
      "        0.0023, 0.0035, 0.0033, 0.0067, 0.0041, 0.0070, 0.0037, 0.0024, 0.0021,\n",
      "        0.0023, 0.0043, 0.0044, 0.0023, 0.0026, 0.0029, 0.0030, 0.0030, 0.0020,\n",
      "        0.0032, 0.0029, 0.0031, 0.0030, 0.0031, 0.0042, 0.0032, 0.0050]), 'FP32-FP16_L_inf': tensor([0.0288, 0.0788, 0.0657, 0.0936, 0.0568, 0.0597, 0.0600, 0.1180, 0.0579,\n",
      "        0.0536, 0.0993, 0.0964, 0.0774, 0.0653, 0.0641, 0.0477, 0.0772, 0.0812,\n",
      "        0.0593, 0.0500, 0.0433, 0.0478, 0.0652, 0.0743, 0.0721, 0.0400, 0.0856,\n",
      "        0.0405, 0.0528, 0.0770, 0.0481, 0.0532, 0.0558, 0.0734, 0.0453, 0.0858,\n",
      "        0.0578, 0.0487, 0.0563, 0.0974, 0.0620, 0.0489, 0.0995, 0.0464, 0.0388,\n",
      "        0.0483, 0.0408, 0.0774, 0.0484, 0.0643, 0.0524, 0.0563, 0.0489, 0.0676,\n",
      "        0.0556, 0.0465, 0.0922, 0.0514, 0.0852, 0.0940, 0.0652, 0.0634, 0.0482,\n",
      "        0.0465, 0.0816, 0.0527, 0.0478, 0.0854, 0.0402, 0.1058, 0.0673, 0.0464,\n",
      "        0.1616, 0.0570, 0.0623, 0.0460, 0.0483, 0.0458, 0.0574, 0.0469, 0.0539,\n",
      "        0.0427, 0.0533, 0.0336, 0.0482, 0.0567, 0.0777, 0.0688, 0.0508, 0.0894,\n",
      "        0.0541, 0.0918, 0.0445, 0.0540, 0.0761, 0.0494, 0.0902, 0.0508, 0.0380,\n",
      "        0.0515, 0.0595, 0.0646, 0.0299, 0.0618, 0.0363, 0.0685, 0.0366, 0.0672,\n",
      "        0.0729, 0.0605, 0.0699, 0.0558, 0.0598, 0.0570, 0.0895, 0.0472, 0.0646,\n",
      "        0.0611, 0.0613, 0.0578, 0.0966, 0.0755, 0.0407, 0.0761, 0.0461, 0.0381,\n",
      "        0.0374, 0.0597, 0.0784, 0.0903, 0.0445, 0.0564, 0.0721, 0.0493, 0.0594,\n",
      "        0.0383, 0.0798, 0.0602, 0.0986, 0.0863, 0.1392, 0.0810, 0.1362, 0.0892,\n",
      "        0.1186, 0.0936, 0.0570, 0.0519, 0.0866, 0.0573, 0.0533, 0.0870, 0.0523,\n",
      "        0.0526, 0.0973, 0.0362, 0.0682, 0.1020, 0.0414, 0.1065, 0.0977, 0.0561,\n",
      "        0.1137, 0.0421, 0.0809, 0.0407, 0.0558, 0.0388, 0.0576, 0.0513, 0.0352,\n",
      "        0.0625, 0.0451, 0.0621, 0.0316, 0.1053, 0.0669, 0.0508, 0.0448, 0.0857,\n",
      "        0.0746, 0.0696, 0.0945, 0.0736, 0.0710, 0.0579, 0.0810, 0.0373, 0.1082,\n",
      "        0.0526, 0.0780, 0.0613, 0.0362, 0.0764, 0.0489, 0.0414, 0.1039, 0.0921,\n",
      "        0.0421, 0.0504, 0.1337, 0.1111, 0.0536, 0.0995, 0.0494, 0.0405, 0.1020,\n",
      "        0.0589, 0.0635, 0.0426, 0.0645, 0.0877, 0.0701, 0.0393, 0.0648, 0.0442,\n",
      "        0.0550, 0.1127, 0.0991, 0.0904, 0.0715, 0.0965, 0.0499, 0.0447, 0.0472,\n",
      "        0.0616, 0.0611, 0.0713, 0.1116, 0.0710, 0.0551, 0.0524, 0.0774, 0.1343,\n",
      "        0.0866, 0.1029, 0.0645, 0.0705, 0.0535, 0.0545, 0.0481, 0.0364, 0.0592,\n",
      "        0.0276, 0.1038, 0.0731, 0.0484, 0.0446, 0.0687, 0.0361, 0.0761, 0.0575,\n",
      "        0.0399, 0.0978, 0.0633, 0.0582, 0.0474, 0.1038, 0.0627, 0.0935, 0.0718,\n",
      "        0.0287, 0.0694, 0.0418, 0.0386, 0.0567, 0.0681, 0.0665, 0.0768, 0.0974,\n",
      "        0.0523, 0.0642, 0.0588, 0.0664, 0.0866, 0.0358, 0.0619, 0.0642, 0.0661,\n",
      "        0.0652, 0.0642, 0.1301, 0.0407, 0.0844, 0.0729, 0.1200, 0.0609, 0.0965,\n",
      "        0.0592, 0.0305, 0.0699, 0.0642, 0.0554, 0.0666, 0.0589, 0.0685, 0.0651,\n",
      "        0.0788, 0.0626, 0.0570, 0.0488, 0.0479, 0.1138, 0.0722, 0.0952, 0.0403,\n",
      "        0.0668, 0.0571, 0.0675, 0.0533, 0.0851, 0.0557, 0.1504, 0.0605, 0.0900,\n",
      "        0.1052, 0.0844, 0.0604, 0.1458, 0.0558, 0.1164, 0.0571, 0.0520, 0.0890,\n",
      "        0.0666, 0.1020, 0.0482, 0.0584, 0.0548, 0.0755, 0.0847, 0.0584, 0.0370,\n",
      "        0.0661, 0.0539, 0.0829, 0.0809, 0.0526, 0.0997, 0.0556, 0.0810, 0.0677,\n",
      "        0.0716, 0.0641, 0.0319, 0.0364, 0.0374, 0.0526, 0.0480, 0.0507, 0.0363,\n",
      "        0.0496, 0.0763, 0.0715, 0.0696, 0.0663, 0.1802, 0.0751, 0.0632, 0.0415,\n",
      "        0.0523, 0.0765, 0.1270, 0.0576, 0.0608, 0.0712, 0.0798, 0.0347, 0.0626,\n",
      "        0.0814, 0.0540, 0.0379, 0.0366, 0.0869, 0.0292, 0.0347, 0.0529, 0.1171,\n",
      "        0.0587, 0.0765, 0.0805, 0.0380, 0.0797, 0.0646, 0.0785, 0.0514, 0.0397,\n",
      "        0.1238, 0.0884, 0.0509, 0.0800, 0.0307, 0.0559, 0.0433, 0.0720, 0.0410,\n",
      "        0.0572, 0.0465, 0.0700, 0.0736, 0.0426, 0.0561, 0.0434, 0.0543, 0.0429,\n",
      "        0.0373, 0.0409, 0.0933, 0.0659, 0.0618, 0.0470, 0.0612, 0.0808, 0.0770,\n",
      "        0.0666, 0.0438, 0.0459, 0.0889, 0.0480, 0.0682, 0.0604, 0.0590, 0.0629,\n",
      "        0.0445, 0.0423, 0.0699, 0.0392, 0.0376, 0.0558, 0.0756, 0.0399, 0.0623,\n",
      "        0.0475, 0.0983, 0.0674, 0.0491, 0.0559, 0.0795, 0.0625, 0.0520, 0.0521,\n",
      "        0.0428, 0.0942, 0.0691, 0.0689, 0.0841, 0.0711, 0.0432, 0.0544, 0.0793,\n",
      "        0.0362, 0.0433, 0.0935, 0.0832, 0.0620, 0.0902, 0.0417, 0.0417, 0.0650,\n",
      "        0.0665, 0.0531, 0.0569, 0.0652, 0.0894, 0.0504, 0.0814, 0.0830, 0.0519,\n",
      "        0.0581, 0.0929, 0.0949, 0.1108, 0.0384, 0.0594, 0.1243, 0.0985, 0.0789,\n",
      "        0.0804, 0.0665, 0.0426, 0.0563, 0.0426, 0.1050, 0.0589, 0.0747, 0.0678,\n",
      "        0.0557, 0.0525, 0.0671, 0.0888, 0.0718, 0.1089, 0.0796, 0.0363, 0.0274,\n",
      "        0.0401, 0.0824, 0.1102, 0.0468, 0.0463, 0.0802, 0.0758, 0.0509, 0.0368,\n",
      "        0.1032, 0.0722, 0.0455, 0.0776, 0.0884, 0.0683, 0.0653, 0.0835]), 'FP32-FP16 mean zero setting Error': '102308 / 1048064', 'FP32-FP16 mean std setting Error': '253945 / 1048064', 'FP32-BF16_mse': tensor([0.2554, 0.3073, 0.1570, 0.9277, 0.1559, 0.5077, 0.4321, 0.8087, 0.1325,\n",
      "        0.3620, 0.2169, 0.3465, 0.1711, 0.2016, 0.2525, 0.2500, 0.9072, 0.3163,\n",
      "        0.4531, 0.4818, 0.1965, 0.3005, 0.5489, 0.5318, 0.2015, 0.2406, 0.3240,\n",
      "        0.2603, 0.3867, 0.3297, 0.2033, 0.1749, 0.2125, 0.4074, 0.1943, 0.9082,\n",
      "        0.2629, 0.1721, 0.1691, 0.4793, 0.2294, 0.4103, 0.1893, 0.3016, 0.3270,\n",
      "        0.2528, 0.5627, 0.2130, 0.3965, 0.7243, 0.2646, 0.3803, 0.4219, 0.2535,\n",
      "        0.6405, 0.1947, 0.1661, 0.2015, 0.2045, 0.3243, 0.5976, 0.4744, 0.3450,\n",
      "        0.1694, 0.4174, 0.1469, 0.1746, 0.4680, 0.3332, 0.2556, 0.1657, 0.3007,\n",
      "        0.5650, 0.2481, 0.3392, 0.1817, 0.2904, 0.3041, 0.5862, 0.1571, 0.2141,\n",
      "        0.4416, 0.2795, 0.1539, 0.3097, 0.4119, 0.1944, 0.2412, 0.4025, 0.4216,\n",
      "        0.1936, 0.9965, 0.1468, 0.3311, 0.1198, 0.3125, 0.5788, 0.4497, 0.2386,\n",
      "        0.3306, 0.3861, 0.2479, 0.2769, 0.3704, 0.2301, 0.6627, 0.2073, 0.7010,\n",
      "        0.2570, 0.7052, 0.2890, 0.2276, 0.4613, 0.6439, 0.2040, 0.5000, 0.6543,\n",
      "        0.4445, 0.3079, 0.1827, 0.2267, 0.2767, 0.2997, 0.2342, 0.3439, 0.2339,\n",
      "        0.2437, 0.2571, 0.6153, 0.7755, 0.3042, 0.1973, 0.4829, 0.5811, 0.2696,\n",
      "        0.4920, 0.1582, 0.1740, 0.4440, 0.3727, 0.7544, 0.5217, 0.4306, 0.3553,\n",
      "        0.3014, 0.6226, 0.2758, 0.1478, 0.4987, 0.1893, 0.1782, 0.1720, 0.3529,\n",
      "        0.2045, 0.1759, 0.2119, 0.5356, 0.4850, 0.1869, 0.4116, 0.2093, 0.1546,\n",
      "        0.4916, 0.2070, 0.3296, 0.2310, 0.2735, 0.1586, 0.2520, 0.2376, 0.2160,\n",
      "        0.6013, 0.2135, 0.4562, 0.1994, 0.6901, 0.2556, 0.2159, 0.2945, 0.1536,\n",
      "        0.1716, 0.2340, 0.6292, 0.3967, 0.2185, 0.2105, 0.9469, 0.1559, 0.7469,\n",
      "        0.2633, 0.1689, 0.1857, 0.1740, 0.5958, 0.2564, 0.2935, 0.3673, 0.8677,\n",
      "        0.1944, 0.2486, 0.2958, 1.0568, 0.5005, 0.5643, 0.3996, 0.1503, 0.3775,\n",
      "        0.3376, 0.3007, 0.2771, 0.2087, 0.3392, 0.3465, 0.1855, 0.2298, 0.2136,\n",
      "        0.1723, 0.2456, 0.3376, 0.1768, 0.1729, 0.5146, 0.3809, 0.1921, 0.3612,\n",
      "        0.1960, 0.1912, 0.6565, 0.5910, 0.1861, 0.2364, 0.1986, 0.2113, 0.7797,\n",
      "        0.4861, 0.7190, 0.4884, 0.2881, 0.3102, 0.2069, 0.2401, 0.1757, 0.3271,\n",
      "        0.1700, 0.5018, 0.3789, 0.1979, 0.3318, 0.1742, 0.2300, 0.1932, 0.2125,\n",
      "        0.1537, 0.1587, 0.1773, 0.2685, 0.2476, 0.4518, 0.2405, 0.2211, 0.3147,\n",
      "        0.1468, 0.3007, 0.2062, 0.1564, 0.1249, 0.2293, 0.5819, 0.2434, 0.5993,\n",
      "        0.3311, 0.1415, 0.4971, 0.4304, 0.1569, 0.2192, 0.2652, 0.2072, 0.3541,\n",
      "        0.6351, 0.4624, 0.1690, 0.2577, 0.5159, 0.5205, 0.5798, 0.3162, 0.3351,\n",
      "        0.3802, 0.2295, 0.2972, 0.1692, 0.1569, 0.8451, 0.5554, 0.4206, 0.1587,\n",
      "        0.2684, 0.1630, 0.2564, 0.2949, 0.2327, 0.2803, 0.6006, 0.2658, 0.2456,\n",
      "        0.7360, 0.2558, 0.9421, 0.1687, 0.4890, 0.1417, 0.2259, 0.6923, 0.1578,\n",
      "        0.4917, 0.3825, 0.1906, 0.1886, 0.3725, 0.7728, 0.2007, 0.2348, 0.4191,\n",
      "        0.1871, 0.3944, 0.2617, 0.2413, 0.5332, 0.2176, 0.1804, 0.1573, 0.1926,\n",
      "        0.5155, 0.3968, 0.3904, 0.2378, 0.5032, 0.5259, 0.2460, 0.9280, 0.2050,\n",
      "        0.4738, 0.5130, 0.1986, 0.1437, 0.2456, 0.2441, 0.4496, 0.1940, 0.1806,\n",
      "        0.2504, 0.7662, 0.2190, 0.9262, 0.3406, 0.2544, 0.2356, 0.3406, 0.3733,\n",
      "        0.3841, 0.3030, 0.7255, 0.5000, 0.1546, 0.1725, 0.3692, 0.2483, 0.4781,\n",
      "        0.3976, 0.1796, 0.1819, 0.2891, 0.6600, 0.3149, 0.2684, 0.3766, 0.4532,\n",
      "        0.3890, 0.6497, 0.1275, 0.2556, 0.2673, 0.4292, 0.2305, 0.1475, 0.1295,\n",
      "        0.6491, 0.6999, 0.4205, 0.2446, 0.5153, 0.2422, 0.1704, 0.3175, 0.1801,\n",
      "        0.3682, 0.2466, 0.3523, 0.2302, 0.2362, 0.4275, 0.1883, 0.1513, 0.4840,\n",
      "        0.1951, 0.1750, 0.5197, 0.3601, 0.4683, 0.2522, 0.4624, 0.4425, 0.4745,\n",
      "        0.1546, 0.2002, 0.1913, 0.7885, 0.3666, 0.2190, 0.3429, 0.2372, 0.3954,\n",
      "        0.4272, 0.1691, 0.2375, 0.3183, 0.1949, 0.1567, 0.9416, 0.2959, 0.1503,\n",
      "        0.1994, 0.3184, 0.2097, 0.1575, 0.1827, 0.3502, 0.3260, 0.2429, 0.2098,\n",
      "        0.1624, 0.2581, 0.3312, 0.2550, 0.4380, 0.1601, 0.1616, 0.4607, 0.4209,\n",
      "        0.1799, 0.1556, 0.4296, 0.6011, 0.1545, 0.2140, 0.4453, 0.3127, 0.4415,\n",
      "        0.2397, 0.6188, 0.3378, 0.5238, 0.6337, 0.1548, 0.3000, 0.5948, 0.1702,\n",
      "        0.4437, 0.2224, 0.7079, 0.3146, 0.2667, 0.1364, 0.1671, 0.4731, 0.4818,\n",
      "        0.6403, 0.1830, 0.1511, 0.2885, 0.2666, 0.2266, 0.1816, 0.1590, 0.1779,\n",
      "        0.1405, 0.4316, 0.3686, 0.6973, 0.6469, 0.8534, 0.5113, 0.1622, 0.1764,\n",
      "        0.2635, 0.6162, 0.4901, 0.2004, 0.4602, 0.3090, 0.2595, 0.1637, 0.2625,\n",
      "        0.2101, 0.3090, 0.3227, 0.2612, 0.2129, 0.6106, 0.3391, 0.6000]), 'FP32-bf16_L_inf': tensor([2.5495, 3.2845, 3.2898, 2.6673, 3.6433, 2.4911, 2.8134, 1.6093, 3.0929,\n",
      "        2.8049, 3.7770, 3.0518, 3.7514, 4.4194, 3.7293, 3.6518, 2.6116, 3.2559,\n",
      "        2.7711, 2.8016, 3.3421, 2.5644, 2.1050, 2.7232, 3.8432, 3.5879, 4.9570,\n",
      "        2.9858, 2.0867, 4.6166, 3.0432, 4.5213, 4.5201, 3.4797, 3.3327, 2.1113,\n",
      "        2.9422, 2.9057, 3.3573, 4.3515, 3.1468, 2.9031, 6.4092, 2.6618, 2.5395,\n",
      "        3.2592, 3.5074, 3.9181, 2.6582, 1.1304, 3.6501, 3.0177, 2.4926, 4.3100,\n",
      "        2.6258, 2.9378, 4.4249, 3.7964, 4.0556, 3.7576, 2.5804, 2.6195, 2.0768,\n",
      "        3.3592, 2.8877, 3.2090, 2.9379, 4.3662, 2.9855, 5.6806, 3.9885, 3.4462,\n",
      "        2.4340, 2.8896, 3.0281, 2.9941, 2.8914, 2.9864, 2.0213, 2.4049, 3.1504,\n",
      "        2.6239, 3.7630, 2.2915, 3.5822, 3.1723, 3.6561, 3.3445, 2.7938, 4.8949,\n",
      "        3.9527, 2.8600, 2.6783, 3.5468, 3.6700, 2.2148, 2.9940, 2.4995, 3.5448,\n",
      "        2.9250, 2.5958, 3.3652, 2.7552, 3.9065, 3.3945, 1.5352, 3.2366, 1.3594,\n",
      "        3.7675, 2.4501, 5.2428, 3.0712, 2.1034, 2.8500, 5.2098, 2.2260, 2.3701,\n",
      "        2.6934, 3.2423, 2.7188, 6.9564, 5.1364, 3.7895, 4.4822, 3.6177, 2.3898,\n",
      "        2.5475, 3.7229, 2.5980, 2.8745, 3.0250, 3.0105, 4.4115, 2.7237, 5.5377,\n",
      "        2.9407, 4.2321, 4.1846, 3.8684, 3.6775, 2.5739, 2.9706, 4.8844, 4.2207,\n",
      "        4.1982, 2.4427, 3.3403, 2.3552, 3.4997, 3.3687, 4.0959, 5.9512, 2.9242,\n",
      "        3.0815, 5.5770, 3.0051, 2.4049, 4.8455, 2.7016, 3.3466, 6.0224, 3.1967,\n",
      "        3.7004, 4.2069, 3.9833, 3.2840, 3.2817, 2.3219, 3.3900, 3.5342, 2.6705,\n",
      "        1.8809, 4.3342, 2.7944, 2.4822, 3.3117, 3.6644, 3.5262, 3.2721, 4.0001,\n",
      "        3.6054, 2.6559, 2.4865, 2.9352, 5.1226, 3.8561, 2.1938, 2.9571, 2.5285,\n",
      "        2.8215, 4.5488, 3.5187, 2.8507, 1.8731, 3.2094, 2.6152, 5.2110, 1.7535,\n",
      "        3.4511, 4.5805, 5.2391, 1.5925, 2.7763, 3.1993, 2.4836, 2.6126, 4.8769,\n",
      "        3.3248, 3.0484, 2.2749, 3.6955, 3.8197, 3.7057, 2.8524, 4.1894, 5.3259,\n",
      "        3.5625, 5.3170, 4.3999, 6.0312, 4.0534, 2.4863, 2.8570, 3.1345, 2.1755,\n",
      "        4.5371, 3.2304, 2.4690, 2.5260, 5.2011, 3.4518, 3.4426, 3.1822, 2.4032,\n",
      "        2.8155, 1.7816, 4.3337, 5.0550, 3.6822, 3.8501, 3.1848, 4.0840, 3.0057,\n",
      "        2.5681, 3.1118, 3.8336, 2.6972, 3.5495, 4.0264, 2.5783, 4.8671, 4.4899,\n",
      "        2.5822, 4.9643, 3.4194, 4.0636, 2.1362, 3.1852, 4.8343, 4.1999, 3.9909,\n",
      "        2.3513, 3.7275, 2.7890, 3.2426, 3.9892, 4.9829, 2.6895, 3.9690, 1.7704,\n",
      "        3.2367, 2.7217, 2.5921, 3.4203, 3.7969, 2.9816, 4.5243, 3.6705, 3.2044,\n",
      "        1.9681, 3.0160, 5.9467, 2.9462, 2.4898, 3.1366, 3.2728, 3.0062, 3.4851,\n",
      "        4.2931, 2.4936, 4.0782, 3.5289, 2.6926, 2.1410, 2.7432, 3.3442, 2.8716,\n",
      "        3.9010, 3.3948, 3.8256, 3.1526, 2.9270, 5.3371, 3.7340, 6.9806, 3.0819,\n",
      "        2.3981, 3.1773, 1.8236, 2.9342, 2.8205, 2.6263, 7.8988, 2.4570, 4.4509,\n",
      "        3.6869, 5.0372, 3.2694, 9.3428, 3.0153, 2.4585, 3.1325, 3.0050, 3.3039,\n",
      "        3.9583, 3.6193, 3.2203, 3.6548, 3.5457, 3.1270, 2.6961, 3.2300, 2.5971,\n",
      "        2.1017, 4.0671, 3.5355, 5.0647, 2.1166, 4.0192, 3.5601, 1.2691, 4.5844,\n",
      "        3.1557, 3.3722, 2.5737, 2.8108, 3.0783, 2.9817, 2.5622, 3.6455, 2.2605,\n",
      "        4.1223, 1.5764, 4.7081, 2.3985, 3.1140, 9.7917, 3.3261, 2.6654, 2.0875,\n",
      "        3.3762, 4.4147, 2.7933, 2.4888, 2.8995, 5.3929, 3.9322, 3.0011, 2.7783,\n",
      "        3.4918, 3.1003, 2.1923, 3.8644, 1.9887, 2.5051, 3.0448, 3.4872, 4.4747,\n",
      "        2.2916, 1.8190, 4.6144, 3.6389, 4.6103, 3.0098, 4.4914, 2.7891, 2.0080,\n",
      "        2.0380, 2.1044, 2.5925, 2.3181, 2.6904, 2.7964, 2.7351, 4.2713, 2.8155,\n",
      "        3.3146, 3.1419, 4.3592, 5.4007, 3.0030, 3.7300, 2.5717, 3.2739, 2.0599,\n",
      "        3.1753, 2.4892, 1.6645, 3.6404, 2.0876, 3.7734, 2.6384, 3.1312, 2.8652,\n",
      "        2.9477, 2.3034, 2.7795, 1.3356, 2.1463, 5.8103, 3.8598, 4.8439, 3.9264,\n",
      "        2.9283, 3.4974, 3.6387, 3.3584, 3.3893, 2.4158, 1.2089, 3.4084, 4.1527,\n",
      "        3.0943, 6.7481, 3.5477, 2.7861, 3.9030, 4.2214, 4.1545, 3.1820, 4.2048,\n",
      "        2.6834, 4.1048, 3.2434, 3.6531, 2.9827, 4.2477, 2.5208, 2.8313, 4.1172,\n",
      "        2.7363, 2.6533, 3.6255, 3.5979, 3.2622, 4.0336, 2.7899, 3.3164, 2.9957,\n",
      "        5.6807, 2.0327, 2.6255, 2.5287, 2.9701, 2.1873, 3.4826, 3.7067, 3.1412,\n",
      "        2.8588, 4.7424, 1.6485, 5.4669, 2.9133, 3.5495, 7.9684, 2.3814, 4.1844,\n",
      "        2.0622, 3.7552, 2.6663, 3.4451, 4.2190, 6.0145, 4.1872, 3.6965, 4.6306,\n",
      "        3.5310, 2.5485, 3.7990, 2.4444, 3.3184, 2.3724, 3.3271, 2.6347, 2.3640,\n",
      "        2.0503, 2.7283, 3.6029, 4.1973, 2.8274, 5.3518, 3.9493, 2.8374, 4.5793,\n",
      "        6.3829, 3.9748, 3.4594, 3.4845, 4.8864, 3.1624, 2.4647, 3.1719]), 'FP32-BF16 mean zero setting Error': '379749 / 1048064', 'FP32-BF16 mean std setting Error': '474598 / 1048064'}\n",
      "100\n",
      "idx :  3\n",
      "layer name :  conv2_x.1.residual_function.1\n",
      "chunk based sum result : 189882/8323072 = 2.28139328956604%\n",
      "chunk based sum result : 1525496/8323072 = 18.328519821166992%\n",
      "chunk based sum result : 1620044/8323072 = 19.464496612548828%\n",
      "chunk based sum result : 3894591/8323072 = 46.79270935058594%\n",
      "{'epoch': 100, 'layer': 'conv2_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0022, 0.0041, 0.0076, 0.0020, 0.0049, 0.0083, 0.0059, 0.0108, 0.0052,\n",
      "        0.0059, 0.0022, 0.0025, 0.0133, 0.0022, 0.0065, 0.0077, 0.0040, 0.0092,\n",
      "        0.0036, 0.0069, 0.0114, 0.0058, 0.0057, 0.0079, 0.0183, 0.0031, 0.0031,\n",
      "        0.0041, 0.0023, 0.0023, 0.0043, 0.0046, 0.0046, 0.0038, 0.0034, 0.0044,\n",
      "        0.0086, 0.0071, 0.0071, 0.0024, 0.0075, 0.0033, 0.0033, 0.0092, 0.0033,\n",
      "        0.0057, 0.0044, 0.0092, 0.0040, 0.0064, 0.0049, 0.0018, 0.0052, 0.0049,\n",
      "        0.0037, 0.0082, 0.0028, 0.0029, 0.0032, 0.0051, 0.0033, 0.0027, 0.0052,\n",
      "        0.0043]), 'FP32-FP16_L_inf': tensor([0.0703, 0.0855, 0.1639, 0.0604, 0.3894, 0.1570, 0.1987, 0.1455, 0.1455,\n",
      "        0.2392, 0.0666, 0.0870, 0.3891, 0.0956, 0.1799, 0.1364, 0.1029, 0.2639,\n",
      "        0.0860, 0.1165, 0.1082, 0.1723, 0.1468, 0.1372, 0.1301, 0.1373, 0.1391,\n",
      "        0.0681, 0.0870, 0.0571, 0.2875, 0.1089, 0.1057, 0.1455, 0.1191, 0.1145,\n",
      "        0.2783, 0.1688, 0.1132, 0.1170, 0.1522, 0.0852, 0.1349, 0.3737, 0.0793,\n",
      "        0.1625, 0.1439, 0.2438, 0.0882, 0.1082, 0.1783, 0.0474, 0.0689, 0.2673,\n",
      "        0.1051, 0.1110, 0.1047, 0.0370, 0.1580, 0.1400, 0.0639, 0.0649, 0.1106,\n",
      "        0.1031]), 'FP32-FP16 mean zero setting Error': '198875 / 8388544', 'FP32-FP16 mean std setting Error': '1538446 / 8388544', 'FP32-BF16_mse': tensor([0.9631, 1.3955, 2.3892, 1.0632, 0.4515, 2.3209, 1.9494, 2.5558, 1.6650,\n",
      "        1.6512, 0.9160, 0.7130, 0.2671, 1.0125, 1.6195, 3.4621, 1.1849, 1.4046,\n",
      "        1.0792, 2.5062, 2.6096, 2.8047, 1.3365, 2.0793, 2.1163, 0.6176, 0.7302,\n",
      "        1.4345, 1.0349, 0.8469, 0.5279, 1.3556, 1.1814, 1.0708, 1.0985, 1.1755,\n",
      "        1.0503, 1.7382, 1.9637, 0.8156, 2.4492, 0.9663, 0.9498, 1.2261, 0.8227,\n",
      "        1.5317, 1.2557, 2.3056, 1.2481, 2.0219, 1.0438, 0.9379, 1.1809, 0.4630,\n",
      "        1.1259, 3.2518, 0.8042, 1.3486, 0.6108, 0.8797, 1.4208, 1.3740, 1.8604,\n",
      "        1.4306]), 'FP32-bf16_L_inf': tensor([30.4408, 25.1077, 16.2617, 31.3000, 32.7795, 16.1525, 26.2961,  7.9311,\n",
      "        25.7010, 34.9046, 23.5010, 25.2531,  4.3905, 43.6767, 25.2703,  7.2443,\n",
      "        23.7957, 13.3079, 25.4412, 11.7060,  7.0772, 13.6637, 18.7867, 14.4138,\n",
      "         4.4110, 27.4490, 33.0099, 17.2246, 37.2003, 19.9642, 32.7970, 21.2190,\n",
      "        24.0453, 34.7057, 33.6705, 26.3429, 20.7832, 14.2350, 15.0099, 38.2386,\n",
      "        15.3368, 22.1897, 32.8182, 13.1763, 19.3897, 27.1335, 30.2010, 12.6422,\n",
      "        21.9028, 19.4827, 25.0296, 24.2315, 17.6176, 25.0573, 25.1123,  9.0433,\n",
      "        30.8714, 18.6129, 28.3738, 15.8890, 22.0257, 41.7206, 19.5928, 26.8442]), 'FP32-BF16 mean zero setting Error': '1671337 / 8388544', 'FP32-BF16 mean std setting Error': '3947520 / 8388544'}\n",
      "idx :  9\n",
      "layer name :  conv4_x.0.residual_function.1\n",
      "chunk based sum result : 2839/1835008 = 0.1547132283449173%\n",
      "chunk based sum result : 75883/1835008 = 4.135295391082764%\n",
      "chunk based sum result : 22648/1835008 = 1.2342180013656616%\n",
      "chunk based sum result : 196189/1835008 = 10.691452026367188%\n",
      "{'epoch': 100, 'layer': 'conv4_x.0.residual_function.1', 'FP32-FP16_mse': tensor([0.0026, 0.0045, 0.0097, 0.0022, 0.0029, 0.0031, 0.0020, 0.0090, 0.0036,\n",
      "        0.0024, 0.0307, 0.0029, 0.0084, 0.0033, 0.0025, 0.0040, 0.0028, 0.0046,\n",
      "        0.0026, 0.0024, 0.0023, 0.0034, 0.0033, 0.0030, 0.0025, 0.0035, 0.0118,\n",
      "        0.0032, 0.0036, 0.0032, 0.0035, 0.0024, 0.0071, 0.0030, 0.0125, 0.0038,\n",
      "        0.0027, 0.0033, 0.0101, 0.0030, 0.0033, 0.0050, 0.0041, 0.0056, 0.0037,\n",
      "        0.0027, 0.0030, 0.0022, 0.0038, 0.0037, 0.0031, 0.0025, 0.0052, 0.0028,\n",
      "        0.0079, 0.0028, 0.0067, 0.0029, 0.0032, 0.0026, 0.0024, 0.0027, 0.0033,\n",
      "        0.0029, 0.0101, 0.0036, 0.0036, 0.0022, 0.0102, 0.0031, 0.0041, 0.0029,\n",
      "        0.0027, 0.0033, 0.0036, 0.0053, 0.0042, 0.0055, 0.0024, 0.0055, 0.0036,\n",
      "        0.0061, 0.0045, 0.0085, 0.0071, 0.0032, 0.0036, 0.0023, 0.0033, 0.0075,\n",
      "        0.0036, 0.0035, 0.0015, 0.0031, 0.0029, 0.0031, 0.0087, 0.0025, 0.0031,\n",
      "        0.0036, 0.0071, 0.0042, 0.0036, 0.0023, 0.0039, 0.0067, 0.0022, 0.0028,\n",
      "        0.0056, 0.0029, 0.0101, 0.0033, 0.0037, 0.0085, 0.0034, 0.0032, 0.0032,\n",
      "        0.0034, 0.0029, 0.0032, 0.0040, 0.0036, 0.0033, 0.0029, 0.0030, 0.0030,\n",
      "        0.0065, 0.0037, 0.0032, 0.0019, 0.0040, 0.0027, 0.0032, 0.0030, 0.0032,\n",
      "        0.0059, 0.0028, 0.0026, 0.0027, 0.0028, 0.0068, 0.0029, 0.0043, 0.0111,\n",
      "        0.0038, 0.0060, 0.0084, 0.0035, 0.0039, 0.0036, 0.0070, 0.0058, 0.0050,\n",
      "        0.0144, 0.0047, 0.0033, 0.0073, 0.0037, 0.0032, 0.0036, 0.0064, 0.0125,\n",
      "        0.0026, 0.0023, 0.0045, 0.0067, 0.0054, 0.0032, 0.0038, 0.0026, 0.0028,\n",
      "        0.0022, 0.0043, 0.0042, 0.0081, 0.0053, 0.0030, 0.0033, 0.0022, 0.0147,\n",
      "        0.0088, 0.0034, 0.0041, 0.0027, 0.0023, 0.0036, 0.0024, 0.0032, 0.0095,\n",
      "        0.0023, 0.0029, 0.0034, 0.0028, 0.0033, 0.0026, 0.0026, 0.0023, 0.0090,\n",
      "        0.0020, 0.0034, 0.0033, 0.0019, 0.0022, 0.0027, 0.0028, 0.0027, 0.0042,\n",
      "        0.0030, 0.0031, 0.0029, 0.0023, 0.0025, 0.0032, 0.0034, 0.0036, 0.0029,\n",
      "        0.0030, 0.0139, 0.0021, 0.0051, 0.0069, 0.0092, 0.0025, 0.0032, 0.0030,\n",
      "        0.0045, 0.0050, 0.0029, 0.0038, 0.0040, 0.0025, 0.0027, 0.0034, 0.0035,\n",
      "        0.0029, 0.0026, 0.0035, 0.0030, 0.0024, 0.0074, 0.0048, 0.0042, 0.0037,\n",
      "        0.0035, 0.0036, 0.0110, 0.0033, 0.0031, 0.0091, 0.0022, 0.0054, 0.0055,\n",
      "        0.0033, 0.0141, 0.0050, 0.0025]), 'FP32-FP16_L_inf': tensor([0.0759, 0.0599, 0.0947, 0.0524, 0.0573, 0.1094, 0.0394, 0.0739, 0.0970,\n",
      "        0.0464, 0.1417, 0.0754, 0.1021, 0.0933, 0.0447, 0.1086, 0.0495, 0.0787,\n",
      "        0.0689, 0.0403, 0.0401, 0.0956, 0.0535, 0.0420, 0.0405, 0.0809, 0.1063,\n",
      "        0.0839, 0.0976, 0.0526, 0.0754, 0.0437, 0.1020, 0.1265, 0.0878, 0.0675,\n",
      "        0.0752, 0.1598, 0.0715, 0.0664, 0.1047, 0.0825, 0.1902, 0.0904, 0.0779,\n",
      "        0.0370, 0.0907, 0.0364, 0.0838, 0.0502, 0.0386, 0.0570, 0.0800, 0.0397,\n",
      "        0.0802, 0.0632, 0.0867, 0.0406, 0.1296, 0.0498, 0.0428, 0.0518, 0.0588,\n",
      "        0.0685, 0.0865, 0.0981, 0.1138, 0.0720, 0.0761, 0.0499, 0.0540, 0.0533,\n",
      "        0.0589, 0.0768, 0.0731, 0.0504, 0.0497, 0.0588, 0.0488, 0.0641, 0.0940,\n",
      "        0.0616, 0.0843, 0.0942, 0.0874, 0.0536, 0.1118, 0.0542, 0.1029, 0.0637,\n",
      "        0.0496, 0.0877, 0.0310, 0.0631, 0.0470, 0.0728, 0.1409, 0.0353, 0.0780,\n",
      "        0.0606, 0.0575, 0.0821, 0.1206, 0.0521, 0.0895, 0.0761, 0.0649, 0.0796,\n",
      "        0.0622, 0.0485, 0.0762, 0.0699, 0.0640, 0.0943, 0.0609, 0.0936, 0.0773,\n",
      "        0.0745, 0.0541, 0.0721, 0.0491, 0.0678, 0.0473, 0.0780, 0.0489, 0.0978,\n",
      "        0.0667, 0.0511, 0.0817, 0.0635, 0.0835, 0.0510, 0.0583, 0.0464, 0.0914,\n",
      "        0.0710, 0.0862, 0.0464, 0.0593, 0.0834, 0.0743, 0.0658, 0.0977, 0.0662,\n",
      "        0.0907, 0.0728, 0.0658, 0.0664, 0.0545, 0.0769, 0.0784, 0.0628, 0.0531,\n",
      "        0.0825, 0.0658, 0.0816, 0.0784, 0.0653, 0.0564, 0.0463, 0.0809, 0.0966,\n",
      "        0.0606, 0.0731, 0.0882, 0.0771, 0.0862, 0.0601, 0.0790, 0.0669, 0.0608,\n",
      "        0.0322, 0.0603, 0.0625, 0.0735, 0.0919, 0.0544, 0.0456, 0.0629, 0.1347,\n",
      "        0.0778, 0.1027, 0.0517, 0.0403, 0.0485, 0.0644, 0.0667, 0.0671, 0.0596,\n",
      "        0.0529, 0.0647, 0.0702, 0.0648, 0.0732, 0.0394, 0.0950, 0.0508, 0.0709,\n",
      "        0.0613, 0.0385, 0.0695, 0.0600, 0.0258, 0.0396, 0.0402, 0.0735, 0.0658,\n",
      "        0.0998, 0.0645, 0.0582, 0.0460, 0.0587, 0.0747, 0.0537, 0.1196, 0.0632,\n",
      "        0.0712, 0.0976, 0.0357, 0.0893, 0.0757, 0.0814, 0.0619, 0.0474, 0.0813,\n",
      "        0.1030, 0.1077, 0.0500, 0.2208, 0.0930, 0.0457, 0.0531, 0.0509, 0.0915,\n",
      "        0.0813, 0.0643, 0.0577, 0.0487, 0.0419, 0.0589, 0.0607, 0.0667, 0.0900,\n",
      "        0.0635, 0.1394, 0.1067, 0.0594, 0.0635, 0.1337, 0.0574, 0.0527, 0.0767,\n",
      "        0.0610, 0.0832, 0.0895, 0.0564]), 'FP32-FP16 mean zero setting Error': '47665 / 2096896', 'FP32-FP16 mean std setting Error': '142844 / 2096896', 'FP32-BF16_mse': tensor([0.6264, 0.9131, 1.0234, 0.6031, 0.7770, 0.5610, 0.6642, 1.8142, 0.4877,\n",
      "        0.5190, 2.5386, 0.5016, 1.2053, 0.5302, 0.5270, 0.3894, 0.5498, 0.9685,\n",
      "        0.5788, 0.4965, 0.4017, 0.4692, 0.6317, 0.6174, 0.6846, 0.6794, 1.4972,\n",
      "        0.4409, 0.3766, 0.5657, 0.4459, 0.7036, 0.8407, 0.5222, 1.6739, 0.7751,\n",
      "        0.3638, 0.4820, 1.7870, 0.4387, 0.4774, 0.7016, 0.4536, 0.9589, 0.7038,\n",
      "        0.6449, 0.5215, 0.6201, 0.7761, 0.6925, 0.5424, 0.6495, 0.7957, 0.5937,\n",
      "        1.1177, 0.4747, 1.4394, 0.3709, 0.4455, 0.4644, 0.5765, 0.4554, 0.6608,\n",
      "        0.4733, 1.2682, 0.3625, 0.4900, 0.5255, 1.5640, 0.5303, 0.9295, 0.5537,\n",
      "        0.5579, 0.7215, 0.3677, 1.0591, 0.9802, 1.2727, 0.6772, 1.1386, 0.8798,\n",
      "        1.1929, 0.5514, 1.6059, 1.3681, 0.5320, 0.4473, 0.5640, 0.5670, 1.3865,\n",
      "        0.9083, 0.7779, 0.6630, 0.3936, 0.5470, 0.4846, 1.2697, 0.5222, 0.4867,\n",
      "        0.8686, 1.3675, 0.5980, 0.3332, 0.4599, 0.4518, 1.5572, 0.4734, 0.4624,\n",
      "        0.8462, 0.7200, 1.4583, 0.7790, 0.5849, 1.0409, 0.5781, 0.4731, 0.4699,\n",
      "        0.6221, 0.5103, 0.4953, 1.0230, 0.8459, 0.4890, 0.8084, 0.8119, 0.4911,\n",
      "        1.5150, 0.8034, 0.3818, 0.4504, 0.4546, 0.5838, 0.5296, 0.4550, 0.4257,\n",
      "        1.2368, 0.4737, 0.6806, 0.7879, 0.4855, 0.9562, 0.5542, 0.7212, 1.7883,\n",
      "        0.6325, 1.2140, 1.4287, 0.6070, 1.1382, 0.4491, 1.1773, 1.1090, 1.2044,\n",
      "        2.0329, 1.2170, 0.5668, 1.0713, 0.5645, 0.5227, 0.5163, 0.9069, 1.6206,\n",
      "        0.6063, 0.4691, 0.6879, 1.2372, 1.1008, 0.5610, 0.6456, 0.6429, 0.5953,\n",
      "        0.5893, 0.8033, 0.7225, 1.3275, 0.7628, 0.5806, 0.4589, 0.5107, 1.6960,\n",
      "        1.3720, 0.5300, 1.0464, 0.7466, 0.3987, 0.7791, 0.4022, 0.5819, 1.5551,\n",
      "        0.5605, 0.7264, 0.6916, 0.4598, 0.6786, 0.7499, 0.4800, 0.4461, 1.6251,\n",
      "        0.3543, 0.8739, 0.4486, 0.4553, 0.5430, 0.5504, 0.6850, 0.3957, 0.8452,\n",
      "        0.5628, 0.3652, 0.4547, 0.5657, 0.5572, 0.4235, 0.4473, 0.3920, 0.6258,\n",
      "        0.4226, 2.3015, 0.4600, 0.9847, 0.9090, 1.4690, 0.4139, 0.5260, 0.4306,\n",
      "        0.9772, 0.8345, 0.4372, 0.4567, 0.5767, 0.5923, 0.5456, 0.6454, 0.8299,\n",
      "        0.6633, 0.5580, 0.6814, 0.6257, 0.4636, 1.5732, 1.1653, 0.7376, 0.7303,\n",
      "        0.5243, 0.6245, 1.1017, 0.5622, 0.4799, 0.9910, 0.4491, 1.4342, 1.4657,\n",
      "        0.5181, 1.2952, 0.7227, 0.4755]), 'FP32-bf16_L_inf': tensor([11.0233,  8.6748,  6.1800, 10.2189, 11.8625, 13.4037, 13.5093,  7.0730,\n",
      "        12.3355,  9.6259,  3.3787, 10.9334,  8.8461, 14.4059,  9.6329,  8.1766,\n",
      "         7.8326, 10.8964, 10.6328,  8.2741,  6.2273, 10.8702,  9.4327,  7.4861,\n",
      "         9.0056, 10.0284,  4.3224, 11.5312, 10.7373,  9.9641,  9.6058, 11.5775,\n",
      "         6.2778, 21.5326,  3.5885, 10.8107, 10.2487, 22.4044,  5.8878,  9.3132,\n",
      "        15.5674,  5.6017, 21.1362,  8.3960, 10.1101,  7.8327, 12.4127,  9.4003,\n",
      "         7.8932,  5.9870,  6.7803, 10.3516,  6.5172,  8.5699,  5.7776, 10.8355,\n",
      "         7.7463,  5.2134, 15.7468,  8.8597,  7.6537,  9.3008,  8.6582, 11.1844,\n",
      "         3.7904,  7.9354, 16.2517, 17.5644,  7.9012,  8.2518,  6.1220, 10.7973,\n",
      "        12.4636, 14.0342,  6.9210,  5.5815,  7.5349,  7.8967,  8.9788,  6.1673,\n",
      "        16.0131,  8.1238,  5.3518,  5.9298,  7.9981,  7.4583, 13.9934, 12.6341,\n",
      "         8.8582,  7.5520,  9.9978, 11.2019, 14.2829,  7.6721,  7.1497, 10.5203,\n",
      "         9.3192,  7.1479,  9.8210,  9.1993,  6.6265,  8.8139, 11.0975, 10.5988,\n",
      "        10.2974,  7.8762, 14.1619, 13.3478,  5.6543,  8.6734,  5.3977, 11.1914,\n",
      "         6.9976,  5.3260,  7.0592, 14.7083, 11.7589,  9.0924,  8.6476, 11.5920,\n",
      "         6.7426, 11.7918,  7.1892, 12.0377,  7.6832, 16.1086, 10.9234,  7.4474,\n",
      "         9.7093, 14.9946,  9.6286,  9.6604,  9.3754,  6.9860, 11.8509,  5.0874,\n",
      "        14.8061,  9.5275, 12.9164, 13.6376,  6.8020,  9.3612, 11.1743,  5.0998,\n",
      "         8.3670,  6.7931,  5.1302, 10.8681,  8.2793,  9.4748,  7.2576,  5.2349,\n",
      "         8.3353,  3.0722,  9.3584, 11.2045,  8.5022,  8.5480,  6.0988,  6.6492,\n",
      "         5.3327,  4.2125, 13.1130, 13.2643,  7.5010, 10.1254, 10.7781,  9.1929,\n",
      "         9.9897, 13.7375,  9.6397,  8.0562,  7.3025,  7.6734,  5.9598,  5.8520,\n",
      "        10.1567,  6.1474, 14.8606,  2.4891,  9.9489,  8.1465,  7.0953,  8.6608,\n",
      "         7.8358,  8.7235, 10.3858,  9.4951,  5.5178, 12.9372, 11.8069, 10.6812,\n",
      "        10.9386, 11.4677,  8.5924, 17.6643,  8.3272,  4.2997, 10.3582,  8.6173,\n",
      "         8.3634, 13.8351,  5.4899,  8.3241,  7.9004, 11.3927,  6.7952, 16.3842,\n",
      "         6.5948,  9.5564, 11.4141, 11.6177,  9.5051,  7.0130, 13.2131, 10.7490,\n",
      "         8.8538,  3.6208,  7.6600,  6.6021,  5.4215,  8.1760,  9.0339,  7.8185,\n",
      "        12.2228, 14.6405,  9.9633,  7.1402, 26.5835,  9.3865,  7.0895, 10.9282,\n",
      "         6.5763, 18.5243, 13.6956, 11.5318,  5.7607, 10.2479,  8.1867,  6.8712,\n",
      "         7.8876,  5.5420,  9.9570,  9.1014, 12.7106,  2.6158,  8.5810, 10.2093,\n",
      "         5.1800, 11.2883, 10.5111, 12.3347,  8.5436,  3.0356,  7.2595, 11.2422]), 'FP32-BF16 mean zero setting Error': '210630 / 2096896', 'FP32-BF16 mean std setting Error': '409145 / 2096896'}\n",
      "idx :  15\n",
      "layer name :  conv5_x.1.residual_function.1\n",
      "chunk based sum result : 343/524288 = 0.06542205810546875%\n",
      "chunk based sum result : 13956/524288 = 2.661895751953125%\n",
      "chunk based sum result : 2551/524288 = 0.48656463623046875%\n",
      "chunk based sum result : 35891/524288 = 6.845664978027344%\n",
      "{'epoch': 100, 'layer': 'conv5_x.1.residual_function.1', 'FP32-FP16_mse': tensor([0.0022, 0.0039, 0.0027, 0.0091, 0.0026, 0.0036, 0.0029, 0.0121, 0.0026,\n",
      "        0.0034, 0.0037, 0.0042, 0.0035, 0.0030, 0.0029, 0.0029, 0.0056, 0.0039,\n",
      "        0.0029, 0.0042, 0.0025, 0.0030, 0.0054, 0.0046, 0.0030, 0.0023, 0.0033,\n",
      "        0.0025, 0.0038, 0.0029, 0.0025, 0.0024, 0.0027, 0.0047, 0.0028, 0.0076,\n",
      "        0.0029, 0.0025, 0.0026, 0.0031, 0.0035, 0.0025, 0.0030, 0.0030, 0.0028,\n",
      "        0.0027, 0.0033, 0.0030, 0.0034, 0.0087, 0.0024, 0.0033, 0.0028, 0.0031,\n",
      "        0.0041, 0.0029, 0.0028, 0.0031, 0.0032, 0.0030, 0.0047, 0.0035, 0.0027,\n",
      "        0.0023, 0.0052, 0.0023, 0.0028, 0.0046, 0.0029, 0.0034, 0.0027, 0.0030,\n",
      "        0.0084, 0.0027, 0.0031, 0.0027, 0.0030, 0.0024, 0.0047, 0.0030, 0.0025,\n",
      "        0.0038, 0.0028, 0.0022, 0.0023, 0.0035, 0.0036, 0.0031, 0.0034, 0.0036,\n",
      "        0.0024, 0.0101, 0.0026, 0.0028, 0.0022, 0.0027, 0.0061, 0.0040, 0.0027,\n",
      "        0.0025, 0.0036, 0.0032, 0.0030, 0.0031, 0.0019, 0.0085, 0.0024, 0.0090,\n",
      "        0.0036, 0.0056, 0.0032, 0.0031, 0.0044, 0.0047, 0.0032, 0.0037, 0.0056,\n",
      "        0.0035, 0.0032, 0.0023, 0.0033, 0.0027, 0.0025, 0.0033, 0.0021, 0.0026,\n",
      "        0.0028, 0.0029, 0.0046, 0.0071, 0.0037, 0.0024, 0.0035, 0.0039, 0.0027,\n",
      "        0.0027, 0.0030, 0.0026, 0.0047, 0.0031, 0.0072, 0.0044, 0.0045, 0.0038,\n",
      "        0.0036, 0.0084, 0.0025, 0.0030, 0.0045, 0.0027, 0.0024, 0.0024, 0.0031,\n",
      "        0.0029, 0.0029, 0.0026, 0.0064, 0.0039, 0.0031, 0.0051, 0.0032, 0.0030,\n",
      "        0.0049, 0.0025, 0.0030, 0.0025, 0.0026, 0.0023, 0.0034, 0.0027, 0.0024,\n",
      "        0.0045, 0.0022, 0.0049, 0.0023, 0.0056, 0.0029, 0.0024, 0.0032, 0.0025,\n",
      "        0.0035, 0.0026, 0.0051, 0.0033, 0.0030, 0.0025, 0.0088, 0.0019, 0.0098,\n",
      "        0.0022, 0.0026, 0.0030, 0.0022, 0.0074, 0.0026, 0.0024, 0.0037, 0.0081,\n",
      "        0.0022, 0.0024, 0.0044, 0.0113, 0.0035, 0.0058, 0.0036, 0.0024, 0.0036,\n",
      "        0.0034, 0.0032, 0.0028, 0.0027, 0.0043, 0.0038, 0.0026, 0.0032, 0.0018,\n",
      "        0.0025, 0.0031, 0.0031, 0.0024, 0.0031, 0.0037, 0.0032, 0.0022, 0.0033,\n",
      "        0.0027, 0.0033, 0.0045, 0.0071, 0.0025, 0.0028, 0.0028, 0.0038, 0.0088,\n",
      "        0.0051, 0.0076, 0.0033, 0.0032, 0.0028, 0.0025, 0.0029, 0.0017, 0.0029,\n",
      "        0.0019, 0.0048, 0.0032, 0.0021, 0.0028, 0.0030, 0.0024, 0.0029, 0.0026,\n",
      "        0.0026, 0.0034, 0.0032, 0.0029, 0.0028, 0.0043, 0.0024, 0.0032, 0.0031,\n",
      "        0.0019, 0.0031, 0.0032, 0.0019, 0.0017, 0.0024, 0.0043, 0.0032, 0.0066,\n",
      "        0.0035, 0.0029, 0.0043, 0.0038, 0.0031, 0.0020, 0.0026, 0.0025, 0.0026,\n",
      "        0.0064, 0.0038, 0.0033, 0.0026, 0.0061, 0.0037, 0.0056, 0.0033, 0.0033,\n",
      "        0.0030, 0.0022, 0.0031, 0.0033, 0.0031, 0.0058, 0.0047, 0.0037, 0.0029,\n",
      "        0.0044, 0.0030, 0.0031, 0.0028, 0.0028, 0.0037, 0.0049, 0.0031, 0.0026,\n",
      "        0.0059, 0.0034, 0.0088, 0.0032, 0.0035, 0.0030, 0.0029, 0.0061, 0.0029,\n",
      "        0.0039, 0.0034, 0.0034, 0.0023, 0.0032, 0.0073, 0.0030, 0.0031, 0.0044,\n",
      "        0.0028, 0.0055, 0.0029, 0.0030, 0.0041, 0.0021, 0.0029, 0.0028, 0.0021,\n",
      "        0.0035, 0.0028, 0.0030, 0.0028, 0.0044, 0.0050, 0.0032, 0.0090, 0.0031,\n",
      "        0.0034, 0.0032, 0.0024, 0.0021, 0.0027, 0.0026, 0.0033, 0.0017, 0.0024,\n",
      "        0.0026, 0.0091, 0.0029, 0.0087, 0.0035, 0.0036, 0.0034, 0.0032, 0.0024,\n",
      "        0.0030, 0.0029, 0.0067, 0.0046, 0.0030, 0.0021, 0.0035, 0.0025, 0.0038,\n",
      "        0.0038, 0.0032, 0.0022, 0.0023, 0.0070, 0.0026, 0.0023, 0.0030, 0.0037,\n",
      "        0.0039, 0.0099, 0.0022, 0.0026, 0.0029, 0.0034, 0.0028, 0.0027, 0.0021,\n",
      "        0.0064, 0.0073, 0.0035, 0.0031, 0.0029, 0.0029, 0.0023, 0.0029, 0.0018,\n",
      "        0.0030, 0.0031, 0.0036, 0.0025, 0.0029, 0.0040, 0.0023, 0.0024, 0.0034,\n",
      "        0.0023, 0.0031, 0.0064, 0.0030, 0.0037, 0.0023, 0.0046, 0.0035, 0.0044,\n",
      "        0.0031, 0.0030, 0.0030, 0.0076, 0.0029, 0.0027, 0.0035, 0.0031, 0.0033,\n",
      "        0.0029, 0.0023, 0.0031, 0.0027, 0.0025, 0.0031, 0.0102, 0.0029, 0.0026,\n",
      "        0.0024, 0.0029, 0.0031, 0.0027, 0.0025, 0.0043, 0.0036, 0.0033, 0.0023,\n",
      "        0.0026, 0.0036, 0.0034, 0.0032, 0.0053, 0.0028, 0.0028, 0.0048, 0.0036,\n",
      "        0.0025, 0.0024, 0.0041, 0.0040, 0.0030, 0.0027, 0.0029, 0.0028, 0.0033,\n",
      "        0.0025, 0.0042, 0.0033, 0.0043, 0.0041, 0.0027, 0.0033, 0.0048, 0.0030,\n",
      "        0.0040, 0.0022, 0.0095, 0.0037, 0.0024, 0.0023, 0.0025, 0.0052, 0.0040,\n",
      "        0.0052, 0.0028, 0.0027, 0.0029, 0.0024, 0.0035, 0.0024, 0.0033, 0.0027,\n",
      "        0.0028, 0.0041, 0.0036, 0.0068, 0.0044, 0.0088, 0.0042, 0.0026, 0.0019,\n",
      "        0.0024, 0.0057, 0.0047, 0.0025, 0.0030, 0.0032, 0.0033, 0.0035, 0.0025,\n",
      "        0.0032, 0.0026, 0.0035, 0.0031, 0.0030, 0.0047, 0.0034, 0.0064]), 'FP32-FP16_L_inf': tensor([0.0302, 0.0812, 0.0531, 0.1142, 0.0621, 0.0637, 0.0560, 0.1128, 0.0562,\n",
      "        0.0545, 0.1060, 0.0824, 0.0800, 0.0684, 0.0676, 0.0600, 0.0639, 0.0726,\n",
      "        0.0510, 0.0573, 0.0414, 0.0504, 0.0766, 0.0801, 0.0713, 0.0432, 0.0938,\n",
      "        0.0383, 0.0719, 0.0671, 0.0652, 0.0612, 0.0535, 0.0789, 0.0486, 0.0867,\n",
      "        0.0647, 0.0522, 0.0492, 0.0973, 0.0709, 0.0378, 0.1063, 0.0463, 0.0460,\n",
      "        0.0557, 0.0447, 0.0688, 0.0540, 0.0658, 0.0586, 0.0542, 0.0464, 0.0688,\n",
      "        0.0500, 0.0465, 0.0977, 0.0530, 0.0839, 0.0806, 0.0672, 0.0657, 0.0458,\n",
      "        0.0375, 0.0880, 0.0541, 0.0441, 0.1083, 0.0455, 0.1319, 0.0712, 0.0553,\n",
      "        0.1620, 0.0749, 0.0590, 0.0499, 0.0581, 0.0593, 0.0596, 0.0475, 0.0442,\n",
      "        0.0523, 0.0669, 0.0338, 0.0483, 0.0591, 0.0803, 0.0802, 0.0524, 0.0839,\n",
      "        0.0536, 0.1014, 0.0515, 0.0556, 0.0674, 0.0483, 0.0926, 0.0549, 0.0441,\n",
      "        0.0450, 0.0608, 0.0662, 0.0464, 0.0874, 0.0398, 0.0745, 0.0394, 0.0752,\n",
      "        0.0865, 0.0657, 0.0898, 0.0521, 0.0593, 0.0647, 0.0886, 0.0469, 0.0747,\n",
      "        0.0634, 0.0633, 0.0493, 0.1088, 0.0717, 0.0423, 0.0782, 0.0458, 0.0341,\n",
      "        0.0442, 0.0644, 0.0764, 0.0845, 0.0565, 0.0533, 0.0733, 0.0514, 0.0680,\n",
      "        0.0390, 0.0843, 0.0653, 0.0932, 0.0805, 0.1442, 0.0695, 0.1136, 0.0919,\n",
      "        0.1191, 0.0960, 0.0697, 0.0434, 0.0887, 0.0603, 0.0591, 0.0808, 0.0441,\n",
      "        0.0537, 0.0892, 0.0389, 0.0773, 0.1022, 0.0518, 0.1137, 0.1102, 0.0692,\n",
      "        0.1235, 0.0453, 0.0711, 0.0471, 0.0623, 0.0370, 0.0651, 0.0576, 0.0377,\n",
      "        0.0610, 0.0428, 0.0714, 0.0360, 0.1241, 0.0731, 0.0495, 0.0487, 0.0787,\n",
      "        0.0752, 0.0554, 0.0801, 0.0667, 0.0678, 0.0738, 0.0801, 0.0362, 0.1563,\n",
      "        0.0554, 0.0780, 0.0610, 0.0373, 0.0815, 0.0474, 0.0405, 0.1215, 0.0762,\n",
      "        0.0415, 0.0669, 0.1350, 0.1118, 0.0695, 0.1070, 0.0474, 0.0441, 0.0943,\n",
      "        0.0774, 0.0688, 0.0491, 0.0765, 0.0788, 0.0812, 0.0440, 0.0724, 0.0440,\n",
      "        0.0557, 0.1269, 0.0865, 0.0724, 0.0792, 0.0820, 0.0496, 0.0457, 0.0551,\n",
      "        0.0703, 0.0572, 0.0768, 0.1040, 0.0693, 0.0530, 0.0532, 0.0769, 0.1452,\n",
      "        0.0896, 0.1151, 0.0623, 0.0747, 0.0546, 0.0526, 0.0412, 0.0457, 0.0539,\n",
      "        0.0273, 0.1039, 0.0642, 0.0522, 0.0481, 0.0703, 0.0415, 0.0724, 0.0613,\n",
      "        0.0445, 0.1117, 0.0797, 0.0660, 0.0515, 0.1023, 0.0602, 0.0925, 0.0671,\n",
      "        0.0359, 0.0640, 0.0562, 0.0386, 0.0517, 0.0752, 0.0745, 0.0786, 0.0977,\n",
      "        0.0594, 0.0592, 0.0600, 0.0711, 0.0838, 0.0339, 0.0615, 0.0732, 0.0520,\n",
      "        0.0758, 0.0666, 0.1361, 0.0352, 0.0826, 0.0582, 0.1226, 0.0636, 0.0789,\n",
      "        0.0720, 0.0327, 0.0707, 0.0776, 0.0578, 0.0559, 0.0664, 0.0686, 0.0667,\n",
      "        0.0771, 0.0472, 0.0697, 0.0539, 0.0426, 0.1116, 0.0755, 0.1066, 0.0409,\n",
      "        0.0679, 0.0647, 0.0673, 0.0626, 0.0839, 0.0642, 0.1479, 0.0659, 0.0936,\n",
      "        0.0975, 0.0928, 0.0599, 0.1428, 0.0772, 0.1191, 0.0480, 0.0605, 0.0998,\n",
      "        0.0634, 0.1188, 0.0653, 0.0559, 0.0523, 0.0600, 0.0793, 0.0707, 0.0311,\n",
      "        0.0657, 0.0555, 0.0809, 0.0902, 0.0535, 0.1115, 0.0606, 0.0774, 0.0620,\n",
      "        0.0578, 0.0572, 0.0338, 0.0372, 0.0390, 0.0595, 0.0464, 0.0468, 0.0333,\n",
      "        0.0586, 0.0845, 0.0861, 0.0721, 0.0717, 0.1860, 0.0857, 0.0707, 0.0437,\n",
      "        0.0634, 0.0727, 0.1162, 0.0586, 0.0697, 0.0576, 0.0877, 0.0408, 0.0730,\n",
      "        0.0893, 0.0448, 0.0347, 0.0312, 0.0937, 0.0336, 0.0332, 0.0574, 0.1156,\n",
      "        0.0540, 0.0933, 0.0683, 0.0418, 0.0707, 0.0708, 0.0802, 0.0486, 0.0406,\n",
      "        0.1110, 0.0899, 0.0586, 0.0871, 0.0395, 0.0598, 0.0369, 0.0773, 0.0324,\n",
      "        0.0565, 0.0474, 0.0777, 0.0779, 0.0469, 0.0637, 0.0416, 0.0501, 0.0477,\n",
      "        0.0381, 0.0473, 0.0922, 0.0696, 0.0635, 0.0548, 0.0658, 0.0798, 0.0774,\n",
      "        0.0686, 0.0488, 0.0490, 0.0860, 0.0517, 0.0724, 0.0641, 0.0508, 0.0675,\n",
      "        0.0416, 0.0453, 0.0672, 0.0549, 0.0434, 0.0506, 0.0805, 0.0492, 0.0667,\n",
      "        0.0476, 0.0965, 0.0757, 0.0421, 0.0589, 0.0758, 0.0597, 0.0528, 0.0489,\n",
      "        0.0436, 0.0956, 0.0647, 0.0678, 0.0958, 0.0797, 0.0495, 0.0643, 0.0776,\n",
      "        0.0383, 0.0407, 0.0966, 0.0895, 0.0666, 0.0784, 0.0359, 0.0417, 0.0566,\n",
      "        0.0732, 0.0513, 0.0524, 0.0688, 0.0824, 0.0530, 0.0833, 0.0941, 0.0559,\n",
      "        0.0576, 0.0820, 0.1156, 0.1048, 0.0453, 0.0535, 0.1271, 0.0901, 0.0821,\n",
      "        0.0737, 0.0603, 0.0476, 0.0702, 0.0490, 0.1156, 0.0620, 0.0747, 0.0683,\n",
      "        0.0706, 0.0588, 0.0839, 0.0911, 0.0873, 0.1149, 0.0770, 0.0371, 0.0262,\n",
      "        0.0484, 0.0906, 0.1124, 0.0570, 0.0622, 0.0910, 0.0770, 0.0650, 0.0489,\n",
      "        0.1002, 0.0650, 0.0513, 0.0774, 0.0791, 0.0684, 0.0682, 0.1033]), 'FP32-FP16 mean zero setting Error': '105613 / 1048064', 'FP32-FP16 mean std setting Error': '253988 / 1048064', 'FP32-BF16_mse': tensor([0.2687, 0.3505, 0.1499, 0.9655, 0.1840, 0.5399, 0.4395, 0.8603, 0.1266,\n",
      "        0.3628, 0.2262, 0.3657, 0.1856, 0.2154, 0.2703, 0.2775, 0.8580, 0.3577,\n",
      "        0.4911, 0.5343, 0.1752, 0.3152, 0.5602, 0.4789, 0.2217, 0.2443, 0.3169,\n",
      "        0.2756, 0.4177, 0.3224, 0.2182, 0.1923, 0.2194, 0.4795, 0.2062, 0.9315,\n",
      "        0.2889, 0.1760, 0.1708, 0.5343, 0.2715, 0.4340, 0.2045, 0.3245, 0.3256,\n",
      "        0.2599, 0.6381, 0.2195, 0.4016, 0.7682, 0.3111, 0.4494, 0.4290, 0.2627,\n",
      "        0.5855, 0.2051, 0.1707, 0.2181, 0.2284, 0.3307, 0.6015, 0.4922, 0.4053,\n",
      "        0.1768, 0.4803, 0.1454, 0.1666, 0.4995, 0.3304, 0.2971, 0.1621, 0.3498,\n",
      "        0.6197, 0.2613, 0.3726, 0.1783, 0.3090, 0.3266, 0.6099, 0.1767, 0.2455,\n",
      "        0.4624, 0.3314, 0.1698, 0.3570, 0.4208, 0.2092, 0.2696, 0.4522, 0.4385,\n",
      "        0.2050, 1.0730, 0.1590, 0.3092, 0.1296, 0.3083, 0.6162, 0.4912, 0.2649,\n",
      "        0.3415, 0.4019, 0.2346, 0.3585, 0.4217, 0.2637, 0.6629, 0.2095, 0.7229,\n",
      "        0.3111, 0.7684, 0.3422, 0.2171, 0.4740, 0.6904, 0.2230, 0.4638, 0.6757,\n",
      "        0.4592, 0.3509, 0.1883, 0.2484, 0.3093, 0.3028, 0.2450, 0.3501, 0.2182,\n",
      "        0.2551, 0.2632, 0.6142, 0.8255, 0.3222, 0.2019, 0.5103, 0.6302, 0.2962,\n",
      "        0.5151, 0.1560, 0.1897, 0.4679, 0.3578, 0.7749, 0.5158, 0.4300, 0.3593,\n",
      "        0.3128, 0.7199, 0.3300, 0.1670, 0.4973, 0.2097, 0.1609, 0.1796, 0.3689,\n",
      "        0.2141, 0.1984, 0.2258, 0.5964, 0.5287, 0.1813, 0.4664, 0.2404, 0.1919,\n",
      "        0.4789, 0.1998, 0.3151, 0.2296, 0.3152, 0.1641, 0.2481, 0.2566, 0.2129,\n",
      "        0.6028, 0.1758, 0.4994, 0.2132, 0.7261, 0.2587, 0.2283, 0.2713, 0.1583,\n",
      "        0.1510, 0.2661, 0.6491, 0.3965, 0.2229, 0.2320, 0.9963, 0.1454, 0.7946,\n",
      "        0.2995, 0.2054, 0.1917, 0.1887, 0.6816, 0.2557, 0.2999, 0.3855, 0.8912,\n",
      "        0.1960, 0.2760, 0.3380, 1.0470, 0.5240, 0.6367, 0.4076, 0.1791, 0.4358,\n",
      "        0.4059, 0.2740, 0.2896, 0.2628, 0.3950, 0.3775, 0.1822, 0.2570, 0.2282,\n",
      "        0.1964, 0.2492, 0.3977, 0.1787, 0.1787, 0.5401, 0.3663, 0.2036, 0.3168,\n",
      "        0.2127, 0.1817, 0.7167, 0.6386, 0.2022, 0.2242, 0.2246, 0.2273, 0.8245,\n",
      "        0.5378, 0.7850, 0.5029, 0.3026, 0.3059, 0.2053, 0.2468, 0.1815, 0.2964,\n",
      "        0.1783, 0.4988, 0.4134, 0.2052, 0.4272, 0.1810, 0.2691, 0.1818, 0.2105,\n",
      "        0.1720, 0.1733, 0.1882, 0.2740, 0.2535, 0.4642, 0.2708, 0.2449, 0.3564,\n",
      "        0.1702, 0.3158, 0.2115, 0.1680, 0.1320, 0.2487, 0.5932, 0.2562, 0.6146,\n",
      "        0.4296, 0.1593, 0.5229, 0.5090, 0.1683, 0.2159, 0.2630, 0.2284, 0.3451,\n",
      "        0.7169, 0.5064, 0.1766, 0.2588, 0.5458, 0.5330, 0.5897, 0.3598, 0.3674,\n",
      "        0.4123, 0.2606, 0.3247, 0.1651, 0.1758, 0.8372, 0.6400, 0.4580, 0.1613,\n",
      "        0.2717, 0.1754, 0.2821, 0.2873, 0.2452, 0.3035, 0.6675, 0.3035, 0.2508,\n",
      "        0.7282, 0.2695, 1.0128, 0.1605, 0.5162, 0.1425, 0.2612, 0.7404, 0.1604,\n",
      "        0.5109, 0.4107, 0.2045, 0.2123, 0.3881, 0.7585, 0.1960, 0.2512, 0.4505,\n",
      "        0.1921, 0.4246, 0.2654, 0.2310, 0.5888, 0.2197, 0.2019, 0.1569, 0.2055,\n",
      "        0.5230, 0.4115, 0.3661, 0.2627, 0.5455, 0.5733, 0.2676, 1.0022, 0.1909,\n",
      "        0.4507, 0.4997, 0.1944, 0.1460, 0.2633, 0.2746, 0.4845, 0.1869, 0.2114,\n",
      "        0.2711, 0.8183, 0.2525, 0.9839, 0.3771, 0.2532, 0.2690, 0.3907, 0.3734,\n",
      "        0.4266, 0.3001, 0.6772, 0.5280, 0.1751, 0.1861, 0.3517, 0.2861, 0.5160,\n",
      "        0.4404, 0.1857, 0.2010, 0.2730, 0.6829, 0.3468, 0.2813, 0.4011, 0.5043,\n",
      "        0.3664, 0.6835, 0.1214, 0.2839, 0.2914, 0.4591, 0.2588, 0.1462, 0.1646,\n",
      "        0.6414, 0.7037, 0.4498, 0.3068, 0.5332, 0.2597, 0.1546, 0.3526, 0.2160,\n",
      "        0.3941, 0.2890, 0.4261, 0.2177, 0.2726, 0.4793, 0.1648, 0.1631, 0.5095,\n",
      "        0.1976, 0.1850, 0.5239, 0.3623, 0.4609, 0.2658, 0.5328, 0.4377, 0.5091,\n",
      "        0.1753, 0.2397, 0.2211, 0.7789, 0.3779, 0.2035, 0.3994, 0.2228, 0.4105,\n",
      "        0.4147, 0.1655, 0.2461, 0.3251, 0.2020, 0.1596, 1.0281, 0.2939, 0.1583,\n",
      "        0.2138, 0.3168, 0.2243, 0.1631, 0.1761, 0.3872, 0.3379, 0.2954, 0.2079,\n",
      "        0.1719, 0.2963, 0.3672, 0.2770, 0.4532, 0.1638, 0.1597, 0.5102, 0.4416,\n",
      "        0.2023, 0.1728, 0.4146, 0.6495, 0.1585, 0.2026, 0.4836, 0.3109, 0.4024,\n",
      "        0.2611, 0.6507, 0.3292, 0.5775, 0.6074, 0.1498, 0.2910, 0.6265, 0.1583,\n",
      "        0.4780, 0.2586, 0.7673, 0.3554, 0.3664, 0.1337, 0.1833, 0.4472, 0.4747,\n",
      "        0.6529, 0.1821, 0.1600, 0.3068, 0.2928, 0.2283, 0.2298, 0.1696, 0.1821,\n",
      "        0.1424, 0.4997, 0.4034, 0.7635, 0.6441, 0.8699, 0.5605, 0.1696, 0.1810,\n",
      "        0.3021, 0.6670, 0.5057, 0.1943, 0.4246, 0.3872, 0.2637, 0.1536, 0.2684,\n",
      "        0.2461, 0.3336, 0.3223, 0.2549, 0.2358, 0.6287, 0.3562, 0.7001]), 'FP32-bf16_L_inf': tensor([2.6463, 3.4676, 2.9923, 2.7767, 3.8233, 2.3267, 2.5721, 1.3399, 2.7361,\n",
      "        2.2829, 3.9996, 3.4437, 4.3409, 4.6877, 4.8677, 3.3756, 2.4207, 2.9229,\n",
      "        2.9174, 2.5522, 2.8295, 2.5627, 2.3429, 2.7598, 3.8797, 3.2962, 4.6202,\n",
      "        2.9773, 2.5088, 3.6594, 3.4414, 4.8340, 4.3585, 3.3584, 3.6012, 2.0456,\n",
      "        3.2722, 2.9054, 3.3164, 3.2916, 3.1457, 2.7232, 7.4008, 2.2674, 2.8427,\n",
      "        3.6753, 3.5607, 2.9152, 2.5116, 1.0956, 3.9691, 3.2659, 2.3090, 4.9767,\n",
      "        2.6693, 2.7313, 4.7743, 3.7408, 4.0088, 3.5287, 2.4797, 2.7173, 2.4895,\n",
      "        2.7533, 2.5301, 3.0427, 2.6735, 4.5272, 2.9180, 6.7121, 4.4787, 3.4193,\n",
      "        2.4594, 3.6559, 3.2511, 2.9898, 3.1602, 3.4261, 1.9047, 2.9993, 2.7666,\n",
      "        3.0765, 4.6968, 2.6511, 3.9063, 3.3258, 3.6099, 3.8844, 2.9248, 3.7882,\n",
      "        4.0991, 3.3662, 3.0336, 3.6794, 3.1321, 2.0689, 2.6510, 2.4297, 3.7054,\n",
      "        2.6803, 2.3221, 3.4610, 3.2973, 4.5281, 3.5514, 1.3940, 3.3680, 1.4234,\n",
      "        3.6036, 2.3475, 5.4455, 2.8535, 2.0707, 2.5008, 6.0114, 2.1588, 2.4254,\n",
      "        3.0039, 3.1234, 2.7803, 7.7357, 4.9191, 3.4132, 4.5040, 3.0914, 2.3087,\n",
      "        2.7903, 4.1775, 2.3077, 2.3020, 3.4133, 3.1970, 4.2107, 2.7510, 5.4217,\n",
      "        3.5792, 4.2935, 4.6163, 3.7130, 3.5827, 2.6879, 2.7288, 4.5422, 4.5478,\n",
      "        4.0244, 2.5736, 3.6995, 2.4580, 3.6759, 3.0453, 3.9652, 5.9305, 2.8055,\n",
      "        3.0828, 6.1005, 3.1400, 2.4722, 4.0713, 3.1078, 3.0542, 6.4310, 3.7132,\n",
      "        4.0558, 3.7609, 3.4917, 3.2712, 3.3950, 2.6090, 3.1436, 3.8191, 2.7855,\n",
      "        1.9122, 3.5211, 2.8769, 2.7021, 3.3052, 3.5260, 3.9032, 3.3684, 3.9755,\n",
      "        3.3702, 3.3149, 2.3345, 3.2080, 5.1364, 3.7890, 2.3663, 2.8784, 2.3719,\n",
      "        2.6631, 4.4773, 3.5270, 3.2945, 1.5926, 3.3350, 2.8864, 5.3995, 1.9042,\n",
      "        3.1932, 5.3026, 6.1721, 1.4579, 2.7241, 3.1827, 2.2837, 3.2629, 4.8820,\n",
      "        3.9390, 3.1766, 2.5015, 3.4310, 3.6066, 3.2479, 2.7185, 4.4938, 5.3351,\n",
      "        3.6329, 5.7844, 4.2530, 5.1599, 3.7622, 2.7954, 2.6826, 3.2273, 2.2099,\n",
      "        4.8879, 2.9772, 2.3471, 2.6636, 5.5068, 3.3955, 4.3093, 3.0710, 2.6146,\n",
      "        2.5846, 1.7653, 3.8719, 4.9596, 3.6557, 3.5691, 2.9847, 4.5443, 2.9118,\n",
      "        2.2671, 3.1215, 3.5384, 3.0681, 3.4897, 4.2591, 3.1083, 4.1081, 4.1748,\n",
      "        3.0452, 5.3035, 4.2123, 3.7515, 2.0873, 3.3284, 5.1311, 4.0142, 3.6794,\n",
      "        2.5754, 3.8979, 2.9467, 3.6698, 4.2131, 5.7036, 2.5728, 4.6185, 1.8861,\n",
      "        3.8294, 3.2104, 2.8495, 3.4743, 3.9535, 2.7897, 4.7566, 4.4982, 3.2333,\n",
      "        2.0637, 2.6058, 5.2671, 2.7434, 2.0414, 2.8772, 3.3844, 2.8613, 3.3139,\n",
      "        4.1297, 2.4373, 3.7312, 3.5272, 3.2148, 2.1223, 2.4221, 3.4797, 2.5934,\n",
      "        3.6443, 2.6245, 3.9396, 3.2460, 3.2431, 4.5644, 3.4035, 6.9103, 3.4763,\n",
      "        2.1307, 3.1083, 1.7875, 3.0864, 3.3313, 2.8365, 8.1969, 2.1349, 4.8694,\n",
      "        4.0810, 4.8612, 3.6518, 8.8613, 3.5082, 2.7187, 3.0533, 3.0752, 3.4749,\n",
      "        3.7524, 3.4019, 3.7333, 3.4471, 3.1621, 3.4335, 2.7714, 2.7136, 2.7302,\n",
      "        2.1192, 4.0210, 3.6488, 5.1157, 2.0237, 4.0398, 4.0816, 1.3106, 3.9600,\n",
      "        2.8089, 2.6526, 2.7995, 2.5725, 2.9073, 3.1450, 2.7584, 3.1620, 2.5510,\n",
      "        5.2157, 1.4890, 5.0918, 2.3092, 3.1063, 9.6185, 3.6964, 2.6082, 2.1619,\n",
      "        3.6909, 4.1394, 2.3112, 2.3957, 3.6486, 4.8435, 4.1591, 3.4070, 2.8435,\n",
      "        3.6407, 2.8423, 2.3785, 3.2503, 2.1822, 2.8687, 3.1573, 3.6436, 4.6797,\n",
      "        2.1183, 1.5863, 3.8267, 3.7162, 4.0905, 3.0399, 4.8456, 2.7729, 2.4422,\n",
      "        2.2459, 2.0351, 2.4832, 2.4928, 2.8124, 2.7652, 2.5733, 4.0503, 2.9257,\n",
      "        3.2014, 2.8282, 4.0001, 5.1283, 3.2969, 3.4879, 2.4904, 3.2915, 1.9294,\n",
      "        3.1475, 2.9663, 1.5305, 3.1124, 2.3830, 3.8913, 2.5229, 3.2456, 2.7839,\n",
      "        2.7041, 2.5114, 2.9097, 1.4406, 2.0195, 5.5164, 3.8558, 3.7295, 3.9681,\n",
      "        2.8844, 3.4497, 3.4790, 3.9210, 3.6412, 2.6031, 1.2469, 3.5674, 4.1753,\n",
      "        3.2788, 6.3975, 3.4889, 2.7032, 3.9130, 4.1964, 3.6888, 2.9540, 4.1999,\n",
      "        2.9243, 3.7279, 3.0029, 3.9525, 2.8638, 4.7747, 2.5800, 2.3320, 4.2176,\n",
      "        2.6974, 2.7165, 3.7117, 3.3305, 3.5110, 3.4929, 2.6536, 3.2566, 2.9913,\n",
      "        5.8869, 1.8417, 2.1837, 2.4414, 2.8118, 2.2982, 3.0393, 4.0235, 3.1355,\n",
      "        2.7367, 4.3862, 1.6503, 5.2062, 3.0036, 3.1196, 8.8785, 2.3616, 3.8008,\n",
      "        2.3768, 3.9207, 2.7274, 3.8100, 4.5823, 6.5146, 4.4848, 3.7449, 4.7985,\n",
      "        3.7641, 2.4483, 3.7881, 2.4019, 3.4957, 2.2475, 3.0331, 2.5563, 2.5077,\n",
      "        2.2919, 2.5578, 3.5254, 4.5061, 3.0277, 5.2064, 3.5801, 2.9236, 4.9835,\n",
      "        6.3766, 4.0241, 3.4003, 3.5477, 4.7731, 2.8583, 2.7883, 3.1751]), 'FP32-BF16 mean zero setting Error': '385218 / 1048064', 'FP32-BF16 mean std setting Error': '475164 / 1048064'}\n"
     ]
    }
   ],
   "source": [
    "result_df =pd.DataFrame()\n",
    "for epoch in option.activation_step:\n",
    "    epoch_df = batchnorm_df[batchnorm_df.epoch == epoch]\n",
    "    print(epoch)\n",
    "    for index in option.activation_index:\n",
    "        alpha_trigger = False\n",
    "        beta_trigger =False\n",
    "        avg_trigger = False\n",
    "        var_trigger =False\n",
    "        for key in sorted(epoch_df.keys()): # alpha, avg, beta, var and find index\n",
    "            if str(index) == key.split(\"_\")[0]:\n",
    "                file_name = '_'.join(key.split(\"_\")[1:-1])\n",
    "                target_key = key\n",
    "                target_df = epoch_df[key].iloc[0]\n",
    "                \n",
    "                if \"alpha\" in key:\n",
    "                    bn_weight = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    alpha_trigger=True\n",
    "                elif \"beta\" in key :\n",
    "                    bn_bias = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    beta_trigger= True\n",
    "                elif \"avg\" in key:\n",
    "                    bn_running_mean = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    avg_trigger = True\n",
    "                elif \"var\" in key:\n",
    "                    bn_running_var = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    var_trigger = True\n",
    "        \n",
    "        if alpha_trigger and beta_trigger and var_trigger and avg_trigger:\n",
    "\n",
    "            print(\"idx : \", index)\n",
    "            print(\"layer name : \", file_name)\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                BatchNorm_fp16_layer = Compare_BatchNorm_Precision(num_features=bn_weight.shape, intermediate_result=True, chunk=1024, compute_type=torch.float16)\n",
    "                BatchNorm_fp16_layer.load_params(bn_weight, bn_bias, bn_running_mean, bn_running_var)\n",
    "                \"\"\" print(\"-------------- FP32 - FP16 distance --------------------\")\n",
    "                print(f\"bn.weight mse distance {((bn_weight - bn_weight.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.bias mse distance {((bn_bias - bn_bias.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.avg mse distance {((bn_running_mean - bn_running_mean.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.var mse distance {((bn_running_var - bn_running_var.type(torch.float16))**2).mean()}\")\n",
    "                print(\"-------------- FP32 - FP16 end --------------------\")\n",
    "                \n",
    "\n",
    "                print(\"-------------- FP32 - BF16 distance --------------------\")\n",
    "                print(f\"bn.weight mse distance {((bn_weight - bn_weight.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.bias mse distance {((bn_bias - bn_bias.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.avg mse distance {((bn_running_mean - bn_running_mean.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.var mse distance {((bn_running_var - bn_running_var.type(torch.bfloat16))**2).mean()}\")\n",
    "                \n",
    "                print(\"-------------- FP32 - BF16 end --------------------\")\n",
    "                 \"\"\"\n",
    "\n",
    "                BatchNorm_bf16_layer = Compare_BatchNorm_Precision(num_features=bn_weight.shape, intermediate_result=True, chunk=1024, compute_type=torch.bfloat16)\n",
    "                BatchNorm_bf16_layer.load_params(bn_weight, bn_bias, bn_running_mean, bn_running_var)\n",
    "\n",
    "                folder_name = f\"idx_{index}_{file_name}\"\n",
    "                input_pkl_file_name = f\"{epoch}_fwd_input.pkl\"\n",
    "                input_pkl_file_path = os.path.join(option.save_path, folder_name, input_pkl_file_name)\n",
    "\n",
    "                with open(input_pkl_file_path, \"rb\") as f:\n",
    "                    input_tensor = pickle.load(f)\n",
    "\n",
    "                output, output_fp16, fp_zero_mean_count, fp_total_mean_count, fp_zero_std_count, fp_total_std_count = BatchNorm_fp16_layer.forward(input_tensor, inference=False)\n",
    "                _, output_bf16, bf_zero_mean_count, bf_total_mean_count, bf_zero_std_count, bf_total_std_count = BatchNorm_bf16_layer.forward(input_tensor, inference=False)\n",
    "\n",
    "\n",
    "                C = output.shape[1]\n",
    "\n",
    "                output_t = output.transpose(0, 1).reshape(C, -1)\n",
    "                output_fp16_t = output_fp16.transpose(0, 1).reshape(C, -1)\n",
    "                fp16_mse_dist = ((output_t - output_fp16_t)**2).mean(-1)\n",
    "                fp16_L_inf = ((output_t - output_fp16_t)**2).abs().max(-1)[0]\n",
    "                \n",
    "                output_bf16_t = output_bf16.transpose(0, 1).reshape(C, -1)\n",
    "                bf16_mse_dist = ((output_t - output_bf16_t)**2).mean(-1)\n",
    "                bf16_L_inf = ((output_t - output_bf16_t)**2).abs().max(-1)[0]\n",
    "                \n",
    "                csv_dict = {\"epoch\": epoch, \"layer\": file_name, \"FP32-FP16_mse\": fp16_mse_dist, \"FP32-FP16_L_inf\":fp16_L_inf, \n",
    "                \"FP32-FP16 mean zero setting Error\" : f\"{fp_zero_mean_count} / {fp_total_mean_count}\", \n",
    "                \"FP32-FP16 mean std setting Error\" : f\"{fp_zero_std_count} / {fp_total_std_count}\" ,\n",
    "                \"FP32-BF16_mse\" : bf16_mse_dist, \"FP32-bf16_L_inf\":bf16_L_inf, \n",
    "                \"FP32-BF16 mean zero setting Error\" : f\"{bf_zero_mean_count} / {bf_total_mean_count}\", \n",
    "                \"FP32-BF16 mean std setting Error\" : f\"{bf_zero_std_count} / {bf_total_std_count}\" ,\n",
    "                \n",
    "                }\n",
    "                print(csv_dict)\n",
    "                result_df = result_df.append(csv_dict, ignore_index=True)\n",
    "\n",
    "result_df.to_csv(\"./precision_compare.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup code momentum check\n",
    "\n",
    "class Compare_BatchNorm_Precision(nn.Module):\n",
    "    # this is custom batchnorm different precision\n",
    "    # Considered https://github.com/ptrblck/pytorch_misc/blob/master/batch_norm_manual.py and rangeBN \n",
    "\n",
    "\n",
    "    def __init__(self, num_features, intermediate_result = False, chunk=1024, dim=1, momentum=0.9, affine=True, eps=1e-5, compute_type=torch.float16):\n",
    "        super(Compare_BatchNorm_Precision, self).__init__()\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.zeros(num_features))\n",
    "\n",
    "        self.momentum = momentum\n",
    "        self.dim = dim\n",
    "        self.eps = 1e-10\n",
    "        self.intermediate_result = intermediate_result\n",
    "        if affine:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_features))\n",
    "            self.weight = nn.Parameter(torch.Tensor(num_features))\n",
    "        self.compute_type = compute_type\n",
    "        self.eps = eps\n",
    "        self.chunk = chunk\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        if self.weight is not None:\n",
    "            self.weight.data.uniform_()\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def load_params(self, weight, bias, running_mean, running_var):\n",
    "        self.weight=weight\n",
    "        self.bias=bias\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var\n",
    "        \n",
    "\n",
    "    def forward(self, x, inference=True):\n",
    "        x_ch = x.type(self.compute_type)        \n",
    "        if not inference:\n",
    "            if self.momentum !=0: # using momentum\n",
    "                n,c,h,w = x.shape\n",
    "                mean = x.transpose(1,0).view(c,-1).mean(dim=-1) # c axis mean\n",
    "                std = x.transpose(1,0).view(c,-1).std(dim=-1) # c axis std\n",
    "\n",
    "                mean_ch, zero_mean_count, total_mean_compute =  BatchNormMeanSim(x, chunk=self.chunk, AdderType=self.compute_type)\n",
    "                std_ch, zero_std_count, total_std_compute = BatchNormStdSim(x, mean_ch, chunk=self.chunk, AdderType=self.compute_type)\n",
    "\n",
    "\n",
    "                momentum_mean = self.momentum * self.running_mean + (1-self.momentum) *  mean\n",
    "                momentum_mean_ch = self.momentum * self.running_mean.type(self.compute_type) + (1-self.momentum) * mean_ch\n",
    "\n",
    "                momentum_std = self.momentum * self.running_var + (1 - self.momentum) * std\n",
    "                momentum_std_ch = self.momentum * self.running_var.type(self.compute_type) + (1-self.momentum) * std_ch\n",
    "\n",
    "                out = (x - momentum_mean.view(1, mean.size(0), 1, 1)) / \\\n",
    "                    (momentum_std.view(1, momentum_std.size(0), 1, 1) + self.eps)\n",
    "\n",
    "                out_ch = (x_ch - momentum_mean_ch.view(1, momentum_mean_ch.size(0), 1, 1)) / \\\n",
    "                    (momentum_std_ch.view(1, momentum_std_ch.size(0), 1, 1) + self.eps)\n",
    "            else:\n",
    "                # not using momentum\n",
    "                n,c,h,w = x.shape\n",
    "                mean = x.transpose(1,0).view(c,-1).mean(dim=-1) # c axis mean\n",
    "                std = x.transpose(1,0).view(c,-1).std(dim=-1) # c axis std\n",
    "\n",
    "                mean_ch, zero_mean_count, total_mean_compute =  BatchNormMeanSim(x, chunk=self.chunk, AdderType=self.compute_type)\n",
    "                std_ch, zero_std_count, total_std_compute = BatchNormStdSim(x, mean_ch, chunk=self.chunk, AdderType=self.compute_type)\n",
    "\n",
    "                out = (x - mean.view(1, mean.size(0), 1, 1)) / \\\n",
    "                    (std.view(1, std.size(0), 1, 1) + self.eps)\n",
    "\n",
    "                out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) / \\\n",
    "                    (std_ch.view(1, std_ch.size(0), 1, 1) + self.eps)\n",
    "\n",
    "\n",
    "        else:\n",
    "            # using running_mean, and running_var\n",
    "            c = x_ch.shape[1]\n",
    "            mean = self.running_mean\n",
    "            scale = self.running_var\n",
    "            mean_ch = self.running_mean.type(self.compute_type)\n",
    "            scale_ch = self.running_var.type(self.compute_type)\n",
    "\n",
    "            out = (x - mean.view(1, mean.size(0), 1, 1)) / \\\n",
    "                (scale.view(1, scale.size(0), 1, 1) + self.eps)\n",
    "\n",
    "            out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) / \\\n",
    "                (scale_ch.view(1, scale.size(0), 1, 1) + self.eps.type(self.compute_type))\n",
    "        \n",
    "        if self.intermediate_result:\n",
    "\n",
    "        if self.weight is not None:\n",
    "            \n",
    "            weight = self.weight\n",
    "            weight_ch = self.weight.type(self.compute_type)\n",
    "            out = out * weight.view(1, weight.size(0), 1, 1)\n",
    "            out_ch = out_ch * weight_ch.view(1, weight_ch.size(0), 1, 1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias =self.bias\n",
    "            out = out + bias.view(1, bias.size(0), 1, 1)\n",
    "            bias_ch = self.bias.type(self.compute_type)\n",
    "            out_ch = out_ch + bias_ch.view(1, bias_ch.size(0), 1, 1)\n",
    "\n",
    "        return out, out_ch"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
