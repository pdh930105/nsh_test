{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from models.resnet import resnet18im, resnet18\n",
    "import os, random\n",
    "import copy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pyhocon import ConfigFactory\n",
    "from options import Option\n",
    "from dataset import create_loader\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from log_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "def accuracy(output, target):\n",
    "    pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "    return pred.eq(target.view_as(pred)).sum().item() / output.shape[0]\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    total_loss = AverageMeter()\n",
    "    total_acc = AverageMeter()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        total_loss.update(loss)\n",
    "        total_acc.update(accuracy(output, target))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: [{}] [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    print('Train Epoch: [{}]\\t Average Loss: {:.6f}\\t Total Acc : {:.4f}'.format(\n",
    "                epoch, total_loss.avg, total_acc.avg * 100))\n",
    "    \n",
    "    return total_acc.avg, total_loss.avg\n",
    "\n",
    "def test(model, test_loader, epoch, device):\n",
    "    model.eval()\n",
    "    total_test_loss = AverageMeter()\n",
    "    correct = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss = F.cross_entropy(output, target)\n",
    "            total_test_loss.update(test_loss)\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct.update((pred.eq(target.view_as(pred)).sum().item()))\n",
    "\n",
    "    total_test_acc = correct.sum / len(test_loader.dataset)\n",
    "    print('\\nEpoch [{}] Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        epoch, total_test_loss.avg, correct.sum, len(test_loader.dataset),\n",
    "        100. * total_test_acc))\n",
    "    return total_test_acc, total_test_loss.avg\n",
    "\n",
    "class Hook():\n",
    "    def __init__(self, module, forward=True):\n",
    "        if forward:\n",
    "            self.hook = module.register_forward_hook(self.hook_fn)\n",
    "        else:\n",
    "            self.hook = module.register_backward_hook(self.hook_fn)\n",
    "    \n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "option = Option(\"./cifar100.hocon\", \"test\")\n",
    "option.set_save_path()\n",
    "\n",
    "writer = SummaryWriter(os.path.join(option.save_path, \"tfboard_result\"))\n",
    "\n",
    "torch.manual_seed(option.seed)\n",
    "torch.cuda.manual_seed(option.seed)\n",
    "np.random.seed(option.seed)\n",
    "\n",
    "if option.dataset.lower() == \"cifar100\":\n",
    "    cifar100_path = os.path.join(option.data_path, \"CIFAR100\")\n",
    "    train_loader, test_loader, n_class, image_size = create_loader(option.batch_size, cifar100_path, option.dataset)\n",
    "    if \"resnet18\" in option.model_name.lower():\n",
    "        net = resnet18(pretrained=False, num_classes=n_class)\n",
    "    \n",
    "    else:\n",
    "        raise AssertionError(\"cifar100 only resnet18 test\")\n",
    "\n",
    "\n",
    "elif option.dataset.lower() == \"imagenet\":\n",
    "    train_loader ,test_loader, n_class, image_size = create_loader(option.batch_size, option.data_path, option.dataset)\n",
    "    if \"resnet18\" in option.model_name.lower():\n",
    "        net = resnet18im(pretrained=False, num_classes=n_class)\n",
    "    else:\n",
    "        raise AssertionError(\"imagenet only resnet18 test\")\n",
    "\n",
    "else:\n",
    "    raise AssertionError(\"using only dataset imagenet/cifar100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if option.optimizer.lower() == \"sgd\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=option.lr, momentum=option.momentum, weight_decay=option.weight_decay, nesterov=True)\n",
    "\n",
    "elif option.optimizer.lower() == \"adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr= option.lr, weight_decay=option.weight_decay)\n",
    "\n",
    "if option.scheduler.lower() == \"multi_step\":\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=option.ml_step, gamma=option.lr_gamma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train base line\n"
     ]
    }
   ],
   "source": [
    "if option.load_state_dict != False:\n",
    "    if not os.path.exists(option.load_state_dict):\n",
    "        raise AssertionError(\"If using load state dict, please set default path\")\n",
    "    else:\n",
    "        print(f\"load state dict {option.load_state_dict}\")\n",
    "        checkpoint = torch.load(option.load_state_dict)\n",
    "        start_epoch = checkpoint['end_epoch']+1\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "else:\n",
    "    print(f\"train base line\")\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_result(model, data, option):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    hook_list = []\n",
    "    for i, (name, module) in enumerate(model.named_modules()):\n",
    "        if isinstance(module, nn.BatchNorm2d) and \"downsample\" not in name:\n",
    "            if count in option.activation_index:\n",
    "                temp_hook = Hook(module)\n",
    "                name_idx = f\"idx_{count}_{name}\"\n",
    "                hook_list.append((name_idx, temp_hook))\n",
    "            count+=1\n",
    "    with torch.no_grad():\n",
    "        _ = model(data)\n",
    "    \n",
    "    return hook_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batchnorm_param_dict(net, epoch):\n",
    "    count = 0\n",
    "    save_bn_dict = {}\n",
    "    save_bn_dict['epoch'] = epoch\n",
    "\n",
    "    for name, m in net.named_modules():\n",
    "        if isinstance(m, nn.BatchNorm2d) and 'downsample' not in name:\n",
    "            save_bn_dict[f\"{count}_{name}_alpha\"] = m.weight.cpu().detach().numpy()\n",
    "            save_bn_dict[f\"{count}_{name}_beta\"] = m.bias.cpu().detach().numpy()\n",
    "            save_bn_dict[f\"{count}_{name}_avg\"] = m.running_mean.cpu().detach().numpy()\n",
    "            save_bn_dict[f\"{count}_{name}_var\"] = m.running_var.cpu().detach().numpy()\n",
    "            count+=1\n",
    "    return save_bn_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------start batchnorm param logging -----------\n",
      "\n",
      "-------end batchnorm param logging -----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "net = net.to(device)\n",
    "random_sampler= torch.utils.data.RandomSampler(test_loader.dataset)\n",
    "sample_loader = torch.utils.data.DataLoader(test_loader.dataset, batch_size=128, sampler=random_sampler)\n",
    "\n",
    "check_data, _ = next(iter(sample_loader))\n",
    "check_data = check_data.to(device)\n",
    "\n",
    "ones_shape = [option.batch_size, 3, 224, 224] if option.dataset.lower() == \"imagenet\" else [option.batch_size, 3, 32, 32]\n",
    "dummy_input = torch.ones(ones_shape).to(device) * 0.1\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    writer.add_graph(net, dummy_input)\n",
    "\n",
    "#del dummy_input\n",
    "#del ones_shape\n",
    "\n",
    "csv_path = os.path.join(option.save_path, \"batchnorm_param.csv\")\n",
    "\n",
    "batchnorm_df = pd.DataFrame()\n",
    "\n",
    "print(f\"-------start batchnorm param logging -----------\\n\")\n",
    "\n",
    "save_bn_dict = get_batchnorm_param_dict(net, epoch=-1)\n",
    "batchnorm_df = batchnorm_df.append(save_bn_dict, ignore_index=True)\n",
    "batchnorm_df.to_csv(csv_path)\n",
    "\n",
    "print(f\"-------end batchnorm param logging -----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfigTree([('save_path', './save_log/resnet18_cifar100'), ('data_path', '/dataset/'), ('dataset', 'cifar100'), ('nGPU', 4), ('GPU', [0, 1, 2, 3]), ('visible_devices', '1'), ('model_name', 'resnet18'), ('worker', 8), ('seed', 0), ('train', True), ('epochs', 150), ('batch_size', 128), ('momentum', 0.9), ('weight_decay', 0.0005), ('optimizer', 'SGD'), ('warmup', 5), ('lr', 0.01), ('scheduler', 'multi_step'), ('ml_step', [30, 60, 90]), ('lr_gamma', 0.2), ('load_state_dict', False), ('log_override', True), ('activation_index', [2, 7, 14]), ('activation_step', [30, 50, 70, 100])])\n"
     ]
    }
   ],
   "source": [
    "print(option.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------0 epoch start-----------\n",
      "Train Epoch: [0] [0/50000 (0%)]\tLoss: 4.822345\n",
      "Train Epoch: [0]\t Average Loss: 3.889081\t Total Acc : 10.6909\n",
      "-------0 epoch end  -----------\n",
      "\n",
      "-------0 batch norm parameter logging ---------\n",
      "-------0 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 0 batch layer input tensor ------------------\n",
      "-------- logging end 0 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [0] Test set: Average loss: 3.4966, Accuracy: 1672/10000 (16.7200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 0 result ------------\n",
      "logging best performance 0 epoch\n",
      "-------1 epoch start-----------\n",
      "Train Epoch: [1] [0/50000 (0%)]\tLoss: 3.612968\n",
      "Train Epoch: [1]\t Average Loss: 3.337270\t Total Acc : 18.8971\n",
      "-------1 epoch end  -----------\n",
      "\n",
      "-------1 batch norm parameter logging ---------\n",
      "-------1 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [1] Test set: Average loss: 3.1624, Accuracy: 2275/10000 (22.7500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 1 result ------------\n",
      "logging best performance 1 epoch\n",
      "-------2 epoch start-----------\n",
      "Train Epoch: [2] [0/50000 (0%)]\tLoss: 3.306896\n",
      "Train Epoch: [2]\t Average Loss: 3.087966\t Total Acc : 23.6717\n",
      "-------2 epoch end  -----------\n",
      "\n",
      "-------2 batch norm parameter logging ---------\n",
      "-------2 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [2] Test set: Average loss: 2.9115, Accuracy: 2711/10000 (27.1100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 2 result ------------\n",
      "logging best performance 2 epoch\n",
      "-------3 epoch start-----------\n",
      "Train Epoch: [3] [0/50000 (0%)]\tLoss: 2.756001\n",
      "Train Epoch: [3]\t Average Loss: 2.910022\t Total Acc : 26.9078\n",
      "-------3 epoch end  -----------\n",
      "\n",
      "-------3 batch norm parameter logging ---------\n",
      "-------3 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [3] Test set: Average loss: 2.7720, Accuracy: 2980/10000 (29.8000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 3 result ------------\n",
      "logging best performance 3 epoch\n",
      "-------4 epoch start-----------\n",
      "Train Epoch: [4] [0/50000 (0%)]\tLoss: 2.878599\n",
      "Train Epoch: [4]\t Average Loss: 2.761673\t Total Acc : 29.9540\n",
      "-------4 epoch end  -----------\n",
      "\n",
      "-------4 batch norm parameter logging ---------\n",
      "-------4 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [4] Test set: Average loss: 2.7086, Accuracy: 3130/10000 (31.3000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 4 result ------------\n",
      "logging best performance 4 epoch\n",
      "-------5 epoch start-----------\n",
      "Train Epoch: [5] [0/50000 (0%)]\tLoss: 2.529573\n",
      "Train Epoch: [5]\t Average Loss: 2.644011\t Total Acc : 32.1695\n",
      "-------5 epoch end  -----------\n",
      "\n",
      "-------5 batch norm parameter logging ---------\n",
      "-------5 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 5 batch layer input tensor ------------------\n",
      "-------- logging end 5 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [5] Test set: Average loss: 2.5599, Accuracy: 3447/10000 (34.4700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 5 result ------------\n",
      "logging best performance 5 epoch\n",
      "-------6 epoch start-----------\n",
      "Train Epoch: [6] [0/50000 (0%)]\tLoss: 2.479699\n",
      "Train Epoch: [6]\t Average Loss: 2.533306\t Total Acc : 34.3342\n",
      "-------6 epoch end  -----------\n",
      "\n",
      "-------6 batch norm parameter logging ---------\n",
      "-------6 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [6] Test set: Average loss: 2.5388, Accuracy: 3502/10000 (35.0200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 6 result ------------\n",
      "logging best performance 6 epoch\n",
      "-------7 epoch start-----------\n",
      "Train Epoch: [7] [0/50000 (0%)]\tLoss: 2.430578\n",
      "Train Epoch: [7]\t Average Loss: 2.429462\t Total Acc : 36.3559\n",
      "-------7 epoch end  -----------\n",
      "\n",
      "-------7 batch norm parameter logging ---------\n",
      "-------7 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [7] Test set: Average loss: 2.4558, Accuracy: 3661/10000 (36.6100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 7 result ------------\n",
      "logging best performance 7 epoch\n",
      "-------8 epoch start-----------\n",
      "Train Epoch: [8] [0/50000 (0%)]\tLoss: 2.604788\n",
      "Train Epoch: [8]\t Average Loss: 2.342565\t Total Acc : 38.3152\n",
      "-------8 epoch end  -----------\n",
      "\n",
      "-------8 batch norm parameter logging ---------\n",
      "-------8 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [8] Test set: Average loss: 2.4145, Accuracy: 3800/10000 (38.0000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 8 result ------------\n",
      "logging best performance 8 epoch\n",
      "-------9 epoch start-----------\n",
      "Train Epoch: [9] [0/50000 (0%)]\tLoss: 2.399656\n",
      "Train Epoch: [9]\t Average Loss: 2.255086\t Total Acc : 40.0308\n",
      "-------9 epoch end  -----------\n",
      "\n",
      "-------9 batch norm parameter logging ---------\n",
      "-------9 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [9] Test set: Average loss: 2.3175, Accuracy: 4003/10000 (40.0300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 9 result ------------\n",
      "logging best performance 9 epoch\n",
      "-------10 epoch start-----------\n",
      "Train Epoch: [10] [0/50000 (0%)]\tLoss: 2.314750\n",
      "Train Epoch: [10]\t Average Loss: 2.190272\t Total Acc : 41.4654\n",
      "-------10 epoch end  -----------\n",
      "\n",
      "-------10 batch norm parameter logging ---------\n",
      "-------10 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 10 batch layer input tensor ------------------\n",
      "-------- logging end 10 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [10] Test set: Average loss: 2.2256, Accuracy: 4138/10000 (41.3800%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 10 result ------------\n",
      "logging best performance 10 epoch\n",
      "-------11 epoch start-----------\n",
      "Train Epoch: [11] [0/50000 (0%)]\tLoss: 2.228493\n",
      "Train Epoch: [11]\t Average Loss: 2.121384\t Total Acc : 42.8625\n",
      "-------11 epoch end  -----------\n",
      "\n",
      "-------11 batch norm parameter logging ---------\n",
      "-------11 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [11] Test set: Average loss: 2.1984, Accuracy: 4250/10000 (42.5000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 11 result ------------\n",
      "logging best performance 11 epoch\n",
      "-------12 epoch start-----------\n",
      "Train Epoch: [12] [0/50000 (0%)]\tLoss: 2.128004\n",
      "Train Epoch: [12]\t Average Loss: 2.044318\t Total Acc : 44.7750\n",
      "-------12 epoch end  -----------\n",
      "\n",
      "-------12 batch norm parameter logging ---------\n",
      "-------12 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [12] Test set: Average loss: 2.2185, Accuracy: 4246/10000 (42.4600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 12 result ------------\n",
      "-------13 epoch start-----------\n",
      "Train Epoch: [13] [0/50000 (0%)]\tLoss: 1.846432\n",
      "Train Epoch: [13]\t Average Loss: 1.991462\t Total Acc : 45.9819\n",
      "-------13 epoch end  -----------\n",
      "\n",
      "-------13 batch norm parameter logging ---------\n",
      "-------13 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [13] Test set: Average loss: 2.1482, Accuracy: 4366/10000 (43.6600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 13 result ------------\n",
      "logging best performance 13 epoch\n",
      "-------14 epoch start-----------\n",
      "Train Epoch: [14] [0/50000 (0%)]\tLoss: 1.947100\n",
      "Train Epoch: [14]\t Average Loss: 1.927087\t Total Acc : 47.4385\n",
      "-------14 epoch end  -----------\n",
      "\n",
      "-------14 batch norm parameter logging ---------\n",
      "-------14 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [14] Test set: Average loss: 2.1096, Accuracy: 4434/10000 (44.3400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 14 result ------------\n",
      "logging best performance 14 epoch\n",
      "-------15 epoch start-----------\n",
      "Train Epoch: [15] [0/50000 (0%)]\tLoss: 1.717793\n",
      "Train Epoch: [15]\t Average Loss: 1.869773\t Total Acc : 48.9114\n",
      "-------15 epoch end  -----------\n",
      "\n",
      "-------15 batch norm parameter logging ---------\n",
      "-------15 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 15 batch layer input tensor ------------------\n",
      "-------- logging end 15 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [15] Test set: Average loss: 2.1033, Accuracy: 4451/10000 (44.5100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 15 result ------------\n",
      "logging best performance 15 epoch\n",
      "-------16 epoch start-----------\n",
      "Train Epoch: [16] [0/50000 (0%)]\tLoss: 1.595132\n",
      "Train Epoch: [16]\t Average Loss: 1.823611\t Total Acc : 49.4445\n",
      "-------16 epoch end  -----------\n",
      "\n",
      "-------16 batch norm parameter logging ---------\n",
      "-------16 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [16] Test set: Average loss: 2.1385, Accuracy: 4492/10000 (44.9200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 16 result ------------\n",
      "logging best performance 16 epoch\n",
      "-------17 epoch start-----------\n",
      "Train Epoch: [17] [0/50000 (0%)]\tLoss: 1.576965\n",
      "Train Epoch: [17]\t Average Loss: 1.772961\t Total Acc : 50.9511\n",
      "-------17 epoch end  -----------\n",
      "\n",
      "-------17 batch norm parameter logging ---------\n",
      "-------17 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [17] Test set: Average loss: 2.0527, Accuracy: 4662/10000 (46.6200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 17 result ------------\n",
      "logging best performance 17 epoch\n",
      "-------18 epoch start-----------\n",
      "Train Epoch: [18] [0/50000 (0%)]\tLoss: 1.754486\n",
      "Train Epoch: [18]\t Average Loss: 1.730107\t Total Acc : 51.7747\n",
      "-------18 epoch end  -----------\n",
      "\n",
      "-------18 batch norm parameter logging ---------\n",
      "-------18 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [18] Test set: Average loss: 2.0962, Accuracy: 4564/10000 (45.6400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 18 result ------------\n",
      "-------19 epoch start-----------\n",
      "Train Epoch: [19] [0/50000 (0%)]\tLoss: 1.658912\n",
      "Train Epoch: [19]\t Average Loss: 1.682841\t Total Acc : 53.0207\n",
      "-------19 epoch end  -----------\n",
      "\n",
      "-------19 batch norm parameter logging ---------\n",
      "-------19 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [19] Test set: Average loss: 2.0706, Accuracy: 4638/10000 (46.3800%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 19 result ------------\n",
      "-------20 epoch start-----------\n",
      "Train Epoch: [20] [0/50000 (0%)]\tLoss: 1.871777\n",
      "Train Epoch: [20]\t Average Loss: 1.638311\t Total Acc : 53.8723\n",
      "-------20 epoch end  -----------\n",
      "\n",
      "-------20 batch norm parameter logging ---------\n",
      "-------20 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 20 batch layer input tensor ------------------\n",
      "-------- logging end 20 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [20] Test set: Average loss: 2.0813, Accuracy: 4602/10000 (46.0200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 20 result ------------\n",
      "-------21 epoch start-----------\n",
      "Train Epoch: [21] [0/50000 (0%)]\tLoss: 1.539117\n",
      "Train Epoch: [21]\t Average Loss: 1.600270\t Total Acc : 54.7207\n",
      "-------21 epoch end  -----------\n",
      "\n",
      "-------21 batch norm parameter logging ---------\n",
      "-------21 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [21] Test set: Average loss: 2.0807, Accuracy: 4647/10000 (46.4700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 21 result ------------\n",
      "-------22 epoch start-----------\n",
      "Train Epoch: [22] [0/50000 (0%)]\tLoss: 1.591386\n",
      "Train Epoch: [22]\t Average Loss: 1.553544\t Total Acc : 56.0026\n",
      "-------22 epoch end  -----------\n",
      "\n",
      "-------22 batch norm parameter logging ---------\n",
      "-------22 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [22] Test set: Average loss: 2.0607, Accuracy: 4656/10000 (46.5600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 22 result ------------\n",
      "-------23 epoch start-----------\n",
      "Train Epoch: [23] [0/50000 (0%)]\tLoss: 1.555660\n",
      "Train Epoch: [23]\t Average Loss: 1.519867\t Total Acc : 56.9769\n",
      "-------23 epoch end  -----------\n",
      "\n",
      "-------23 batch norm parameter logging ---------\n",
      "-------23 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [23] Test set: Average loss: 2.0309, Accuracy: 4712/10000 (47.1200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 23 result ------------\n",
      "logging best performance 23 epoch\n",
      "-------24 epoch start-----------\n",
      "Train Epoch: [24] [0/50000 (0%)]\tLoss: 1.509933\n",
      "Train Epoch: [24]\t Average Loss: 1.471960\t Total Acc : 58.0091\n",
      "-------24 epoch end  -----------\n",
      "\n",
      "-------24 batch norm parameter logging ---------\n",
      "-------24 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [24] Test set: Average loss: 2.0732, Accuracy: 4745/10000 (47.4500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 24 result ------------\n",
      "logging best performance 24 epoch\n",
      "-------25 epoch start-----------\n",
      "Train Epoch: [25] [0/50000 (0%)]\tLoss: 1.348771\n",
      "Train Epoch: [25]\t Average Loss: 1.437775\t Total Acc : 58.6877\n",
      "-------25 epoch end  -----------\n",
      "\n",
      "-------25 batch norm parameter logging ---------\n",
      "-------25 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 25 batch layer input tensor ------------------\n",
      "-------- logging end 25 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [25] Test set: Average loss: 2.0631, Accuracy: 4796/10000 (47.9600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 25 result ------------\n",
      "logging best performance 25 epoch\n",
      "-------26 epoch start-----------\n",
      "Train Epoch: [26] [0/50000 (0%)]\tLoss: 1.288291\n",
      "Train Epoch: [26]\t Average Loss: 1.396482\t Total Acc : 59.9624\n",
      "-------26 epoch end  -----------\n",
      "\n",
      "-------26 batch norm parameter logging ---------\n",
      "-------26 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [26] Test set: Average loss: 2.0526, Accuracy: 4779/10000 (47.7900%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 26 result ------------\n",
      "-------27 epoch start-----------\n",
      "Train Epoch: [27] [0/50000 (0%)]\tLoss: 1.251763\n",
      "Train Epoch: [27]\t Average Loss: 1.366600\t Total Acc : 60.4915\n",
      "-------27 epoch end  -----------\n",
      "\n",
      "-------27 batch norm parameter logging ---------\n",
      "-------27 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [27] Test set: Average loss: 2.0649, Accuracy: 4774/10000 (47.7400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 27 result ------------\n",
      "-------28 epoch start-----------\n",
      "Train Epoch: [28] [0/50000 (0%)]\tLoss: 0.889389\n",
      "Train Epoch: [28]\t Average Loss: 1.326548\t Total Acc : 61.6736\n",
      "-------28 epoch end  -----------\n",
      "\n",
      "-------28 batch norm parameter logging ---------\n",
      "-------28 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [28] Test set: Average loss: 2.0495, Accuracy: 4878/10000 (48.7800%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 28 result ------------\n",
      "logging best performance 28 epoch\n",
      "-------29 epoch start-----------\n",
      "Train Epoch: [29] [0/50000 (0%)]\tLoss: 1.280233\n",
      "Train Epoch: [29]\t Average Loss: 1.288442\t Total Acc : 62.7070\n",
      "-------29 epoch end  -----------\n",
      "\n",
      "-------29 batch norm parameter logging ---------\n",
      "-------29 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [29] Test set: Average loss: 2.0452, Accuracy: 4836/10000 (48.3600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 29 result ------------\n",
      "-------30 epoch start-----------\n",
      "Train Epoch: [30] [0/50000 (0%)]\tLoss: 1.257771\n",
      "Train Epoch: [30]\t Average Loss: 1.258811\t Total Acc : 63.2860\n",
      "-------30 epoch end  -----------\n",
      "\n",
      "-------30 batch norm parameter logging ---------\n",
      "-------30 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 30 batch layer input tensor ------------------\n",
      "-------- logging end 30 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [30] Test set: Average loss: 2.0605, Accuracy: 4806/10000 (48.0600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 30 result ------------\n",
      "-------31 epoch start-----------\n",
      "Train Epoch: [31] [0/50000 (0%)]\tLoss: 1.151547\n",
      "Train Epoch: [31]\t Average Loss: 1.231240\t Total Acc : 64.0349\n",
      "-------31 epoch end  -----------\n",
      "\n",
      "-------31 batch norm parameter logging ---------\n",
      "-------31 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [31] Test set: Average loss: 2.0394, Accuracy: 4880/10000 (48.8000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 31 result ------------\n",
      "logging best performance 31 epoch\n",
      "-------32 epoch start-----------\n",
      "Train Epoch: [32] [0/50000 (0%)]\tLoss: 0.862917\n",
      "Train Epoch: [32]\t Average Loss: 1.196869\t Total Acc : 64.8841\n",
      "-------32 epoch end  -----------\n",
      "\n",
      "-------32 batch norm parameter logging ---------\n",
      "-------32 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [32] Test set: Average loss: 2.0672, Accuracy: 4872/10000 (48.7200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 32 result ------------\n",
      "-------33 epoch start-----------\n",
      "Train Epoch: [33] [0/50000 (0%)]\tLoss: 1.099298\n",
      "Train Epoch: [33]\t Average Loss: 1.166406\t Total Acc : 65.5531\n",
      "-------33 epoch end  -----------\n",
      "\n",
      "-------33 batch norm parameter logging ---------\n",
      "-------33 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [33] Test set: Average loss: 2.0731, Accuracy: 4914/10000 (49.1400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 33 result ------------\n",
      "logging best performance 33 epoch\n",
      "-------34 epoch start-----------\n",
      "Train Epoch: [34] [0/50000 (0%)]\tLoss: 1.185251\n",
      "Train Epoch: [34]\t Average Loss: 1.132805\t Total Acc : 66.4874\n",
      "-------34 epoch end  -----------\n",
      "\n",
      "-------34 batch norm parameter logging ---------\n",
      "-------34 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [34] Test set: Average loss: 2.0444, Accuracy: 4953/10000 (49.5300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 34 result ------------\n",
      "logging best performance 34 epoch\n",
      "-------35 epoch start-----------\n",
      "Train Epoch: [35] [0/50000 (0%)]\tLoss: 1.020104\n",
      "Train Epoch: [35]\t Average Loss: 1.095058\t Total Acc : 67.5995\n",
      "-------35 epoch end  -----------\n",
      "\n",
      "-------35 batch norm parameter logging ---------\n",
      "-------35 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 35 batch layer input tensor ------------------\n",
      "-------- logging end 35 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [35] Test set: Average loss: 2.1178, Accuracy: 4884/10000 (48.8400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 35 result ------------\n",
      "-------36 epoch start-----------\n",
      "Train Epoch: [36] [0/50000 (0%)]\tLoss: 1.046064\n",
      "Train Epoch: [36]\t Average Loss: 1.081389\t Total Acc : 67.9496\n",
      "-------36 epoch end  -----------\n",
      "\n",
      "-------36 batch norm parameter logging ---------\n",
      "-------36 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [36] Test set: Average loss: 2.1003, Accuracy: 4905/10000 (49.0500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 36 result ------------\n",
      "-------37 epoch start-----------\n",
      "Train Epoch: [37] [0/50000 (0%)]\tLoss: 0.885742\n",
      "Train Epoch: [37]\t Average Loss: 1.039917\t Total Acc : 68.9574\n",
      "-------37 epoch end  -----------\n",
      "\n",
      "-------37 batch norm parameter logging ---------\n",
      "-------37 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [37] Test set: Average loss: 2.1153, Accuracy: 4960/10000 (49.6000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 37 result ------------\n",
      "logging best performance 37 epoch\n",
      "-------38 epoch start-----------\n",
      "Train Epoch: [38] [0/50000 (0%)]\tLoss: 0.960944\n",
      "Train Epoch: [38]\t Average Loss: 1.012175\t Total Acc : 69.5257\n",
      "-------38 epoch end  -----------\n",
      "\n",
      "-------38 batch norm parameter logging ---------\n",
      "-------38 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [38] Test set: Average loss: 2.1088, Accuracy: 4924/10000 (49.2400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 38 result ------------\n",
      "-------39 epoch start-----------\n",
      "Train Epoch: [39] [0/50000 (0%)]\tLoss: 0.771763\n",
      "Train Epoch: [39]\t Average Loss: 0.992290\t Total Acc : 70.0420\n",
      "-------39 epoch end  -----------\n",
      "\n",
      "-------39 batch norm parameter logging ---------\n",
      "-------39 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [39] Test set: Average loss: 2.1291, Accuracy: 4942/10000 (49.4200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 39 result ------------\n",
      "-------40 epoch start-----------\n",
      "Train Epoch: [40] [0/50000 (0%)]\tLoss: 0.702212\n",
      "Train Epoch: [40]\t Average Loss: 0.969975\t Total Acc : 71.0486\n",
      "-------40 epoch end  -----------\n",
      "\n",
      "-------40 batch norm parameter logging ---------\n",
      "-------40 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 40 batch layer input tensor ------------------\n",
      "-------- logging end 40 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [40] Test set: Average loss: 2.1483, Accuracy: 4943/10000 (49.4300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 40 result ------------\n",
      "-------41 epoch start-----------\n",
      "Train Epoch: [41] [0/50000 (0%)]\tLoss: 0.964644\n",
      "Train Epoch: [41]\t Average Loss: 0.935362\t Total Acc : 71.6892\n",
      "-------41 epoch end  -----------\n",
      "\n",
      "-------41 batch norm parameter logging ---------\n",
      "-------41 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [41] Test set: Average loss: 2.1443, Accuracy: 4967/10000 (49.6700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 41 result ------------\n",
      "logging best performance 41 epoch\n",
      "-------42 epoch start-----------\n",
      "Train Epoch: [42] [0/50000 (0%)]\tLoss: 0.859031\n",
      "Train Epoch: [42]\t Average Loss: 0.903262\t Total Acc : 72.7466\n",
      "-------42 epoch end  -----------\n",
      "\n",
      "-------42 batch norm parameter logging ---------\n",
      "-------42 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [42] Test set: Average loss: 2.1779, Accuracy: 4909/10000 (49.0900%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 42 result ------------\n",
      "-------43 epoch start-----------\n",
      "Train Epoch: [43] [0/50000 (0%)]\tLoss: 0.867159\n",
      "Train Epoch: [43]\t Average Loss: 0.884394\t Total Acc : 73.2125\n",
      "-------43 epoch end  -----------\n",
      "\n",
      "-------43 batch norm parameter logging ---------\n",
      "-------43 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [43] Test set: Average loss: 2.1488, Accuracy: 4963/10000 (49.6300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 43 result ------------\n",
      "-------44 epoch start-----------\n",
      "Train Epoch: [44] [0/50000 (0%)]\tLoss: 0.811009\n",
      "Train Epoch: [44]\t Average Loss: 0.862574\t Total Acc : 73.8247\n",
      "-------44 epoch end  -----------\n",
      "\n",
      "-------44 batch norm parameter logging ---------\n",
      "-------44 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [44] Test set: Average loss: 2.1865, Accuracy: 4901/10000 (49.0100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 44 result ------------\n",
      "-------45 epoch start-----------\n",
      "Train Epoch: [45] [0/50000 (0%)]\tLoss: 0.739550\n",
      "Train Epoch: [45]\t Average Loss: 0.824952\t Total Acc : 74.8338\n",
      "-------45 epoch end  -----------\n",
      "\n",
      "-------45 batch norm parameter logging ---------\n",
      "-------45 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 45 batch layer input tensor ------------------\n",
      "-------- logging end 45 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [45] Test set: Average loss: 2.1782, Accuracy: 4949/10000 (49.4900%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 45 result ------------\n",
      "-------46 epoch start-----------\n",
      "Train Epoch: [46] [0/50000 (0%)]\tLoss: 0.643807\n",
      "Train Epoch: [46]\t Average Loss: 0.812694\t Total Acc : 75.3365\n",
      "-------46 epoch end  -----------\n",
      "\n",
      "-------46 batch norm parameter logging ---------\n",
      "-------46 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [46] Test set: Average loss: 2.2086, Accuracy: 4962/10000 (49.6200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 46 result ------------\n",
      "-------47 epoch start-----------\n",
      "Train Epoch: [47] [0/50000 (0%)]\tLoss: 0.773323\n",
      "Train Epoch: [47]\t Average Loss: 0.796869\t Total Acc : 75.6586\n",
      "-------47 epoch end  -----------\n",
      "\n",
      "-------47 batch norm parameter logging ---------\n",
      "-------47 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [47] Test set: Average loss: 2.1771, Accuracy: 4957/10000 (49.5700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 47 result ------------\n",
      "-------48 epoch start-----------\n",
      "Train Epoch: [48] [0/50000 (0%)]\tLoss: 0.597215\n",
      "Train Epoch: [48]\t Average Loss: 0.780681\t Total Acc : 76.1793\n",
      "-------48 epoch end  -----------\n",
      "\n",
      "-------48 batch norm parameter logging ---------\n",
      "-------48 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [48] Test set: Average loss: 2.2025, Accuracy: 4945/10000 (49.4500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 48 result ------------\n",
      "-------49 epoch start-----------\n",
      "Train Epoch: [49] [0/50000 (0%)]\tLoss: 0.701654\n",
      "Train Epoch: [49]\t Average Loss: 0.760904\t Total Acc : 76.8175\n",
      "-------49 epoch end  -----------\n",
      "\n",
      "-------49 batch norm parameter logging ---------\n",
      "-------49 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [49] Test set: Average loss: 2.2519, Accuracy: 4867/10000 (48.6700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 49 result ------------\n",
      "-------50 epoch start-----------\n",
      "Train Epoch: [50] [0/50000 (0%)]\tLoss: 0.694511\n",
      "Train Epoch: [50]\t Average Loss: 0.742763\t Total Acc : 77.1028\n",
      "-------50 epoch end  -----------\n",
      "\n",
      "-------50 batch norm parameter logging ---------\n",
      "-------50 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 50 batch layer input tensor ------------------\n",
      "-------- logging end 50 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [50] Test set: Average loss: 2.2653, Accuracy: 4885/10000 (48.8500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 50 result ------------\n",
      "-------51 epoch start-----------\n",
      "Train Epoch: [51] [0/50000 (0%)]\tLoss: 0.558697\n",
      "Train Epoch: [51]\t Average Loss: 0.715945\t Total Acc : 77.9568\n",
      "-------51 epoch end  -----------\n",
      "\n",
      "-------51 batch norm parameter logging ---------\n",
      "-------51 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [51] Test set: Average loss: 2.2417, Accuracy: 4960/10000 (49.6000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 51 result ------------\n",
      "-------52 epoch start-----------\n",
      "Train Epoch: [52] [0/50000 (0%)]\tLoss: 0.589050\n",
      "Train Epoch: [52]\t Average Loss: 0.679722\t Total Acc : 79.2991\n",
      "-------52 epoch end  -----------\n",
      "\n",
      "-------52 batch norm parameter logging ---------\n",
      "-------52 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [52] Test set: Average loss: 2.2785, Accuracy: 4934/10000 (49.3400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 52 result ------------\n",
      "-------53 epoch start-----------\n",
      "Train Epoch: [53] [0/50000 (0%)]\tLoss: 0.622385\n",
      "Train Epoch: [53]\t Average Loss: 0.682361\t Total Acc : 79.1121\n",
      "-------53 epoch end  -----------\n",
      "\n",
      "-------53 batch norm parameter logging ---------\n",
      "-------53 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [53] Test set: Average loss: 2.3395, Accuracy: 4867/10000 (48.6700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 53 result ------------\n",
      "-------54 epoch start-----------\n",
      "Train Epoch: [54] [0/50000 (0%)]\tLoss: 0.702539\n",
      "Train Epoch: [54]\t Average Loss: 0.669293\t Total Acc : 79.2455\n",
      "-------54 epoch end  -----------\n",
      "\n",
      "-------54 batch norm parameter logging ---------\n",
      "-------54 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [54] Test set: Average loss: 2.2720, Accuracy: 4941/10000 (49.4100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 54 result ------------\n",
      "-------55 epoch start-----------\n",
      "Train Epoch: [55] [0/50000 (0%)]\tLoss: 0.570131\n",
      "Train Epoch: [55]\t Average Loss: 0.646503\t Total Acc : 80.0312\n",
      "-------55 epoch end  -----------\n",
      "\n",
      "-------55 batch norm parameter logging ---------\n",
      "-------55 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 55 batch layer input tensor ------------------\n",
      "-------- logging end 55 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [55] Test set: Average loss: 2.3157, Accuracy: 4934/10000 (49.3400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 55 result ------------\n",
      "-------56 epoch start-----------\n",
      "Train Epoch: [56] [0/50000 (0%)]\tLoss: 0.589774\n",
      "Train Epoch: [56]\t Average Loss: 0.630526\t Total Acc : 80.7309\n",
      "-------56 epoch end  -----------\n",
      "\n",
      "-------56 batch norm parameter logging ---------\n",
      "-------56 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [56] Test set: Average loss: 2.3391, Accuracy: 4967/10000 (49.6700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 56 result ------------\n",
      "-------57 epoch start-----------\n",
      "Train Epoch: [57] [0/50000 (0%)]\tLoss: 0.506589\n",
      "Train Epoch: [57]\t Average Loss: 0.615649\t Total Acc : 80.9451\n",
      "-------57 epoch end  -----------\n",
      "\n",
      "-------57 batch norm parameter logging ---------\n",
      "-------57 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [57] Test set: Average loss: 2.3346, Accuracy: 4951/10000 (49.5100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 57 result ------------\n",
      "-------58 epoch start-----------\n",
      "Train Epoch: [58] [0/50000 (0%)]\tLoss: 0.568895\n",
      "Train Epoch: [58]\t Average Loss: 0.600940\t Total Acc : 81.5046\n",
      "-------58 epoch end  -----------\n",
      "\n",
      "-------58 batch norm parameter logging ---------\n",
      "-------58 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [58] Test set: Average loss: 2.3640, Accuracy: 4928/10000 (49.2800%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 58 result ------------\n",
      "-------59 epoch start-----------\n",
      "Train Epoch: [59] [0/50000 (0%)]\tLoss: 0.689902\n",
      "Train Epoch: [59]\t Average Loss: 0.592141\t Total Acc : 81.7052\n",
      "-------59 epoch end  -----------\n",
      "\n",
      "-------59 batch norm parameter logging ---------\n",
      "-------59 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [59] Test set: Average loss: 2.3622, Accuracy: 4942/10000 (49.4200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 59 result ------------\n",
      "-------60 epoch start-----------\n",
      "Train Epoch: [60] [0/50000 (0%)]\tLoss: 0.364578\n",
      "Train Epoch: [60]\t Average Loss: 0.571453\t Total Acc : 82.4185\n",
      "-------60 epoch end  -----------\n",
      "\n",
      "-------60 batch norm parameter logging ---------\n",
      "-------60 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 60 batch layer input tensor ------------------\n",
      "-------- logging end 60 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [60] Test set: Average loss: 2.3969, Accuracy: 4906/10000 (49.0600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 60 result ------------\n",
      "-------61 epoch start-----------\n",
      "Train Epoch: [61] [0/50000 (0%)]\tLoss: 0.424230\n",
      "Train Epoch: [61]\t Average Loss: 0.571865\t Total Acc : 82.3342\n",
      "-------61 epoch end  -----------\n",
      "\n",
      "-------61 batch norm parameter logging ---------\n",
      "-------61 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [61] Test set: Average loss: 2.4076, Accuracy: 4823/10000 (48.2300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 61 result ------------\n",
      "-------62 epoch start-----------\n",
      "Train Epoch: [62] [0/50000 (0%)]\tLoss: 0.495431\n",
      "Train Epoch: [62]\t Average Loss: 0.553947\t Total Acc : 82.8005\n",
      "-------62 epoch end  -----------\n",
      "\n",
      "-------62 batch norm parameter logging ---------\n",
      "-------62 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [62] Test set: Average loss: 2.4055, Accuracy: 4876/10000 (48.7600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 62 result ------------\n",
      "-------63 epoch start-----------\n",
      "Train Epoch: [63] [0/50000 (0%)]\tLoss: 0.477041\n",
      "Train Epoch: [63]\t Average Loss: 0.541475\t Total Acc : 83.3044\n",
      "-------63 epoch end  -----------\n",
      "\n",
      "-------63 batch norm parameter logging ---------\n",
      "-------63 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [63] Test set: Average loss: 2.3866, Accuracy: 4927/10000 (49.2700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 63 result ------------\n",
      "-------64 epoch start-----------\n",
      "Train Epoch: [64] [0/50000 (0%)]\tLoss: 0.502409\n",
      "Train Epoch: [64]\t Average Loss: 0.522368\t Total Acc : 83.9466\n",
      "-------64 epoch end  -----------\n",
      "\n",
      "-------64 batch norm parameter logging ---------\n",
      "-------64 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [64] Test set: Average loss: 2.3938, Accuracy: 4935/10000 (49.3500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 64 result ------------\n",
      "-------65 epoch start-----------\n",
      "Train Epoch: [65] [0/50000 (0%)]\tLoss: 0.447614\n",
      "Train Epoch: [65]\t Average Loss: 0.526152\t Total Acc : 83.9646\n",
      "-------65 epoch end  -----------\n",
      "\n",
      "-------65 batch norm parameter logging ---------\n",
      "-------65 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 65 batch layer input tensor ------------------\n",
      "-------- logging end 65 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [65] Test set: Average loss: 2.4266, Accuracy: 4898/10000 (48.9800%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 65 result ------------\n",
      "-------66 epoch start-----------\n",
      "Train Epoch: [66] [0/50000 (0%)]\tLoss: 0.392750\n",
      "Train Epoch: [66]\t Average Loss: 0.511189\t Total Acc : 84.3746\n",
      "-------66 epoch end  -----------\n",
      "\n",
      "-------66 batch norm parameter logging ---------\n",
      "-------66 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [66] Test set: Average loss: 2.4204, Accuracy: 4882/10000 (48.8200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 66 result ------------\n",
      "-------67 epoch start-----------\n",
      "Train Epoch: [67] [0/50000 (0%)]\tLoss: 0.448586\n",
      "Train Epoch: [67]\t Average Loss: 0.505504\t Total Acc : 84.3906\n",
      "-------67 epoch end  -----------\n",
      "\n",
      "-------67 batch norm parameter logging ---------\n",
      "-------67 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [67] Test set: Average loss: 2.5448, Accuracy: 4721/10000 (47.2100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 67 result ------------\n",
      "-------68 epoch start-----------\n",
      "Train Epoch: [68] [0/50000 (0%)]\tLoss: 0.461873\n",
      "Train Epoch: [68]\t Average Loss: 0.496772\t Total Acc : 84.5612\n",
      "-------68 epoch end  -----------\n",
      "\n",
      "-------68 batch norm parameter logging ---------\n",
      "-------68 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [68] Test set: Average loss: 2.4346, Accuracy: 4925/10000 (49.2500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 68 result ------------\n",
      "-------69 epoch start-----------\n",
      "Train Epoch: [69] [0/50000 (0%)]\tLoss: 0.429894\n",
      "Train Epoch: [69]\t Average Loss: 0.494087\t Total Acc : 84.7678\n",
      "-------69 epoch end  -----------\n",
      "\n",
      "-------69 batch norm parameter logging ---------\n",
      "-------69 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [69] Test set: Average loss: 2.5028, Accuracy: 4796/10000 (47.9600%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 69 result ------------\n",
      "-------70 epoch start-----------\n",
      "Train Epoch: [70] [0/50000 (0%)]\tLoss: 0.286466\n",
      "Train Epoch: [70]\t Average Loss: 0.467634\t Total Acc : 85.6378\n",
      "-------70 epoch end  -----------\n",
      "\n",
      "-------70 batch norm parameter logging ---------\n",
      "-------70 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 70 batch layer input tensor ------------------\n",
      "-------- logging end 70 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [70] Test set: Average loss: 2.4871, Accuracy: 4855/10000 (48.5500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 70 result ------------\n",
      "-------71 epoch start-----------\n",
      "Train Epoch: [71] [0/50000 (0%)]\tLoss: 0.373925\n",
      "Train Epoch: [71]\t Average Loss: 0.465426\t Total Acc : 85.5738\n",
      "-------71 epoch end  -----------\n",
      "\n",
      "-------71 batch norm parameter logging ---------\n",
      "-------71 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [71] Test set: Average loss: 2.4389, Accuracy: 4890/10000 (48.9000%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 71 result ------------\n",
      "-------72 epoch start-----------\n",
      "Train Epoch: [72] [0/50000 (0%)]\tLoss: 0.361810\n",
      "Train Epoch: [72]\t Average Loss: 0.473597\t Total Acc : 85.5047\n",
      "-------72 epoch end  -----------\n",
      "\n",
      "-------72 batch norm parameter logging ---------\n",
      "-------72 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [72] Test set: Average loss: 2.4571, Accuracy: 4892/10000 (48.9200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 72 result ------------\n",
      "-------73 epoch start-----------\n",
      "Train Epoch: [73] [0/50000 (0%)]\tLoss: 0.313804\n",
      "Train Epoch: [73]\t Average Loss: 0.449614\t Total Acc : 86.2264\n",
      "-------73 epoch end  -----------\n",
      "\n",
      "-------73 batch norm parameter logging ---------\n",
      "-------73 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [73] Test set: Average loss: 2.4842, Accuracy: 4881/10000 (48.8100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 73 result ------------\n",
      "-------74 epoch start-----------\n",
      "Train Epoch: [74] [0/50000 (0%)]\tLoss: 0.549133\n",
      "Train Epoch: [74]\t Average Loss: 0.451914\t Total Acc : 85.8392\n",
      "-------74 epoch end  -----------\n",
      "\n",
      "-------74 batch norm parameter logging ---------\n",
      "-------74 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [74] Test set: Average loss: 2.5030, Accuracy: 4822/10000 (48.2200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 74 result ------------\n",
      "-------75 epoch start-----------\n",
      "Train Epoch: [75] [0/50000 (0%)]\tLoss: 0.529609\n",
      "Train Epoch: [75]\t Average Loss: 0.433312\t Total Acc : 86.8195\n",
      "-------75 epoch end  -----------\n",
      "\n",
      "-------75 batch norm parameter logging ---------\n",
      "-------75 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 75 batch layer input tensor ------------------\n",
      "-------- logging end 75 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [75] Test set: Average loss: 2.4852, Accuracy: 4925/10000 (49.2500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 75 result ------------\n",
      "-------76 epoch start-----------\n",
      "Train Epoch: [76] [0/50000 (0%)]\tLoss: 0.328963\n",
      "Train Epoch: [76]\t Average Loss: 0.444997\t Total Acc : 86.2944\n",
      "-------76 epoch end  -----------\n",
      "\n",
      "-------76 batch norm parameter logging ---------\n",
      "-------76 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [76] Test set: Average loss: 2.5734, Accuracy: 4774/10000 (47.7400%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 76 result ------------\n",
      "-------77 epoch start-----------\n",
      "Train Epoch: [77] [0/50000 (0%)]\tLoss: 0.341994\n",
      "Train Epoch: [77]\t Average Loss: 0.431957\t Total Acc : 86.5185\n",
      "-------77 epoch end  -----------\n",
      "\n",
      "-------77 batch norm parameter logging ---------\n",
      "-------77 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [77] Test set: Average loss: 2.4643, Accuracy: 4927/10000 (49.2700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 77 result ------------\n",
      "-------78 epoch start-----------\n",
      "Train Epoch: [78] [0/50000 (0%)]\tLoss: 0.370779\n",
      "Train Epoch: [78]\t Average Loss: 0.432788\t Total Acc : 86.6960\n",
      "-------78 epoch end  -----------\n",
      "\n",
      "-------78 batch norm parameter logging ---------\n",
      "-------78 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [78] Test set: Average loss: 2.5386, Accuracy: 4871/10000 (48.7100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 78 result ------------\n",
      "-------79 epoch start-----------\n",
      "Train Epoch: [79] [0/50000 (0%)]\tLoss: 0.440927\n",
      "Train Epoch: [79]\t Average Loss: 0.416820\t Total Acc : 87.2806\n",
      "-------79 epoch end  -----------\n",
      "\n",
      "-------79 batch norm parameter logging ---------\n",
      "-------79 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [79] Test set: Average loss: 2.4915, Accuracy: 4931/10000 (49.3100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 79 result ------------\n",
      "-------80 epoch start-----------\n",
      "Train Epoch: [80] [0/50000 (0%)]\tLoss: 0.341023\n",
      "Train Epoch: [80]\t Average Loss: 0.425582\t Total Acc : 86.9613\n",
      "-------80 epoch end  -----------\n",
      "\n",
      "-------80 batch norm parameter logging ---------\n",
      "-------80 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 80 batch layer input tensor ------------------\n",
      "-------- logging end 80 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [80] Test set: Average loss: 2.4878, Accuracy: 4881/10000 (48.8100%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 80 result ------------\n",
      "-------81 epoch start-----------\n",
      "Train Epoch: [81] [0/50000 (0%)]\tLoss: 0.495913\n",
      "Train Epoch: [81]\t Average Loss: 0.413794\t Total Acc : 87.3150\n",
      "-------81 epoch end  -----------\n",
      "\n",
      "-------81 batch norm parameter logging ---------\n",
      "-------81 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [81] Test set: Average loss: 2.4904, Accuracy: 4927/10000 (49.2700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 81 result ------------\n",
      "-------82 epoch start-----------\n",
      "Train Epoch: [82] [0/50000 (0%)]\tLoss: 0.312635\n",
      "Train Epoch: [82]\t Average Loss: 0.410683\t Total Acc : 87.4469\n",
      "-------82 epoch end  -----------\n",
      "\n",
      "-------82 batch norm parameter logging ---------\n",
      "-------82 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [82] Test set: Average loss: 2.5246, Accuracy: 4857/10000 (48.5700%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 82 result ------------\n",
      "-------83 epoch start-----------\n",
      "Train Epoch: [83] [0/50000 (0%)]\tLoss: 0.428383\n",
      "Train Epoch: [83]\t Average Loss: 0.401358\t Total Acc : 87.8233\n",
      "-------83 epoch end  -----------\n",
      "\n",
      "-------83 batch norm parameter logging ---------\n",
      "-------83 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [83] Test set: Average loss: 2.4964, Accuracy: 4899/10000 (48.9900%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 83 result ------------\n",
      "-------84 epoch start-----------\n",
      "Train Epoch: [84] [0/50000 (0%)]\tLoss: 0.217823\n",
      "Train Epoch: [84]\t Average Loss: 0.396387\t Total Acc : 87.8509\n",
      "-------84 epoch end  -----------\n",
      "\n",
      "-------84 batch norm parameter logging ---------\n",
      "-------84 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [84] Test set: Average loss: 2.5303, Accuracy: 4829/10000 (48.2900%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 84 result ------------\n",
      "-------85 epoch start-----------\n",
      "Train Epoch: [85] [0/50000 (0%)]\tLoss: 0.390712\n",
      "Train Epoch: [85]\t Average Loss: 0.407490\t Total Acc : 87.6019\n",
      "-------85 epoch end  -----------\n",
      "\n",
      "-------85 batch norm parameter logging ---------\n",
      "-------85 batch norm parameter log end ---------\n",
      "\n",
      "-------- logging 85 batch layer input tensor ------------------\n",
      "-------- logging end 85 --------------------\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [85] Test set: Average loss: 2.5509, Accuracy: 4825/10000 (48.2500%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 85 result ------------\n",
      "-------86 epoch start-----------\n",
      "Train Epoch: [86] [0/50000 (0%)]\tLoss: 0.359616\n",
      "Train Epoch: [86]\t Average Loss: 0.404892\t Total Acc : 87.6183\n",
      "-------86 epoch end  -----------\n",
      "\n",
      "-------86 batch norm parameter logging ---------\n",
      "-------86 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [86] Test set: Average loss: 2.5014, Accuracy: 4913/10000 (49.1300%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 86 result ------------\n",
      "-------87 epoch start-----------\n",
      "Train Epoch: [87] [0/50000 (0%)]\tLoss: 0.248214\n",
      "Train Epoch: [87]\t Average Loss: 0.388328\t Total Acc : 88.0874\n",
      "-------87 epoch end  -----------\n",
      "\n",
      "-------87 batch norm parameter logging ---------\n",
      "-------87 batch norm parameter log end ---------\n",
      "\n",
      "----- test and print accuracy ------------------\n",
      "\n",
      "Epoch [87] Test set: Average loss: 2.5099, Accuracy: 4892/10000 (48.9200%)\n",
      "\n",
      "----- test end -------------------------\n",
      "\n",
      "\n",
      "----- save intermediate 87 result ------------\n",
      "-------88 epoch start-----------\n",
      "Train Epoch: [88] [0/50000 (0%)]\tLoss: 0.322426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30309/1392492302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"-------{epoch} epoch start-----------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Acc/Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/Train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30309/2272628329.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtotal_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_test_acc = 0\n",
    "best_epoch = 0\n",
    "save_best_acc_path = os.path.join(option.save_path, \"best_checkpoint.pth\")\n",
    "\n",
    "#   logger \n",
    "\n",
    "for epoch in range(start_epoch, option.epochs):\n",
    "    print(f\"-------{epoch} epoch start-----------\")\n",
    "    train_acc, train_loss = train(net, train_loader, optimizer, epoch, device)\n",
    "    writer.add_scalar(\"Acc/Train\", train_acc, epoch)\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    print(f\"-------{epoch} epoch end  -----------\\n\")\n",
    "    print(f\"-------{epoch} batch norm parameter logging ---------\")\n",
    "    save_bn_dict = get_batchnorm_param_dict(net, epoch)\n",
    "    batchnorm_df = batchnorm_df.append(save_bn_dict, ignore_index=True)\n",
    "    batchnorm_df.to_csv(csv_path)\n",
    "    print(f\"-------{epoch} batch norm parameter log end ---------\\n\")\n",
    "    \n",
    "    if epoch in option.activation_step:\n",
    "        print(f\"-------- logging {epoch} batch layer input tensor ------------------\")        \n",
    "        result_hook_list = hook_result(net, check_data, option)\n",
    "        for hook in result_hook_list:\n",
    "            name = hook[0]\n",
    "            batch_input = hook[1].input[0].cpu().detach()\n",
    "            save_pkl_path = os.path.join(option.save_path, f\"{name}_{epoch}_input.pkl\")\n",
    "            with open(save_pkl_path, \"wb\") as fw:\n",
    "                pickle.dump(batch_input, fw)\n",
    "            hook[1].close()\n",
    "        print(f\"-------- logging end {epoch} --------------------\")         \n",
    "                \n",
    "    if epoch % 1 == 0: # imagenet epoch % 5 == 0\n",
    "        print(\"----- test and print accuracy ------------------\")\n",
    "        test_acc, test_loss=test(net, test_loader, epoch, device)\n",
    "        writer.add_scalar(\"Acc/Test\", test_acc, epoch)\n",
    "        writer.add_scalar(\"Loss/Test\", test_loss, epoch)\n",
    "        print(\"----- test end -------------------------\")\n",
    "        print(\"\\n\")\n",
    "        print(f\"----- save intermediate {epoch} result ------------\")\n",
    "        save_state_dict_path = os.path.join(option.save_path, f\"epoch_{epoch}_state_dict.pth\")\n",
    "        save_prev_state_dict_path = os.path.join(option.save_path, f\"epoch_{epoch-1}_state_dict.pth\")\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            print(f\"logging best performance {epoch} epoch\")\n",
    "            torch.save(net.state_dict(), save_best_acc_path)\n",
    "            best_epoch = epoch\n",
    "            best_test_acc = test_acc\n",
    "            writer.add_scalar(\"Best Test Acc\", best_test_acc, best_epoch)\n",
    "        \n",
    "    torch.save({\n",
    "        'end_epoch': epoch,\n",
    "        'model_state_dict' : net.state_dict(),\n",
    "        'optimizer_state_dict' : optimizer.state_dict(),\n",
    "        'scheduler_state_dict' : scheduler.state_dict()\n",
    "    }, save_state_dict_path)\n",
    "\n",
    "    if os.path.exists(save_prev_state_dict_path):\n",
    "        os.remove(save_prev_state_dict_path)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': '123', 'b': '456'}\n"
     ]
    }
   ],
   "source": [
    "a = {\"a\":\"123\", \"b\":\"456\"}\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
